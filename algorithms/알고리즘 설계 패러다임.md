
# 6장 알고리즘 설계 패러다임

여기서는 단순히 각 알고리즘 설계 패러다임에 대한 간략한 정의 및 설명만을 정리한다. 실제 패러다임에 맞는 문제들은 각 페이지 별로 참고하자.


## 무식하게 풀기(Brute-Force)

brute는 "짐승같은, 난폭한"이라는 뜻이다. 따라서 brute-force는 "난폭한 힘, 폭력"이라는 뜻이다. 

흔히 전삭학에서 무식하게 푼다라는 말의 컴퓨터의 빠른 계산 능력을 이용해 가능한 경우의 수를 일일이 나열하면서 답을 찾는 방법을 의미한다.  

가능한 방법을 모두 만들어 보는 알고리즘을 완전 탐색(exhaustive search)이라고 부른다. 얼핏 보면 이런 것을 언급할 필요가 있나 싶을 정도로 간단한 방법이지만, 완전 탐색은 컴퓨터의 장점을 가장 잘 이용하는 방법이다. 컴퓨터의 최대 장점은 결국 계산 속도가 빠르다는 것이기 때문이다. 

## 분할 정복법(Divide & Conquer)

가장 유명한 알고리즘 디자인 패러다임으로, 각개 격파라는 말이다. 
주어진 문제를 둘 이상의 부분 문제로 나누고, 각 문제에 대한 답을 재귀호출을 이용해 계산하고, 각 부분 문제의 답으로 부터 전체 문제의 답을 계산해낸다. 
분할 정복법을 사용하는 알고리즘은 대개 아래 세 가지 스텝으로 구성된다.

* 문제를 더 작은 문제로 나누는 과정(Divide)
* 더 이상 문제를 나누지 않고, 바로 답을 낼 수 있는 매우 작은 문제(Base case)
* 각 문제에 대한 답을 구한뒤, 원래 큰 문제의 답으로 병합하는 과정(Merge)


## 동적 계획법(Dynamic Programming)

동적 계획법은 프로그래밍 대회 문제에 가장 자주 출현하는 디자인 패러다임이다. 이름만 가지고는 무엇을 의미하는지 알기가 어렵기 때문에 많은 오해를 불러일으키는 주제이기도 한다.

동적 계획법이란 말은 최적화 문제를 연구하는 수학 이론에서 왔으며, 우리가 전산학 전반에서 일반적으로 사용하는 동적, 혹은 프로그래밍이라는 단어와는 아무 관련이 없다. 

동적 계획법의 고안자 벨만은 dynamic이라는 단어가 멋있어서 선택했다고 한다. Programming이란 말은 최적화 연구분야에서 최적의 프로그램을 찾아낸다는 의미로 사용된다.

### 중복되는 부분 문제

동적 계획법을 사용하는 알고리즘들은 처음에 주어진 문제를 더 작은 문제들로 나눈뒤 각 부분의 답을 계산후, 이 답들로 부터 원래 문제에 대한 답을 계산해 낸다.

이러한 형태는 사실 큰 의미에서 분할 정복 방법과 비슷하다. 두 패러다임의 차이는 문제를 나누는 방식에서 있다.  동적계획법에서 어떤 부분 문제는 전체 문제를 푸는데 두 번 이상 사용 될수 있기 때문에, 같은 부분 문제의 답을 여러번 계산하는 대신 한번만 계산하고 그 계산결과를 재활용함으로써 속도의 향상을 꾀할 수 있다. 

그러기 위해서는 각 문제의 답을 저장해 둘 필요가 있으며, 이미 계산한 값을 저장해 두는 메모리의 장소를 캐시라고 부른다. 또 두 번 이상 계산되는 부분 문제를 중복되는 부분 문제(overlapping subproblmes)라고 부른다. 

동적 계획법의 대표적인 알고리즘으로 이항 계수의 계산이 있다. 
이항 계수는 n개의 서로 다른 원소중에서 r개의 원소를 순서 없이 뽑는 문제이다. 

${n}\choose{r}$ = ${n-1}\choose{r-1}$ +${n-1}\choose{r}$

이 식을 재귀적 호출로 간단하게 구현하면 아래와 같다. 이때 주목할 점은 이항계수의 특성상 같은 값을 두 번 이상 계산할 일이 빈번하다는 점이다. 
``` 
int binomial(int n, int r) {재귀호출을 이용한 이항 계수의 계산
	if(n == r || r==0){
		return 1;
	} // base 모든 원소를 다 고른 경우 또는 고를 원소가 없는 경우
	return binomial(n-1, r-1) + binomial(n-1, r)
}
```
![](http://andromeda-express.com/dp/figures/binomial_call_tree.dot.png)

위의 그림은 bino(4,2)를 계산하는 과정을 나타낸 그림이다. 여기서 중요한 점은 bino(2,1)이 두번 호출된다는 점이다. 

bino(2,1)은 bino(3,1)과 bino(3,2)를 위해서 필요하다. 게다가 bino(2,1)은 bino(1,0)과 bino(1,1)을 호출하기 때문에 같은 계산을 두번이나 하게 된다. 

함수의 중복 호출 수는 n과 r이 커짐에 따라 기하 급수적으로 증가한다.  아래 그림을 보면, bino(8,4)를 계산하기 위해서 bino(1,0)과 bino(1,1)를 반복적으로 호출하는 것을 볼 수가 있다.

![](http://andromeda-express.com/dp/figures/binomial_call_tree3.dot.png)

일반화해서 더 많은 n에 대해서 호출의 수를 계산해보자면, 
$bino(n, \frac{n}{2})$을 계산하기 위해서, 아래와 같이 n이 증가할때마다 거의 두 배 가까이 증가하는 것을 볼수 있다. 

|n| 2 | 3  |  4| 5|6 | ... | 18| ...  | 25|
|--|--|--|--|--|--|--|--|--|--|
|호출 횟수| 3|5 | 11 |19|39|...|97239|...|10400599

그럼 이 계산량은 피할수 없는 숙명일까? 입력인 n과 r이 정해져 있을때, bion(n,r)의 반호나 값이 일정하다는 사실을 이용하면 중복 계산을 제거 할 수 있다.  n과 r조합에 대해 답을 저장하는 캐시 배열을 만들어서 입력 결과를 저장하도록 하자. 

이렇게 결과를 저장하는 장소를 마련해두고, 계산한 값을 저장해두었다가 재활용하는 최적화 기법을 [메모이제이션(memoization)](https://ko.wikipedia.org/wiki/%EB%A9%94%EB%AA%A8%EC%9D%B4%EC%A0%9C%EC%9D%B4%EC%85%98)이라고 한다. 메모라이제이션이라고 잘못 사용하는 경우가 많은데 메모이제이션이 옳은 표현이다 . 

```
int cache[30][30]; // 모든 값을 -1로 초기화해둔다.
int binomial2(int n, int r){ //메모이제이션을 활용한 이항계구 계산
	if(n == r || r == 0){
		return 1;
	} // base 모든 원소를 다 고른 경우 또는 고를 원소가 없는 경우
	if(cache[n][r] != -1){
		return cache[n][r];
	}	
	int binomial = binomial2(n-1, r-1) + binomial2(n-1, r)
	cache[n][r] = binomial;
	return binomial;
}
```
메모이제이션을 쓰면 모든 부분 문제가 한번씩만 계산되기 때문에 호출횟수를 엄청나게 줄일 수 있다. 

### 메모이제이션 심화 

수학의 함수와 프로그래밍에서의 함수가 사실 비슷해보이지만 다르다. 수학의 함수는 입력이 정해져 있을때 출력도 언제나 정해져 있다. 예를 들어 $f(x)=\frac{x}{2}$ 라면 $f(10)$은 죽어도 5다. 

하지만 프로그래밍에서는 함수의 입력외에도 전역 변수, 입력 파일, 멤버 변수등 수많은 다른 입력과 상호작용하기 때문에 결과가 다를 수 있다. 

함수의 반환 값이 그 함수의 입력 값만에만 의존하거나 결정된다면 이것을 유식할 말로 참조적 투명성(referential transparency)이라고 한다. 더 나아가 입력 값이 고정되었을때 결과가 항상 같은 함수를 참조적 투명함수(referential transparency function)이라고 한다.

**당연하게도 메모이제이션은 참조적 투명 함수에만 적용 할 수 있다.** 입력이 같은데 외부 요소에 따라 값이 반환되면 캐싱을 할 수가 없다.

메모이제이션의 시간복잡도를 분석하는 과정은 다소 헷갈릴 수 있다. 각 입력에 대해서 함수를 처음 호출할때와 다음으로 호출할때 캐시 존재 유무에 따라 걸리는 시간이 다르기 때문이다. 다행이도 알고리즘의 시간 복잡도를 간단하게 (주먹구구)로 계산하는 방법이 있다. 

- 존재하는 부분 문제의 수 * 한 부분 문제를 풀때 필요한 반복문 수행 횟수 

무슨말인지 binomial2 로 설명해보자면, 먼저 $r$의 최대치는 $n$이기 때문에 만나는 부분 문제의 수는  최대로 $O(n^2)$이다. 
재귀함수의 중복 호출은 일어나지만 메모이제이션에서 사용하는 실제 복잡도는 메모이제이션 캐시의 크기 만큼인 $n * r$이다. 다만 r은 1 ~ n까지만 가질 수 있기 때문에 최악의 경우 $n^2$개이다. 

 각 부분 문제에는 반복문이 없어 $O(1)$이다. 따라서 bino2(n,r)을 계산하는데 걸리는 시간 복잡도는 $O(n^2)$이다. 

정말 이런 식이 성립할까? 각 부분 문제를 해결하기 위한 재귀 호출이 이루어지는 과정을 아래 그림에서 나타내고 있다. 

![](http://andromeda-express.com/dp/figures/calltree.dot.png)

굵은 원은 해당 부분 문제를 처음 만나 답을 직접 계산하는 경우, 얇은 원은 이미 기저 사례나 답을 계산해 둔 부분 문제에 도달한 경우를 말한다. 

먼저 얇은 부분의 원들은 상수 시간에 수행되기 때문에 전체 시간 복잡도에는 영향을 미치지 않는다. 따라서 굵은 원으로 표시된 재귀 호출의 수행 시간의 합이 시간 복잡도가 된다. 물론 이 식 상항을 간단히 계산할 수 있는 방법이며 정확하지 않다. 

## 탐욕법(Greedy Approach)

탐욕법(Greedy Method)은 가장 직관적인 알고리즘 설계 패러다임 중 하나다. 탐욕적인 알고리즘은 우리가 원하는 답을 여러 조각으로 쪼개고, 각 단계마다 답의 결과를 만들어 간다는 점에서 동적계획법, 완전탐색과 비슷하다. 하지만 탐욕법은 두 방법과 달리, 각 단계마다 지금 당장 가장 좋은 방법만을 선택한다. 

예를 들어, 외판원 문제는 모든 도시들을 하나씩 검사하여 필요한 거리를 최소화하는 경로를 찾는다. 탐욕법은 지금의 선택이 앞으로 남은 선택에 어떤 영향을 미칠지 고려하지 않고 당장 눈앞에 최소 경로를 가지는 도시를 선택한다. 당연히 이런 간단한 방법으로는 우리가 원하는 정답이 나올리 없다. 탐욕적 알고리즘은 대체로 최적해를 찾지 못한다. 따라서 탐욕법이 사용되는 경우는 크게 두가지로 제한된다. 

1. 탐욕법을 사용해도 최적해를 구할 수 있는 문제인 경우, 탐욕법은 동적계획법보다 수행시간이 훨씬 빠르기 때문에 유용하다.
2. 시간이나 공간적 제약으로 다른 방법으로 최적해를 찾기 너무 어려운 경우, 최적해 대신 적당한 답을 찾는 것으로 타협이 가능하다. 이럴때 탐욕법이 유용하게 사용된다.

탐욕법의 개념은 간단하지만 굉장히 어려운 주제다. 한 문제를 해결하는데 탐욕적으로 해결하는 방법이 한 가지만이 아닌 경우도 많고, 어느 방법을 선택해야 최적해를 구하는지 알기가 어렵기 때문이다. 실제로 최적해를 얻을 수 있는 접근이 직관적이지 않은 경우도 많다. 그러니 탐욕적 알고리즘을 풀때는 정당성 증명과정을 정확히 하는게 좋다. 

## 조합 탐색법(Combinational Search)

동적 계획법이나 분할정복등의 디자인 패러다임은 적절히 사용될때는 매우 유용하지만 많은 문제에 적용되기는 힘들다. 적절한 분할 방법이 없는 경우 분할정복을 쓸수 없고 부분문제가 너무 많아 메모리가 부족한 경우 동적계획법을 쓸수가 없다. 이럴 경우 원점인 완전 탐색으로 돌아와야 한다. 

완전 탐색 알고리즘은 대개 답을 만드는 과정이 여러 선택으로 나뉘고, 재귀 호출을 통해 각 선택지를 채워가는 형태로 구현된다. 이때 부분 답과 완성된 답의 집합을 탐색 공간(search space)이라고 한다. 
완전 탐색의 수행시간은 탐색 공간의 크기와 직접적으로 비례한다. 그런데 대부분 문제에서 탐색 공간의 크기는 문제의 규모에 따라 기하급수적으로 증가한다. 따라서 완전 탐색은 규모가 커질 수록 사용하기 어렵다는 문제가 있다. 

완전 탐색을 포함해, 이렇게 유한한 크기의 탐색 공간을 뒤지면서 답을 찾아내는 알고리즘들을 조합탐색(combinational search)이라고 한다. 조합탐색에는 다양한 최적화 기법이 있으며, 접근 방법은 다르지만 모두 기본적으로 최적해가 될 가능성이 없는 답을 탐색하는 것을 방지하여 계산해야할 답의 수을 줄인다. 

조합 탐색을 최적화 하기 위해서는 문제에 대한 높은 식견과, 속도와 정확도 사이 상충 관계, 다양한 입력 형태 사이에 관계 등을 모두 고려하기 때문에 딱히 정답이 없어 아직도 활발히 연구되고 있는 주제이다.  

조합 탐색 최적화 기법에는 대표적으로 분기한정법이 있다.

## 분기한정법(branch-and-bound)
분기한정법은 여러가지의 최적화 문제, 특히 조합최적화 (combinatorial optimization) 에서 최적해를 찾기위한 일반적인 방법이다. `최소한 특정 영역 내에 있어야 최적의 답을 찾을 가능성이 있다.`라는 한정 범위(가능영역;feasible region)를 정해두고 범위를 벗어나는 경우는 계산과정에서 제외하여 속도 향상을 꾀한다. 

분기한정 과정은 분기(branching)와 한정(bounding)이라는 두 가지 과정을 거친다. 

분기(branching)
: 분기는 가능영역(feasible region)에서 여러 개의 작은 하위영역(feasible subregion)을 구성한다. 이 작은 하위 영역은 재귀 반복 과정을 통해 만들어지고 자연스럽게 branch-and-bound-tree 라고 불리는 tree 구조를 형성한다. 이 구조의 각 노드들이 바로 하위영역이다.

한정(bounding)
: 한정은 하위영역에서 최소 또는 최대의 범위(upper and lower bound)를 계산하는 과정을 말한다. 이 계산 결과를 이용해서 탐색공간(search space)를 줄이는 것이 가능한데 이런 기법을 가지치기(pruning)이라고 부른다. 
예를 들어 외판원 문제에서, 길이가 10인 경로를 이미 찾아냈다고 하자. 그러면 재귀 호출 도중 현재까지 만든 부분경로의 길이가 이미 10이상이라면 더 이상 탐색하지 않아도 된다. 왜냐하면 나머지 탐색을 진행해도 10보다 작은 경로를 찾을 수 없다는게 자명하기 때문이다. 

 분기한정법의 효율은 가지치기(pruning) 전략에 좌지우지 된다. 비효율적인 알고리즘을 사용하면 하위영역이 매우 작아질 때 까지 어떤 가지치기도 없이 반복해서 분기만 할수도 있다. 
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTUzOTcwOTM0MiwyNjMyODAwMjAsLTMxNz
EwMDQxMiwtMTAzNjYwOTEzNCwtMTI1ODIyMjczMSwtMTIyNDM4
NDA1NywxOTEzNjk5OTk3LC0xNzI3MzM1MzA5LC0xODg5MTA5Mj
k1LDIwNDIzNTk0NzMsLTE5NTQ1MTk4MzgsLTMzMDg1NTM2MCwt
MjA2MTMyNjc1MCw5NDkzNDY1NDgsLTE2NTQzNzQ4OTQsMTU2OD
g0MDQ0NSwtOTIxODQwMzYsLTcyOTk0NzA3NiwyNDYzNDUwMzUs
LTEyOTA4ODU2MF19
-->