
# 4장 알고리즘의 시간 복잡도 분석(1)

알고리즘을 평가하는 두 가지 기준 :

* 시간 : 알고리즘이 적은 시간을 사용한다는 것은 더 빠르게 동작한다는 이야기.
* 공간 : 더 적은 용량의 메모리를 사용한다는 이야기. 알고리즘이 아무리 빠르더라도 너무 많은 메모리 공간을 사용하면 수행이 불가

두 기준은 서로 상충하는 경우가 많다. 메모리 사용량을 늘려 속도를 높이거나, 속도를 희생해서 메모리 사용량을 줄이는 알고리즘들도 있다. 보통은 속도를 중시하는 경우가 많다.

## 4.1 도입 

프로그램의 소요시간은 프로그래밍 언어, 하드웨어, 컴파일러 등의 환경적인 요소로 크게 변화할 수 있다. 심지어 같은 알고리즘의 수행시간도 입력크기, 입력 데이터의 특성 등에 의해 변화한다. 
다수의 항목 중에 특정 항목이 전체의 대소를 좌지우지 한다는 것을 지배한다(dominate)라고 표현한다.  알고리즘 수행 시간을 지배하는 것은 일반적으로 반복문이다.

## 4.2 선형 시간 알고리즘 

선형시간(linear) 알고리즘은 입력 N(데이터의 크기)에 1:1로 비례하는 수행시간을 보이는 알고리즘을 말한다. 

## 4.3 선형 이하 알고리즘

입력의 크기가 커지는 것보다 수행 시간이 느리게 증가하는 알고리즘들을 선형 이하 알고리즘(sublinear)이라 한다. 

책에서는 사진이 날짜별로 정렬되어 있고 특정 사진을 찾으려고 한다. 매번 확인 할때마다 확인해야 할 사진의 수자 절반씩 줄어든다. 
$$1,000,000 > 500,000 > 250,000 > 125,000 > ... > 3 > 1$$

즉 $log N$의 의미는 즉 `주어진 N에 대해서 절반씩 몇번을 나누어야 원하는 값을 찾을 수 있을까?`에 대한 답이다. 

### 이진 탐색(Binary Search)

이진 탐색이 하는 일의 정의
binsearch(A[], x) = 오름 차순으로 정렬된 배열  A와 찾고 싶은 값  x가 주어질 때 $A[i-1] < x <= A[i]$인 i를 반환한다. 

대개 배열이나 리스트 구현에서  i번째 위치에 새 원소를 삽입한다는 것은 i번째와 그 이후의 원소들을 뒤로 한 칸씩 밀어내고 들어간다는 뜻

7 , 8, 9, 9 , 10 ... ; 만약 9를 넣을 자리를 찾는 다면? $A[1] = 8 < x <= A[2] = 9$ 이기 때문에 2번째 자리를 반환 

C++ 표준 라이브러리에는 두개의 이진 탐색 함수가 존재, 가장 앞에 있는 것을 반환하는 lower_bound()와 가장 뒤의 것을 반환하는 upper_bound()

## 4.4 다항 시간 이상 알고리즘

### 다항 시간 알고리즘
변수 $N$, $N^2$ 그 외의 거듭제곱들의 선형 결합으로 이루어진 식들을 다항식이라고 부른다. 사실 다항 시간 알고리즘에 분류가 되는 알고리즘 간에도 엄청난 시간 차이가 날 수 있다.  $N^2, N^3, ..., N^{100}$ 모두 같은 다항시간이다. 그런데도 이런 부류를 묶은 이유는 다항 시간 알고리즘보다 훨씬 더 오래 걸리는 알고리즘들이 있기 때문이다.

### 지수 시간 알고리즘
$2^N$ 과 같이 지수함수는 알고리즘의 전체 수행시간에 엄청난 영향을 미친다. N이 하나 증가할때마다 시간이 배로 증가하는 알고리즘을 지수시간(exponential time)에 동작한다고 한다. 

## 4.5 시간복잡도

시간 복잡도(time complexity)
: 가장 널리 사용되는 알고리즘의 수행시간 기준 
알고리즘의 기본적인 연산 수를 입력의 크기에 대한 함수로 표현한 것

* 시간 복잡도가 높다 = 입력의 크기가 증가할때 알고리즘 수행시간이 더 빠르게 증가한다는 뜻
* 시간 복잡도가 낮다 = 입력의 크기가 커지면 알고리즘 수행시간이 더 효율적이다라는 뜻

사실 시간 복잡도가 낮다고해서 언제나 빠르게 동작하는 것은 아니다. 입력의 크기가 충분히 작을 때는 시간 복잡도가 높은 알고리즘이 더 빠르게 동작 할수도 있다 .


기본적인 연산
: 더 이상 쪼개지지 않는 최소 단위의 연산

>기본적인 연산의 예  
두 부호있는 32비트 정수의 사칙연산
두 실수형 변수 대소 비교

>기본적인 연산이 아닌 예
정수 배열 정렬하기, 두 문자열이 서로 같은지 확인하기
반복문을 포함하기 때문에 기본적 연산이 아니다.


### 입력의 형태에 따른 수행 시간의 변화

입력의 크기가 수행 시간을 결정하는 유일학 척도는 아니다. 입력의 형태도 수행 시간에 영향을 미친다. 예를 들어, 배열을 넣는데 찾고자 하는 값이 맨 앞에 있을수도 있고, 맨 뒤에 있을 수도 있다. 

이와 같이 입력의 따라 수행시간이 달라지는 경우를 고려하기 위해, 최선, 최악 그리고 평균 수행시간을 각각 따로 계산한다. 

최선(best case) : 주어진 입력이 알고리즘의 최단 수행 시간 만큼 걸리는 케이스
최악(worst case) : 주어진 입력이 알고리즘의 최장 수행 시간 만큼 걸리는 케이스
평균(average case) : 주어진 입력이 알고리즘의 평균 수행 시간 만큼 걸리는 케이스

단순 선형 탐색에서는 평균 수행 횟수는 $N/2=  (1 + 2 + ... + n) / n$ = (첫번째로 답을 찾는 연산 수 + 두번째로 답을 찾는 연산수 + .... + n번째로 답을 찾는 연산수) / n == 평균 연산 수행 횟수

주로 사용하는 것은 최악의 수행 시간 또는 평균 수행시간을 사용한다.  

### 점근적 시간 표기: O 표기

시간 복잡도는 알고리즘 수행 시간을 표기하는 방법이지만,  알고리즘의 분석하여 실제로 정확한 시간복잡도를 계산하기는 너무 힘들다. 그래서 수행시간에 큰 영향을 미치는 부분만 표기하는 표기 방법이 고안되었다.

### O 표기법(Big - O notation, Big O)

O 표기법은 알고리즘 수행시간의 표기법 중 하나로 **특정 알고리즘의 시간 복잡도 상한을 나타낸다.** 
$n$(데이터 입력크기)에 대한 실제 연산회수 함수 $f(n)$이 존재한다고 하자. 이 함수 $f(n)$에 대해 $f(n) = O(g(n))$라고 쓰는것은 아래와 같은 의미를 가진다.

**적당히 큰 $n_0$ 보다 같거나 큰 $n$ 중에서, $|f(n)| <= C * |g(n)|$을 만족하는 상수(C)가 존재한다.**

![](https://t1.daumcdn.net/cfile/tistory/276E894E559798A516)

>Example 1
$N^3  <= C * (N^2 ) --> N^3  !=  O(N^2)$// C는  N 보다는 작다.
$N^3  <= C * (N^3 ) --> N^3 =  O(N^3)$
$N^3  <= C * (N^4 ) --> N^3  =  O(N^4)$

>Example 2
$2N^3 + N^2 + N  <= C * (N^2 ) --> 2N^3 + N^2 + N  !=  O(N^2)$ // C는  N 보다는 작다.
$2N^3 + N^2 + N   <= C * (N^3 ) --> 2N^3 + N^2 + N =  O(N^3)$
$2N^3 + N^2 + N   <= C * (N^4 ) --> 2N^3 + N^2 + N  =  O(N^4)$
...

실제 연산회수$(f(n))$을 O 표기를 통해 연산회수의 상한을 나타낼수 있다. 
어떤 알고리즘의 연산횟수 $f(n)$에 대해 ...
$f(N) = O(n^3)$ : 최대 $n^3$ 시간 복잡도를 가진다.  
$f(N) = O(nlogn)$ : 최대 $nlogn$ 시간 복잡도를 가진다.  

### Ω 표기법(small - O notation, Big Omega)
Ω 표기법은 함수의 하한을 나타낸다는 의미로 앞에서  O 표기법과는 반대되는 개념.

n(데이터 입력크기)에 대한 실제 연산회수 함수 $f(n)$이 존재하고, 함수 $f(n)$에 대해 $f(n) = Ω(g(n))$라고 쓰는것은 아래와 같은 의미이다. 

**적당히 큰 $n_0$ 보다 같거나 큰 $n$ 중에서, $|f(n)| >= C * |g(n)|$을 만족하는 상수(C가 존재한다.**

![](https://t1.daumcdn.net/cfile/tistory/2416234D55979CF032)
위의 빅오 정의와 다른 점은, 부등호의 방향이 반대

> Example 1
$N^3  >= C * (N^2 ) --> N^3 =  Ω(N^2)$
$N^3  >= C * (N^3 ) --> N^3 =  Ω(N^3)$
$N^3  >= C * (N^4 ) --> N^3  !=  Ω(N^4)$ // C는  N 보다는 작다.

실제 연산회수$(f(N))$을 $Ω$표기를 통해 연산회수의 하한을 나타낼수 있다. 
어떤 알고리즘의 연산횟수 $f(N)$에 대해 ...
$f(N) = Ω(n^3)$ : 최소 $n^3$ 시간 복잡도를 가진다.  
$f(N) = Ω(nlogn)$ : 최소 $nlogn$ 시간 복잡도를 가진다.  

O표기법과 관계를 표현하면 ...
$f(n) = O(g(n))$ 이면 $g(n) = Ω(f(n))$
특정 알고리즘의 시간 복잡도 $f(n)$의 최대는 $g(n)$,  최대 복잡도 $g(n)$의 최소는 $f(n)$

>Example 1
$N^3 = O(n^3) --> N^3 = Ω(n^3)$
$N^3 = O(n^4) --> N^4 = Ω(n^3)$
$N^3 = O(n^5) --> N^5 = Ω(n^3)$

f(n) = Ω(g(n)) 이면 g(n) = O(f(n))
> Example 1
$N^3 = Ω(n^3) --> N^3 = O(n^3)$
$N^3 = Ω(n^2) --> N^2 = O(n^3)$
$N^3 = Ω(n^1) --> N^1 = O(n^3)$
... 

예외적으로 상수번 만큼의 연산만이 필요한 알고리즘의 경우, 예를들어 $42 = O(1)$ 로 표현할 수 있다.  이러한 알고리즘을 카리켜 상수 시간(constant-time) 알고리즘이라고 한다. 

### 빅 세타 표기법(Big θ notation)
θ 표기법은 함수의 상한과 하한을 동시에 나타낸다.
n(데이터 입력크기)에 대한 실제 연산회수 함수 $f(n)$이 존재하고, 함수 $f(n)$에 대해 $f(n) = θ(g(n))$라고 쓰는것은 아래와 같은 의미

![](https://t1.daumcdn.net/cfile/tistory/2307BA4A55979DBA23)
``` 
적당한 n(n ∈ N)과 C1, C2(c1, C1 > 0)에 대해, n 보다 크거나 같은(n <= N)인
모든 N에 대해 C1 * |g(N)| <= |f(N)| <= C2 * |g(N)|이 성립한다.
```

>Example 1
$C1 * N^2 <= N^2  <= C2 * (N^2 ) --> N^2 =  θ(N^2)$
...

실제 연산회수$(f(N))$을 θ 표기를 통해 연산회수의 상환과 동시에 하한을 나타낼수 있다. 
어떤 알고리즘의 연산횟수 f(N)에 대해 ...
$f(N) = θ(n^3)$ : 최소 $n^3$ 그리고 최대 $n^3$ 시간 복잡도를 가진다.  
$f(N) = Ω(nlogn)$ : 최소 $nlogn$ 그리고 최대 $nlogn$시간 복잡도를 가진다.  

## 4.6 수행시간 어림짐작하기

프로그래밍 대회의 시간 제한은 알고리즘의 시간 복잡도가 아니라 프로그램의 실제 수행시간을 기준으로 한다. 
따라서 프로그램 작성전에 입력의 최대 크기와 알고리즘의 시간 복잡도를 보고 수행시간을 어림 짐작 할 수 있어야 한다. 

입력의 최대 크기 N과 테스크 케이스를 푸는데 시간 제한이 주어졌을때, 만든 알고리즘으로 시간 내에 문제를 풀수 있을지 어림 짐작하는 방법이 있다. 
알고리즘 대회에서 많은 참가자들이 사용하는 주먹구구 법칙 

```
 입력의 크기를 시간 복잡도에 대입해서 얻은 반복문 수행 회수에 대해,
 1초당 반복문 수행 회수가 1억(10^8)을 넘어가면 시간 제한을 초과할 가능성이 있다.
```
$O(N^3)$ 알고리즘 : 
최대 입력 크기를 10000($10^4$)을 주면, 1억을 초과한다.
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTM4MDU0OTU4MywtMjEzNzM2MjI4NCwxMT
I0ODM5NzcsNDk2NDQ5Njk0LC0xODAyNDkyNzA0LDE4OTY5NTk2
NjIsLTEwNzU5NTgxOCw3NTc3Mzk2MjUsMTkyMzM0MTA3OCwtMj
IwNjg5NTksLTE5NTM3OTUxMjUsLTE5ODU5MTI2MjMsLTc0MzA0
NjE2NSwtMTY3ODk5ODY5NywyMTkyMDMxODEsLTEzNjYwMjQyND
csNTU4Njg4NjQsLTE1OTIwNDIwMTQsLTI3Njk4OTEyXX0=
-->