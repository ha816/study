
# 4장 알고리즘의 시간 복잡도 분석(1)

알고리즘을 평가하는 두 가지 기준

* 시간 : 알고리즘이 적은 시간을 사용한다는 것은 더 빠르게 동작한다는 이야기.
* 공간 : 더 적은 용량의 메모리를 사용한다는 이야기. 알고리즘이 아무리 빠르더라도 너무 많은 메모리 공간을 사용하면 수행이 불가

두 기준은 서로 상충하는 경우가 많다. 메모리 사용량을 늘려 속도를 높이거나, 속도를 희생해서 메모리 사용량을 줄이는 알고리즘들도 있다. 보통은 속도를 중시하는 경우가 많다.

사실 한 프로그램의 수행 시간은 프로그래밍 언어, 하드웨어, 컴파일러 등의 환경적인 요소로 크게 변화할 수 있다. 심지어 한 알고리즘의 수행시간도 입력크기, 입력 데이터의 특성 등에 의해 변화한다.

## 4.2 선형 시간 알고리즘 

선형시간(linear) 알고리즘
: 입력 데이터 크기에 1:1로 비례하는 수행시간을 보이는 알고리즘


M-이동 평균(M-moving average)
: 시계열 데이터(시간에 따라 변화하는 데이터)를 관찰하는 통계 기법. 일반적으로 특정 날짜를 기준으로 가장 최근 M일의 데이터의 평균이 그 날짜에 해당하는 M-이동 평균이다.

M-이동평균을 계산하는건 이중 for 문을 이용하면 간단하다.
``` 
N = Data.size;
for(base = 0 + M-1; base < N){// M-1번째 부터 시작하여 N까지 처리; 최근 M일을 계산하는데 초기 0~M-2일 까지는 계산하지 않는다.
partialSum =0;
	for(j = 0; j < M; j++){ // 가장 최근 M일 
	partialSum += Data[base-j];
	average = partialSum / M;
	}
}
```

그러나 이것을 개선이 가능하다. **아이디어는 중복된 계산을 없애는것**
0부터 M-1까지 데이터의 총합 : $Sum[0] = D[0] + D[1] + D[2] + ... + D[M-1]$
1부터 M까지 데이터의 총합: $Sum[1] = D[1] + D[2] + ... + D[M]$
...
i-1부터 M+i-2까지 데이터의 총합: $Sum[i-1] = D[i-1] + D[i] + ... + D[i+M-2]$
i부터 M+i-1까지 데이터의 총합: $Sum[i] = D[i] + D[i+1] + ... + D[i+M-1]$

즉 i번째 데이터의 총합은 i-1번째 데이터의 총합에서 D[i-1]을 빼고 D[i+M-1]를 더한 값이다. $Sum[i] = Sum[i-1]- D[i-1] +D[i+M-1]$이다.  위의 아이디어를 사용하면 선형시간만에 M-이동평균을 구할 수 있다. 
```
for(i = 0; i < M-1; ++i) // 제일 초기의 데이터 총합
	partialSum = D[i];
for(i = M -1 ; i < N; ++i)
	partialSum += D[i]
	average = partialSum / M
	partialSum -= D[i-(M-1)] 	
```

위와 같은 알고리즘은 선형시간(linear) 알고리즘이다. 정확한 시간복잡도는 $O(M -1 + (N-M +1))$이다.

## 4.3 선형 이하 알고리즘

입력의 크기가 커지는 것보다 수행 시간이 느리게 증가하는 알고리즘들을 선형 이하 알고리즘(sublinear)이라 한다. 

책에서는 사진이 날짜별로 정렬되어 있고 특정 사진을 찾으려고 한다. 매번 확인 할때마다 확인해야 할 사진의 수자 절반씩 줄어든다. 
$$1,000,000 > 500,000 > 250,000 > 125,000 > ... > 3 > 1$$

즉 $log N$의 의미는 즉 주어진 N에 대해서 절반씩 몇번을 나누어야 원하는 N을 찾을까?에 대한 답이다. 

### 이진 탐색

이진 탐색이 하는 일의 정의
binsearch(A[], x) = 오름 차순으로 정렬된 배열  A와 찾고 싶은 값  x가 주어질 때 $A[i-1] < x <= A[i]$인 i를 반환한다. 

대개 배열이나 리스트 구현에서  i번째 위치에 새 원소를 삽입한다는 것은 i번째와 그 이후의 원소들을 뒤로 한 칸씩 밀어내고 들어간다는 뜻

7 , 8, 9, 9 , 10 ... ; 만약 9를 넣을 자리를 찾는 다면? $A[1] = 8 < x <= A[2] = 9$ 이기 때문에 2번째 자리를 반환 

C++ 표준 라이브러리에는 두개의 이진 탐색 함수가 존재, 가장 앞에 있는 것을 반환하는 lower_bound()와 가장 뒤의 것을 반환하는 upper_bound()

## 4.4 지수 시간 알고리즘

### 다항 시간 알고리즘
변수 $N$N과 $N^2$, 그 외의 거듭제곱들의 선형 결합으로 이루어진 식들을 다항식이라고 부른다. 
다항 시간이라는 분류에 포함되는 알고리즘 간에는 엄청난 시간 차이가 날 수 있다. 
$N^2, N^3, ..., N^{100}$ 도 다 같은 다항시간이다. 그런데 이런 부류를 묶은 이유는 이런 다항 시간 알고리즘보다 더더욱 오래 걸리는 알고리즘들이 있다. 

### 지수 시간 알고리즘
$2^N$ 과 같이 지수함수는 알고리즘의 전체 수행시간에 엄청난 영향을 미친다. N이 하나 증가할때마다 시간이 배로 증가하는 알고리즘을 지수시간(exponential time)에 동작한다고 한다. 

## 4.5 시간복잡도

시간 복잡도(time complexity)
: 가장 널리 사용되는 알고리즘의 수행시간 기준 
알고리즘의 기본적인 연산 수를 입력의 크기에 대한 함수로 표현한 것

* 시간 복잡도가 높다 = 입력의 크기가 증가할때 알고리즘 수행시간이 더 빠르게 증가한다는 뜻
* 시간 복잡도가 낮다 = 입력의 크기가 커지면 알고리즘 수행시간이 더 효율적이다라는 뜻

사실 시간 복잡도가 낮다고해서 언제나 빠르게 동작하는 것은 아니다. 입력의 크기가 충분히 작을 때는 시간 복잡도가 높은 알고리즘이 더 빠르게 동작 할수도 있다 .


기본적인 연산
: 더 이상 쪼개지지 않는 최소 단위의 연산

>기본적인 연산의 예  
두 부호있는 32비트 정수의 사칙연산
두 실수형 변수 대소 비교

>기본적인 연산이 아닌 예
정수 배열 정렬하기, 두 문자열이 서로 같은지 확인하기
반복문을 포함하기 때문에 기본적 연산이 아니다.


### 입력의 형태에 따른 수행 시간의 변화

입력의 크기가 수행 시간을 결정하는 유일학 척도는 아니다. 입력의 형태도 수행 시간에 영향을 미친다. 예를 들어, 배열을 넣는데 찾고자 하는 값이 맨 앞에 있을수도 있고, 맨 뒤에 있을 수도 있다. 

이와 같이 입력의 따라 수행시간이 달라지는 경우를 고려하기 위해, 최선, 최악 그리고 평균 수행시간을 각각 따로 계산한다. 

최선(best case) : 주어진 입력이 알고리즘의 최단 수행 시간 만큼 걸리는 케이스
최악(worst case) : 주어진 입력이 알고리즘의 최장 수행 시간 만큼 걸리는 케이스
평균(average case) : 주어진 입력이 알고리즘의 평균 수행 시간 만큼 걸리는 케이스

단순 선형 탐색에서는 평균 수행 횟수는 $N/2=  (1 + 2 + ... + n) / n$ = (첫번째로 답을 찾는 연산 수 + 두번째로 답을 찾는 연산수 + .... + n번째로 답을 찾는 연산수) / n == 평균 연산 수행 횟수

주로 사용하는 것은 최악의 수행 시간 또는 평균 수행시간을 사용한다.  

### 점근적 시간 표기: O 표기

시간 복잡도는 알고리즘 수행 시간을 표기하는 방법이지만,  알고리즘의 분석하여 실제로 정확한 시간복잡도를 계산하기는 너무 힘들다. 그래서 수행시간에 큰 영향을 미치는 부분만 표기하는 표기 방법이 고안되었다.

### O 표기법(Big - O notation, Big O)
O 표기법은 특정 알고리즘의 시간 복잡도를 상한으로 나타낸다는 의미. 
대문자 O 표기법(Big-O notation) : 알고리즘 수행시간의 표기법 중 하나. 
n(데이터 입력크기)에 대한 실제 연산회수 함수 $f(n)$이 존재한다.  함수 $f(n)$에 대해 $f(n) = O(g(n))$라고 쓰는것은 아래와 같은 의미
``` 
적당한 n(n ∈ N)과 C(c > 0)에 대해, n 보다 크거나 같은(n <= N)인 
모든 N에 대해 |f(N)| <= C * |g(N)|이 성립
```
![](https://t1.daumcdn.net/cfile/tistory/276E894E559798A516)

>Example 1
$N^3  <= C * (N^2 ) --> N^3  !=  O(N^2)$// C는  N 보다는 작다.
$N^3  <= C * (N^3 ) --> N^3 =  O(N^3)$
$N^3  <= C * (N^4 ) --> N^3  =  O(N^4)$

>Example 2
$2N^3 + N^2 + N  <= C * (N^2 ) --> 2N^3 + N^2 + N  !=  O(N^2)$ // C는  N 보다는 작다.
$2N^3 + N^2 + N   <= C * (N^3 ) --> 2N^3 + N^2 + N =  O(N^3)$
$2N^3 + N^2 + N   <= C * (N^4 ) --> 2N^3 + N^2 + N  =  O(N^4)$
...

실제 연산회수$(f(N))$을 O 표기를 통해 연산회수의 상한을 나타낼수 있다. 
어떤 알고리즘의 연산횟수 f(N)에 대해 ...
$f(N) = O(n^3)$ : 최대 $n^3$ 시간 복잡도를 가진다.  
$f(N) = O(nlogn)$ : 최대 $nlogn$ 시간 복잡도를 가진다.  

### Ω 표기법(small - O notation, Big Omega)
Ω 표기법은 함수의 하한을 나타낸다는 의미. 앞에서  O 표기법과는 반대되는 개념.

n(데이터 입력크기)에 대한 실제 연산회수 함수 $f(n)$이 존재하고, 함수 $f(n)$에 대해 $f(n) = Ω(g(n))$라고 쓰는것은 아래와 같은 의미

![](https://t1.daumcdn.net/cfile/tistory/2416234D55979CF032)
``` 
적당한 n(n ∈ N)과 C(c > 0)에 대해, n 보다 크거나 같은(n <= N)인
모든 N에 대해 |f(N)| >= C * |g(N)|이 성립한다.
```
위의 빅오 정의와 다른 점은, 부등호의 방향이 반대

> Example 1
$N^3  >= C * (N^2 ) --> N^3 =  Ω(N^2)$
$N^3  >= C * (N^3 ) --> N^3 =  Ω(N^3)$
$N^3  >= C * (N^4 ) --> N^3  !=  Ω(N^4)$ // C는  N 보다는 작다.

실제 연산회수$(f(N))$을 $Ω$표기를 통해 연산회수의 하한을 나타낼수 있다. 
어떤 알고리즘의 연산횟수 $f(N)$에 대해 ...
$f(N) = Ω(n^3)$ : 최소 $n^3$ 시간 복잡도를 가진다.  
$f(N) = Ω(nlogn)$ : 최소 $nlogn$ 시간 복잡도를 가진다.  

O표기법과 관계를 표현하면 ...
$f(n) = O(g(n))$ 이면 $g(n) = Ω(f(n))$
특정 알고리즘의 시간 복잡도 $f(n)$의 최대는 $g(n)$,  최대 복잡도 $g(n)$의 최소는 $f(n)$

>Example 1
$N^3 = O(n^3) --> N^3 = Ω(n^3)$
$N^3 = O(n^4) --> N^4 = Ω(n^3)$
$N^3 = O(n^5) --> N^5 = Ω(n^3)$

f(n) = Ω(g(n)) 이면 g(n) = O(f(n))
> Example 1
$N^3 = Ω(n^3) --> N^3 = O(n^3)$
$N^3 = Ω(n^2) --> N^2 = O(n^3)$
$N^3 = Ω(n^1) --> N^1 = O(n^3)$
... 

예외적으로 상수번 만큼의 연산만이 필요한 알고리즘의 경우, 예를들어 $42 = O(1)$ 로 표현할 수 있다.  이러한 알고리즘을 카리켜 상수 시간(constant-time) 알고리즘이라고 한다. 

### 빅 세타 표기법(Big θ notation)
θ 표기법은 함수의 상한과 하한을 동시에 나타낸다.
n(데이터 입력크기)에 대한 실제 연산회수 함수 $f(n)$이 존재하고, 함수 $f(n)$에 대해 $f(n) = θ(g(n))$라고 쓰는것은 아래와 같은 의미

![](https://t1.daumcdn.net/cfile/tistory/2307BA4A55979DBA23)
``` 
적당한 n(n ∈ N)과 C1, C2(c1, C1 > 0)에 대해, n 보다 크거나 같은(n <= N)인
모든 N에 대해 C1 * |g(N)| <= |f(N)| <= C2 * |g(N)|이 성립한다.
```

>Example 1
$C1 * N^2 <= N^2  <= C2 * (N^2 ) --> N^2 =  θ(N^2)$
...

실제 연산회수$(f(N))$을 θ 표기를 통해 연산회수의 상환과 동시에 하한을 나타낼수 있다. 
어떤 알고리즘의 연산횟수 f(N)에 대해 ...
$f(N) = θ(n^3)$ : 최소 $n^3$ 그리고 최대 $n^3$ 시간 복잡도를 가진다.  
$f(N) = Ω(nlogn)$ : 최소 $nlogn$ 그리고 최대 $nlogn$시간 복잡도를 가진다.  

## 4.6 수행시간 어림짐작하기

프로그래밍 대회의 시간 제한은 알고리즘의 시간 복잡도가 아니라 프로그램의 실제 수행시간을 기준으로 한다. 
따라서 프로그램 작성전에 입력의 최대 크기와 알고리즘의 시간 복잡도를 보고 수행시간을 어림 짐작 할 수 있어야 한다. 

입력의 최대 크기 N과 테스크 케이스를 푸는데 시간 제한이 주어졌을때, 만든 알고리즘으로 시간 내에 문제를 풀수 있을지 어림 짐작하는 방법이 있다. 
알고리즘 대회에서 많은 참가자들이 사용하는 주먹구구 법칙 

```
 입력의 크기를 시간 복잡도에 대입해서 얻은 반복문 수행 회수에 대해,
 1초당 반복문 수행 회수가 1억(10^8)을 넘어가면 시간 제한을 초과할 가능성이 있다.
```
$O(N^3)$ 알고리즘 : 
최대 입력 크기를 10000($10^4$)을 주면, 1억을 초과한다.
<!--stackedit_data:
eyJoaXN0b3J5IjpbMzUyNzA0NDU0LC0xOTg1OTEyNjIzLC03ND
MwNDYxNjUsLTE2Nzg5OTg2OTcsMjE5MjAzMTgxLC0xMzY2MDI0
MjQ3LDU1ODY4ODY0LC0xNTkyMDQyMDE0LC0yNzY5ODkxMl19
-->