# 통계학의 실천은 기본부터 - '평균'과 '비율'

어떤 사건의 원인과 결과(인과 관계)를 통찰하려면, 다음 세 가지 지혜를 갖춰야 한다. 
* 평균과 비율 등 통계 지표의 본질적인 이해
* 데이터를 점이 아닌 구간으로 이해
* 무슨 값을 어떻게 정리해야하는지 아는 지혜

## 평균의 본질

다수의 데이터에서 전체 현상 파악을 위한 값을 전문용어로 대푯값이라고 한다.  조심해야 할 점은 대표값에는 일반적인 평균값만이 있는 것이 아니다. 중앙값(median)이나 최빈수(mode)도 있다. 

* 중앙값(median)
	* 데이터를 나열했을때 정중앙 위치에 있는 값
	* 예를들어, 9개의 데이터가 있으면 나열했을때 중앙인 5번째 값을 말한다. 8개의 데이터 일땐 4번째와 5번째 데이터의 평균값이 중앙값이다. 
* 최빈수(mode)
	* 가장 출현빈도가 높은 값

### 대푯값을 둘러싼 수학자들의 연구

옛날 천문학 관측 도구에서 얻어지는 측정 결과는 굉장히 오차가 컸다. 그래서 측정이 정확하다고 가정할 경우, 본래 천체의 위치를 나타내는 참값이 어디있는지 수학적으로 밝히려고 노력했다. 

불규칙성이 있는 데이터에서 참값을 계산하려면 참값과 참값에서 벗어난 값을 분류해 참값에서 벗어난 값을 최소화 해야 한다고 생각했다. 즉 신뢰할수 있는 참값은 어떤 값이 참값이라고 가정했을때 얻어진 데이터 값과 가정한 참값 사이에 차이가 최소라고 보는 사고 방식이다. 

가정한 참값과 데이터 값 차이의 절대값의 총합을 최소화하는 값이 바로 나열하였을때 중앙의 값인 중앙 값을 말했다. 그런데 절대값의 합계를 최소화 한다는 방식은 수학적으로 계산 작업이 너무 번잡스러웠다. 그래서 가우스는 최소제곱법(least of squares)을 사용하게 되었다.

최소 제곱법은 간단히 말하자면, 절대값 대신 제곱을 사용하는 것이 낫다는 이야기다. 예를 들어 차이가 -2만큼 난다면 절대값이 2가 아니라 제곱인 4로 나타낸다는 것이다. 이러한 제곱으로 나타낸 차이의 합을 최소화하는 참값을 추정하는 법이 최소 제곱법이다. 

최소 제곱법에 기초하여 불규칙한 데이터에서 참값을 추정할때는 평균을 사용하는 것이 가장 적절한 추정방법이 된다. 최소제곱법에 기초하면 계산상의 복잡성을 제거할 수 있고 평균값이 중앙값보다 뛰어난 이유를 가우스는 수학적으로 밝혀 냈다. 

일반적으로 평균을 데이터의 값을 전부 더한 다음 총 개수로 나누는 계산 과정으로 이해하지만 다음 문장을 꼭 기억해 두자
`평균은 최소제곱법에 기초하여 측정값에 포함되어 있는 차이를 가장 적게 만드는 뛰어난 추정값이다.`

### 평균과 비율의 차이 

평균과 비율은 기본적으로 완전히 동일한 개념이다. 숫자로 표현되는 정보(양적변수, quantitative variable)는 평균이라 부르고 문자로 표현되는 정보(질적변수, qualitative variable)는 비율이라 한다.

예를 들어, 100명을 조사하여 60명이 남성이라면, 남성의 비율은 60%라는 결과가 나온다. 남성이라는 질적 변수로 비율을 계산하는것은 문제가 없다. 이번에는 남성의 수라는 양적 변수를 가지고 생각해보자. 남성인 사람은 양적 변수 1을 가지고 아닌 사람은 양적변수 0을 가진다. 즉 60 / 100이라는 남성 수의 평균값은 0.6이다.  

다시 말해, 비율과 평균은 전혀 다른 계산법이 존재하는게 아니다. 수의 형태로 표현할 수 없는 질적 변수에 대해서 각 분류마다 1 또는 0이라는 양적 변수로 취급하여 평균을 계산하는 것이다. 

1이나 0 같은 형태로 표현할 수 있는 변수에 대해 양적변수와 질적변수의 특징을 모두 가지는 특별한 경우로 생각할 수 있고 두개의 값만 가진다는 의미에서 이항 변수라고도 부른다. 

## 데이터를 점이 아닌 구간으로 이해 

여기서 점이란 평균 또는 비율을 나타낸다. 우리는 무수히 많은 데이터가 있을때 데이터의 중심을 나타내는 단 하나의 점으로 전체를 이해하려고 한다. 하지만 이는 실제로 무수히엄청나게 많은 데이터정보를 무시한 결과를 초래할 가능성일수도 있다. 

예를 들면, 임의의 사람 집단에서 평균 나이가 20살이라고 해도, 스무살 전후의 사람만 모았는지 마흔 살 전후 부모와 한 두살 남짓의 영유아를 반반 썩었는지 전혀 알수 가 없기 때문이다. 때문에 통계학에서 **데이터는 대체로 어디에서 어디까지 범위에 속해 있는가 하는 식의 구간으로 데이터를 파악하는 방법**을 고안해 냈다. 

## 어떤 항목을 어떻게 정리해야하는지 아는 지혜(원인과 결과 항목을 줄여라)

실제 세상에는 무수히 많은 항목이 존재하고 그 중에서 어떤 원인이 결과 에 어떤 영향을 주는지 알고 싶다. 

우리가 최종적으로 알고 싶거나 조절하고 싶은 결과를 저자는 아웃컴(성과지표; outcome)이라 한다. **아웃컴은 여러 항목 중에서 무엇을 최대화 혹을 최소화 해야하는지 목표의식이 철저히 내재되어 있는 항목을 말한다.** 의학에서는 사망률, 발병률 등이 될수 있고  비즈니스에서는 기업 매출, 적자와 같이 최대화하거나 최소화 해야하는 항목 등이 된다. 

아웃컴에 영향을 미칠 수 있거나 차이를 설명할 수 있는 요인을 설명 변수(explanatory variable)라고 한다. 설명 변수는 다른 분야에서는 결과변수, 목적변수, 종속변수 그리고 외적기준이라는 말로 쓰이기도 한다. 

# 분포

## 정규분포(Normal Distribution)

자연계의 대다수의 데이터는가 경험적으로 보았을때 정규분포를 따른다. 

>중심극한정리(Central Limit Theorem, CLT)
>대다수 데이터가 정규분포를 따른다는 말은 어떤 데이터가 정규분포를 따르지 않는다고 해도 데이터값을 거듭 추가 할수록 정규분포에 수렴하기 마련임을 뜻한다. 이런 현상을 중심 극한 정리라고 한다. 

원래 데이터가 평균값 부근에 볼록한 정규분포를 따르지 않는다고 해도 데이터를 지속적으로 추가하면추가하여 생성된 값은 중심(평균값) 부근으로 모이고 좌우대칭의 완만한 곡선을 그리게 된다. 

통계학을 조금 아는 사람에게 혼란을 주는 분포 성질이 있는데 그것은 아래와 같다.
`본래 원시 데이터 자체는 정규분포가 아니지만 적당히 계산된 평균값은 정규분포를 따른다.`

원시 데이터의 실제 분포 현상 파악을 위한 관점이라면, 적당히 계산된 평균값으로 만든 정규분포를 보는것이 아니라 원래 원시데이터의 분포를 보는 것이 맞다. 하지만 인과관계의 통찰이라면, **적당한 평균값으로 정규분포를 따르는 데이터로 다루는 게 가능하다.** 

원시 데이터의 불규칙성과는 상관없이 데이터를 뽑아 평균값 계산을 수차례 반포한 데이터는 중심극한 정리에 기초하여 정규분포에 수렴한다. 따라서 원시 데이터가 정규분포를 따르지 않는다고 해도 적당한 평균값을 계산하여 정규분포를 따르도록 수정이 가능하다. 

## 사분위점, 분산, 표준편차

**사분위점**은 데이터를 특정 항목 값으로 나열한 후, 전체 데이터의 갯수를 4등분한 위치에 있는 특정 값들을 통칭하는 말이다.
* 전체 데이터의 갯수가 n이고, 갯수가 4로 나누어질때
	*  25%점 : Data[n * 1/4]
	*  75%점 : Data[n * 3/4]
	*  50%점(중앙값) : (Data[n * 2/4] + Data[(n * 2/4) + 1]) / 2
* 전체 데이터의 갯수가 4로 나누어지지 않을 때,
	*  25%점 : RoundUp(Data[n * 1/4]) //올림
	* 75%점 : RoundUp(Data[n * 3/4]) //올림
	* 50%점(중앙값) : (Data[n * 2/4] + Data[(n * 2/4) + 1]) / 2

**분산(Variation, V)** 은 데이터의 불규칙성이 얼마나 되는지 판단할 수 있는 값이다. 분산은 관측값에서 평균을 뺀 값을 제곱하고, 그것을 모두 더한 후 전체 갯수로 나눠서 구한다. 관측값과 평균의 차이를 **편차(deviations)** 라 하고 이것을 제곱한것을 **편차제곱(squared deviations)** 이라 한다. 분산은 바로 이 편차제곱의 평균을 말한다. 참고로 편차제곱을 모두 합친 값을 **편차제곱합(SS; sum of squared deviation)** 이라고도 한다. 

분산은 크게 모분산과 표본분산으로 나누어진다. 모 분산(population variance; $σ^2$) 은 모집단의 분산이다. 관측값에서 모 평균(population mean; $μ$)을 빼고 그것을 제곱한 값을 모두 더하여 전체 데이터 수(모집단의 크기) $n$으로 나눈 것이다. 
$$V(x)= \cfrac{1}{n}∑_{i=1}^n(x_i - μ)^2$$
$μ$는 통계학에서 관례적으로 데이터를 무한히 모으면 알수 있는 진정한 평균(mean)을 알파벳 m에 대응하는 그리스 문자 뮤($μ$)를 사용하여 나타낸다. 

모든 데이터를 더하고 데이터의 수로 나누는 과정을 기댓값(Expectation; $E(x)$)을 구한다. 따라서 분산은 아래처럼도 표현된다.
$$V(x) = E((x - μ)^2) = E((x - E(x))^2)$$
또한, 기대값의 정의를 다시 잘 생각해보면 취하는 값 * 그 값이 될 확률의 합으로도 나타낼수 있다. 
$$E(x)=  \cfrac{1}{n}∑_{i=1}^nx_i =  ∑_{i=1}^nx_iP(x_i)$$
정리하자면 모분산 $σ^2$은 아래와 같이 표현이 가능하다. 
$$σ^2 = V(x)= E((x - μ)^2) = ∑_{i=1}^n(x_i-μ)^2P(x_i)$$ 

$σ$는 시그마라는 그리스 문자이며 알파벳 s에 대응한다. 앞서 그리스 문자 뮤($μ$)와 같게 데이터를 무한히 모으면 알수 있는 진정한 분산을 나타낼때 $σ^2$을 사용한다.

**표준편차(Standard Deviation, SD)** 는 분산을 직감적으로 쉽게 표현한 것이다. 분산은 실제 데이터와 참값의 차이(편차)의 제곱의 평균이기 때문에 이 제곱을 처리하기위해 root($\sqrt {}$)를 씌운다. 분산에 $\sqrt {}$를 씌운값이 바로 표준편차이다. 

평균값과 표준편차를 활용하면, 사분위점처럼 대략 특정 부근에 데이터가 존재유무를 파악할 수 있다. 데이터 자체가 정규 분포를 따른다면 평균값 - SD와 평균값 + SD인 값의 범위에서 전체 데이터의 약 68.3 %가 포함된다. 평균값 - 2SD와 평균값 + 2SD인 값의 범위에서 전체 수험자의 약 95%가 포함된다.  이 내용은 사실 아래의 표준 정규분포와 매우 밀접한 관련이 있다.

**표준 정규분포표(Standard Normal Distribution)** 는 원래 정규분포를에 평균과 표준편차를 활용하여 표준화한 분포이다. 표준 정규분포는 반드시 평균이 0이고 표준편차가 1이다.
$$Z = \frac {X-μ}{σ}$$ 

위의 식이 소위 Z 표준화이다. 표준 정규분포표를 보면 Z 값이 1일때 0.8413 값을 가진다. 따라서 Z값이 -1 <= Z <= 1일때 전체 데이터의 68%정도가 해당 범위에 포함된다. 따라서 평균과 표준편차가 주어진 정규분포가 주어지면, 특정 값이 대략 어디 부근에 존재하는지 파악할 수 있다. 

# 표준오차, 가설검정

## [제 1종과 제2종 오류](https://support.minitab.com/ko-kr/minitab/18/help-and-how-to/statistics/basic-statistics/supporting-topics/basics/type-i-and-type-ii-error/)

통계학에서는 가설이 올바른지 판단하기 위한 분석방법을 일반적으로 검정(통계적 가설검정)이라고 한다.  어떤 사건이 우연히 발생했다고 생각하기 어려운 차이를 **유의한 차이(Significant Difference)** 또는 유의차라고 한다. 
매출 1000원 정도의 차이가 생기는 이유를 밝혔다고 하더라고 일반적으로 이게 의미 있다고는 하지 않는다. 하지만 통계학적으로는 유의한 차이를 보인다고 한다. 

통계학에서는 가설 검증과정에서 범하는 오류를 크게 1종 오류와 2종 오류로 나눈다.

**1종 오류(α error)** 는 가설이 참인데 참인 가설을 기각하는 오류를 범하는 것이다. 즉 참인 가설이 존재하지만 인식을 못하고 놓쳐버리는 실수이다. 다.

1종의 오류의 허용 수준을 가리켜 **유의수준(level of significance)** 이라고 한다. 쉽게 이야기하면 유의수준이란 가설 검정시 제1종 오류를 범할 확률이과 같다. 유의수준이 0.05이면 참인 가설을 잘못 기각할 가능성이 5%임을 인정하는 것이다. 

**2종 오류(β error)** 는 가설이 거짓이지만, 옳다고 채택하는 오류이다. 즉 거짓 가설을 보고 참이라고 인식을 하는  경우이다. 

**검정력(power of test)** 은 검정이 잘못된 가설을 올바르게 기각하는 정도 또는 확률이입니다. 검정력이 좋아지게 되면, 2종 오류(β error)를 범할 확률은 작아지게 된다. 

1종 오류와 2종 오류는 서로 이율배반적 관계이다. 이율배반적이란 말은 하나가 참이면 다른 하나는 무조건 거짓이 되는 관계를 말한다. 

||Negative(채택) | Positive(기각)|
|--|--|--|
|False(가설이 거짓)  | 2종 오류 | 검정력 = 1-(2종 오류)|
|True(가설이 참)  |   1-(1종 오류 ;유의수준)| 1종 오류(유의수준) |

설정된 유의 수준에서 가장 검정력이 높은 분석 방법을 최대 검정(most powerful test)라고 한다. 

## 오차(Error)

만약 데이터 표본이 많다면, 한 두 표본의 변화가 전체의 큰 영향을 주지 않는다. 그러나 표본이 적은 상황에서는 작은 표본의 변화가 큰 영향을 준다. 이 한정된 데이터를 통해 얻어진 평균 또는 비율이 참값에서 어느정도로 벗어나 있는지 나타내는것이 통계학적 의미의 오차다.

### 표준오차(표본 평균의 표준편차, Standard Error, SE)

표준오차를 이해하기 위해선 먼저 표본 평균을 이해해야 한다. 표본은 원시 데이터 전체 중 일부만 추출하여 만든다. 또한, 표본의 갯수를 전문용어로 표본 크기라 한다. 표본 평균이란 말 그대로 원시 데이터 전체의 평균이 아니라 표본의 평균을 말한다. 보통 표본의 평균을 $\bar x$와 같이 상단에 막대를 붙여서 표현한다. 표준오차($σ(\bar x)$)란 표본평균의 표준편차를 말한다. 

$$σ(\bar x) = \cfrac {σ}{\sqrt{n}} = \cfrac {원시 데이터의 표준편차}{\sqrt{표본크기}}$$

위 관계식을 증명하기 위해 앞서 논했던 기대값을 이용한다. 기댓값의 표현은 통계학 증명에서 많이 사용하고 대표적 공식 세 가지만 소개한다.
두 종류의 데이터 $x, y$가 같은 갯수로 존재할때, 아래 공식이 성립한다.
> $E(x+y) = E(x) + E(y)$
> $=\cfrac{1}{n} ∑_{i=1}^n(x_i + y_i) = \cfrac{1}{n}∑_{i=1}^nx_i + \cfrac{1}{n}∑_{i=1}^n y_i$
 
> $E(ax) = aE(x)$
>$=\cfrac{1}{n} ∑_{i=1}^nax_i = a\cfrac{1}{n} ∑_{i=1}^nx_i$

> $E(xy) = E(x)E(y)$  
> $=\cfrac{1}{n^2} ∑_{i=1}^nx_i∑_{j=1}^ny_j = \cfrac{1}{n} ∑_{i=1}^nx_i \cfrac{1}{n}∑_{j=1}^ny_j$
> $E(xy)$는 $(x_1 + x_2 + ... + x_n)(y_1 + y_2 + ... + y_n)$의 기댓값

위 세가지 공식을 사용하면, 추가적으로 분산의 가법성이라는 성질을 증명할 수 있다. 분산의 가법성은 서로  같은 갯수의 데이터가 존재한다면, 데이터를 모두 더한 값의 분산은 원래 각 분산을 더한 것과 같다는 것을 말한다.
>$$V(x+y) = V(x) + V(y)$$

[분산의 가법성 증명]
$$V(x+y) = E((x+y-E(x+y))^2)$$$$=E((x+y-E(x) -E(y))^2) = E((x-E(x)+y-E(y))^2) //x-E(x)와 y-E(y)를 묶어$$$$=E( (x-E(x))^2 + 2(x-E(x))(y-E(y)) + (y-E(y))^2)$$$$=E( (x-E(x))^2) + 2E((x-E(x))(y-E(y))) + E((y-E(y))^2)$$

그런데 여기서 $E((x-E(x))^2) = V(x), E((y-E(y))^2) = V(y)$ 이므로 ...

$$=V(x) + 2E((x-E(x))(y-E(y))) + V(y)$$$$=V(x) + 2E(xy-xE(y)-yE(x)+E(x)E(y)) + V(y)$$$$=V(x) + 2(E(xy)-E(x)E(y)-E(y)E(x)+E(x)E(y)) + V(y)$$$$=V(x) + 2(E(x)E(y)-E(x)E(y)-E(y)E(x)+E(x)E(y)) + V(y)$$$$= V(x) + V(y)$$

또한, 분산은 데이터를 제곱한 상태로 생각하는 지표이므로 $x$를 $a$원시 데이터 $x$를 $a$배 한 $ax$값의 분산을 생각하면, 아래 식이 성립한다.
> $$V(ax) = a^2V(x)$$

$$V(ax) = E((ax - E(ax))^2) = E((ax-aE(x))^2)$$$$E((a(x-E(x)))^2) = E((a(x-E(x)))^2)$$$$= E(a^2(x-E(x))^2) = a^2E((x-E(x))^2)$$$$= a^2V(x)$$

주의할점은 원시 데이터 중에서 표본으로 삼은 $n$개의 표본이 여기서 모집단이 된다는 점이다. 이제 표준오차($σ(\bar x)$)를 진정한 표준편차($σ$)와 표본크기($n$)와 관계로 표현해보자. $V(\overline{x})$의 의미는 $n$개의 데이터로 만든 평균의 분산을 말한다.

$$V(\overline{x}) = V(\cfrac {x_1 + x_2 + ... + x_n}{n})$$$$V(\cfrac {x_1 + x_2 + ... + x_n}{n}) = V(\cfrac{1}{n}({x_1 + x_2 + ... + x_n}))$$$$=\cfrac{1}{n^2}V({x_1 + x_2 + ... + x_n})$$$$= \cfrac{1}{n^2}(V({x_1) + V(x_2) + ... + V(x_n)}))$$

모분산($σ^2$) 정의에 따라 아래 식이 성립한다.
$$σ^2= \cfrac{1}{n}((x_1 - μ)^2 + \cdots + (x_n - μ)^2)$$$$nσ^2 = (x_1 - μ)^2 + \cdots + (x_n - μ)^2 = V(x_1) + V(x_2) + \cdots + V(x_n)$$

>$$\cfrac{1}{n^2}(V({x_1) + V(x_2) + ... + V(x_n)})) =\cfrac{1}{n^2}(nσ^2) = \cfrac{σ^2}{n} = V(\overline{x})$$

마지막으로 표준오차($σ(\overline{x})$; SE)는 $V(\overline{x})$에 $\sqrt{}$를 씌운것이다. 
$$σ(\overline{x}) = \sqrt{V(\overline{x})} = \sqrt{\cfrac{σ^2}{n}}= \cfrac{σ}{\sqrt n}$$

표준편차(σ)는 모든 원시 데이터 전체에 대한그 자체의 불규칙성을 나타내는 지표이다. 그에 비해 **표본으로 산출한 평균에 대한 표준편차**를 표준오차라고 부른다. 표본 집합에서 얻어진 평균값의 불규칙성은 반드시 원시 데이터의 불규칙성(표준편차) 작다. 또 표본크기가 커지면 표준오차는 작아진다. 

---
지금까지는 표준오차를 계산하는데 평균을 대상으로 했지만 이번에는 비율에 적용시켜 보도록 하자. 비율에선 $x$가 0 또는 1값만을 가진다. 그리고 표본의 비율 정의에 따라서 $x=1$인 경우의 확률을 나타낸다. 
$$\cfrac{1}{n}∑_{i=1}^{n}x_i = \cfrac{|\{x_i|x_i = 1 \text{ and } x_i \in x\}|}{n} = P(x=1)$$

정의에 따라 분산을 계산해보자. 
$$V(x) = \cfrac{1}{n}∑_{i=1}^{n}(x_i-μ)^2$$$$=∑_{x=0}^{x=1}(x-μ)^2 p(x) = (0-μ)^2p(0) + (1-μ)^2p(1)$$

만약 $x = 0$ 이면 $μ^2$만 더해지고 $x =1$ 이면 $(1-μ)^2$가 더해진다.  또한, $μ = p(x=1)$는 1이 나올확률이고 반대로 0이 나올확률 $p(x=0)$은 $1-μ$이다.
>$$V(x) = p(1)^2p(0) + p(0)^2p(1) = p(0)p(1)$$

따라서 표본비율의 표준오차는 아래식으로 표현한다.
$$σ(\overline{x}) = \sqrt{\cfrac{σ^2}{n}} = \sqrt {\cfrac {V(x)}{n}}=\sqrt {\cfrac {p(0)p(1)}{n}}$$

# 가설검정

`모든 ~ 는 ... 이다.` 라는 표현은 모든 ~ 에 대해서 칭하다는 의미로 전칭성이 있다고 말한다. 전칭성이 있는 가설을 반증하는 일은 매우 간단하다. 예를들어 `모든 까마귀는 검다`라는 전칭성을 반증하는 방법은 검지 않은 까마귀 한 마리만 가져오면 모든 까마귀가 검지 않다는 것을 증명할 수 있다. 그런데 모든 까마귀는 검다는 것을 증명하려면, 세상 모든 까마귀를 보여주어야 하기 때문에, 일부 까마귀만 가지고는 증명할 수 없다. 이런 상황에서 우리는 가설검정을 한다. 사실 **가설 검정으로 전칭성을 완벽히 증명 할순 없지만, 확률을 도입해 모든이 아닌 거의 모든을 생각하도록 만든다.** 즉 가설검정은 모든 까마귀를 보는 것이 아니라 지금 자신들이 수집할수 있는 데이터 범위에서 가설의 타탕성을 따지는데 초점을 둔다. 

## 귀무가설(歸無假說)

`까마귀는 기본적으로 거의 검다` 라는 가설을 주장하고 싶을때는 우선적으로 자신의 주장에 반하는 가설을 세우고 이야기를 전개한다. 주장하고 싶은 것을 `무로 돌려 보낸다`라고 해서 이 가설을 귀무가설(歸無假說)이라고 한다. 그리고 귀무가설이 성립한다는 가정아래 실제 관측 데이터가 얻어질 확률을 p-값(p-value)이라 한다. 여기서 p는 단순히 확률(probability)의 약자다. 분야에 따라 차이는 있지만 5%미만, 귀무가설 아래 실제 데이터가 나올확률이 5% 미만의 확률이라면, 관례적으로 귀무가설이 틀렸다라고 생각하는 것이 관례다. 위대한 통계학자 피셔가 일찍이 5%로 판단하는 것이 편리하다고 글을 남긴것이 유래가 되었다. 

귀무가설로 까마귀가 검은지 하얀지는 각각 50%의 확률이라고 세웠고, 실제 관측을 통해 100번 연속으로 검은 까마귀가 발견된 관찰 결과가 얻어졌다면 이 관찰 결과가 얻어질 확률은 엄청나게 작다. ($\cfrac {1}{2^{100}}$) 그렇다면 이 귀무가설은 발생할 확률은 엄청나게 작다, 즉 이 가설은 기각하는 편이 자연스럽다. 

## Z검정(Z-test)

`스포츠를 하는 사람들은 출세한다`라는 주장을 하고 싶다고 하자. 주어진 데이터는 총 500명의 직원 정보중에 300명이 대학의 체육 동아리 출신이고 나머지 200명은 기타 동아리 출신이다. 500 명중 100명이 과장 또는 그 이상의 직급에서 소위 출세를 하여 일을 하고 있고 나머지 400명은 평사원이다. 
||  과장이상|직급 없음  | 합계 |
|--|--|--|--|
|체육 동아리| 63명  | 237명  | 300명 |
|기타 동아리| 37명 | 163명 | 200명|
|합계| 100명 | 400명  | 500명|

체육동아리의 출세비율 경우 63/300 = 21%, 기타 동아리의 출세비율은 37/200 = 18.5%이다. 출세비율만 가지고 체육 동아리가 출세한다라고 주장한다면, 굉장히 어리석은 행동이다. 왜냐하면 위의 데이터는 우연한 결과일수 있기 때문이다. 

체육동아리 출신자의 출세율의 표준오차는 아래와 같다. 
$$\sqrt \cfrac{0.21 * (1-0.21)}{300} = 2.35%$$

즉 체육동아리 출세율 21%에 대해 +-2SE의 범위를 생각하면 
16.3(21-4.7)% ~ 25.7(21+4.7)%이고 95%정도의 데이터가 분포한다. 마찬가지로 기타 동아리 출신자 18.5%에 대해 출세율의 표준오차는 아래와 같다.
$$\sqrt \cfrac{0.185 * (1-0.185)}{200} = 2.75%$$

출세율이 13.0(18.5-5.5)% ~ 24.0(18.5+5.5)%에 있을 거라는 건 95% 신뢰구간과 5% 유의수준을 고려하여 올바른 추측이다.

체육동아리 출세율 분포(16.3% ~ 25.7%)와 기타동아리 출세율 분포(13.0% ~ 24.0%는 상당히 많은 구간이 중복되어 있다.  따라서 두 그룹의 비율 차이가 우연한 불규칙성에 의한것인지 아닌지 한눈에 판단하기도 어렵다. 또한 체육 동아리 출신자의 출세율이 최대 25.7%라는 말을 부정할 수도 없고, 기타 동아리 출신자의 출세율이 최소 13.0%라는 것도 부정할 수 없다면, 체육동아리의 출세율이 2배 가까이 높을 가능성도 있다는 말이 아닌가? 왜 이런 의문이 생기는가 하면, 각 그룹의 출세율을 별개로 생각했기 때문이다. 진정으로 우리가 알고 싶은 것은 **어느 그룹이 출세 가능성이 높은가를** 알고 싶은 것이다. 즉, 두 그룹의 출세율을 한꺼번에 아우르는 출세율을 다루어야 하며, 이는 **두 그룹간의 비율의 차이**를 말한다.

### 비율 차이를 판단하는 Z검정

그렇다면 비율 차이로 어떻게  Z검정을 할까? 임의의 그룹 $i$ 에 있는 데이터의 갯수를 $n_i$ 그리고 이 그룹에서 우리가 관심이 있는 특정조건을 만족하는 비율을 $p_i$라고 하두자.

그렇다면 그룹 $i$에 대해  특정조건을 만족하는 비율의 분산한 아래 식으로 표현된다. 
$$V(i) = \cfrac {p_i(1-p_i)}{n_i}$$

Z검정은 서로 다른 두 그룹간의 비율의 차이 ($p_i-p_j$)를 이용하여 검정을 한다.  표현의 편의상 $i$와 $j$를 아닌 $1$, $2$로 표현하겠다. 그러면 두 그룹의 차이의 분산은 아래와 같다. 

$V(p_1 - p_2) = V(p_1 + (-p_2))= V(p_1) +V (-p_2))$
$= V(p_1) + (-1)^2V(p_2)= V(p_1) + V(p_2)$

그리고 두 그룹간에 비율차이가 없다는 귀무가설을 세운다. 비율차이가 없다는 귀무가설에 기초하여 $p_i$는 각 그룹의 조건을 만족하는 비율을 그대로 사용하는 것이 아니라 두 그룹에 공통되는 비율을 생각한다.  즉 양 그룹에 전혀 차이가 없었을 경우, 양 그룹의 공통 비율 ($p$)를 구한다.

$$ p = \cfrac{n_1p_1+n_2p_2}{n_1+n_2}$$

따라서 아래 식이 전개된다.
$$V(p_1 - p_2) = V(p_1) + V(p_2) = \cfrac {p(1-p)}{n_1} + \cfrac {p(1-p)}{n_2}=p(1-p)(\frac{1}{n_1} + \frac{1}{n_2})$$

여기다가 Z 변환을 하여 표준정규분포를 따르게 하고 귀무가설하에 관측된 데이터가 나타날 확률이 유의수준내에 있는지 판단하여 검정을 한다.

$$Z = \frac {p_1-p_2}{\sqrt {V(p_1 - p_2)}}$$

이와 같은 가설검정 방법을 Z검정이라고 한다. 다르게 표현하면, 비율이나 평균, 그것들의 차이는 표본크기가 큰 경우 정규분포를 따른다는 점을 이용하여 특정 관찰 데이터가 불규칙성의 의해 생
기는 것인지 아닌지 생각하는 방법이다. 

자 이제 실제 본문의 데이터에 적용해보자. 

||  과장이상|직급 없음  | 합계 |
|--|--|--|--|
|체육 동아리| 63명  | 237명  | 300명 |
|기타 동아리| 37명 | 163명 | 200명|
|합계| 100명 | 400명  | 500명|

$$ p(공통 추세율) = \cfrac{n_1p_1+n_2p_2}{n_1+n_2} = \cfrac{300*\frac{63}{300}+200*\frac{37}{200}}{300+200} = \frac{100}{500} =0.2$$

$$V(p_1-p_2)= p(1-p)(\frac{1}{n_1} + \frac{1}{n_2}) = 0.2*0.8*(\frac{1}{300} + \frac{1}{200})$$

따라서 양 그룹 출세율 차이의 표준오차는 
$$\sqrt{V(p_1-p_2)}= \sqrt{0.2*0.8*(\frac{1}{300} + \frac{1}{200})} = 3.65%$$


앞서 체육 동아리의 출세율은 21% 였고 기타 동아리는 18.5% 였다. 즉 두 비율의 차 2.5%에 대해서 표준오차가 3.65%라는 말이다. 95%신뢰구간으로 생각하면 두 비율의 차는 -4.8% ~ 9.8%의 비율을 가진다. 이것은 다시 말해, 양쪽 5%유의 수준에서 체육동아리가 9.8%나 출세율이 높다는 가설도 부정할수 없지만, 반대로 기타동아리가 4.8%나 출세율이 높다는 가설도 부정할수 없다는 말이다. 즉 어디가 높은지 낮은지 확실치 않다는 말이다.

좀 더 엄밀하게 이야기 하기 위해서 Z변환을 사용해보자. 양쪽의 출세율의 차이가 없다는 귀무가설하에서 p-값을 구한다면, 실제 얻어진 2.5%라는 출세율 차이를 표준오차 3.65로 나눈 값이 된다. 
$$Z = \frac {2.5- 0; 출세율차이의 평균 }{3.65} = 0.685$$

표준정규분포에서 중심으로부터 표준편차 * 0.685 보다 큰 값이 구해질 확률이 약 25%가 된다. 
다시 말해 양쪽의 출세율에 차이가 없다는 가설하에도 50%의 확률로 그룹간 큰 출세율차이는 나타날 수 있다는 말이다. 

### 평균의 차이도 Z-검정으로 접근할수 있다. 

비율뿐만 아니라 평균값의 차이에 관해서도 마찬가지로 Z검정을 사용하여 우연한 차이인지 의미있는 차이인지 생각할 수 있다.  앞선 이야기와 다르게 출세 비율로 따지는게 아니라 실적 달성의 보수로 지급된 보너스의 많고 적음으로 평가한다고 하자.

||표본 평균보너스|모표준편차|표본 인원수|
|--|--|--|--|
|체육동아리| 80만엔  | 12만엔  | 300명 |
|기타동아리| 78만엔 | 10만엔 | 200명|

각 그룹의 표준편차를 인원수의 루트로 나눈것이 평균값의 표준 오차다. 

$$σ(\overline{x}) = \sqrt{V(\overline{x})} = \cfrac{σ}{\sqrt n}$$


체육과 기타 동아리 출신자 평균 보너스의 표준오차 : $\cfrac {120000} {\sqrt{300}}$, $\cfrac {100000} {\sqrt{200}}$

두개의 값을 분산의 가법성을 이용하면 아래식이 성립한다.

$$V(m_1 - m_2)=V(m_1)+V(m_2)=(\frac {120000} {\sqrt{300}})^2 +  (\frac {100000} {\sqrt{200}})^2$$

$$σ(m_1-m_2) = \sqrt{(\frac {120000} {\sqrt{300}})^2 +  (\frac {100000} {\sqrt{200}})^2}$$

계산을 해보면 대략 9900엔 정도 평균값 차이의 표준오차가 나온다. 즉 2만엔(80-78=2)정도의 평균 보너스의 차이값에 대해서 95% 신뢰구간에서 신뢰 범위는 200엔($20000-2*9900$)에서   39800엔($20000+2*9900$)이다. 두 그룹간의 평균값 차이가 없다라는 귀무가설하에 시행한 검정이지만 95% 신뢰구간이 모두 양의 값을 가진다. 즉 5%의 유의수준안에서 보너스가 만든 적든 체육동아리 출신자의 평균보너스가 거의 항상 높다는 이야기가 된다. 따라서 그룹 평균 보너스에 차이가 없다는 귀무가설은 기각 된다. 

## T-검정

수백건 수천건 이상의 데이터가 각 그룹에 존재한다면, 평균값의 차이가 정규분포를 따른다라고 보고 Z검정을 하면 된다. 그러나 통계학에선 소수의 데이터만 가지고도 평균값의 차이가 우연한 차이인지 생각하는 방법이 존재한다. 이럴때 T-검정을 사용하면 된다. 

정규분포가 아닐지도 모르는 소수의 데이터를 검정하기 위해 T분포라는 것을 생각해내고 그것을 사용하여 검정을 하기 때문에 T검정이라 부르는지도 모른다. T검정을 이해하려면 T분포를 알아야하고 T분포를 이해하려면 $χ^2$카이제곱 분포를 이해해야 한다. 이해를 돕기 위해 다소 극단적인 예를 생각해보자. 본래 정규분포를 따르는 집단에서 추출된 3개의 표본이 모두 진정한 평균값보다 크다라는 확률은 $\frac{1}{2}^3 = \frac{1}{8}$로 적지 않다.  

예를 들어 키의 평균값이 170cm이고 표본은 172cm, 174cm, 176cm라고 하자. 3명의 평균키는 174cm이지만 전정한 평균값으로 부터 벗어난 차이로 분산을 생각해보자. 

$(172-170)^2 + (174- 170)^2 + (176- 170)^2 = 56$ 여기서 3을 나눠 18.7이 얻어진다. 

한편 표본 평균인 174를 기준으로는 $(172-174)^2 + (174- 174)^2 + (176- 174)^2 = 8$ 즉 약 2.7 값밖에 얻어지지 않는다. 또 더 정확하게 불편성을 가진 분산이기 때문에  인원수 -1(3-1) 값으로 나누어도 표본 분산은 4밖에 되지 않는다.

[보충 4] 분산과 불편성을 가진 분산
$n$건의 표본 데이터 $x_1, x_2, \dots x_n$로부터 분산(표본의 분산)은 아래식을 따른다.
$$v = \frac{1}{n}∑_{i=1}^{n}(x_i-μ)^2$$ 하지만 진정한 평균 $μ$ 대신에 우리는 얻어진 표본의 평균 $\bar x$를 사용하여 분산을 계산해야 하는데, 특히 데이터의 수가 적은 경우에는 더 큰 차이가 발생할 수 있다.
$$∑_{i=1}^{n}(x_i-\bar x)^2 = ∑_{i=1}^{n}(x_i-μ + μ - \bar x)^2 = ∑_{i=1}^{n}((x_i-μ)^2+2(x_i-μ)(μ-\bar x)+(μ-\bar x)^2)$$$$=∑_{i=1}^{n}(x_i-μ)^2 + ∑_{i=1}^{n}(2(x_i-μ)(μ-\bar x)+ (u-\bar x)^2)$$ 
여기서 $nv = ∑_{i=1}^{n}(x_i-μ)^2$ 이므로, 
$$= nv + ∑_{i=1}^{n}(x_i-\bar x)^2 = nv + ∑_{i=1}^{n}(2(x_i-μ)(μ-\bar x)+ (u-\bar x)^2)$$$$= nv + ∑_{i=1}^{n}(2μx_i-2\bar xx_i - 2μ^2 + 2μ\bar x + μ^2 -2μ\bar x + \bar x^2)$$$$= nv + ∑_{i=1}^{n}(2μx_i-2\bar xx_i - μ^2 + \bar x^2)$$$$= nv + n\bar x^2-nμ^2 + 2(μ-\bar x)∑_{i=1}^{n}x_i$$$$= nv + n\bar x^2-nμ^2 + 2(μ-\bar x)n\bar x$$$$= nv + n\bar x^2-nμ^2 + 2nμ\bar x - 2n\bar x^2$$$$= nv -n\bar x^2-nμ^2 + 2nμ\bar x $$$$= nv -n(\bar x^2-μ^2 + 2μ\bar x) $$$$= nv -n(\bar x - μ)^2$$
따라서, $$∑_{i=1}^{n}(x_i-\bar x)^2=nv -n(\bar x - μ)^2$$$$\frac{1}{n}∑_{i=1}^{n}(x_i-\bar x)^2 = v - (\bar x - μ)^2$$

μ 대신에 $\bar x$을 사용하면 실제 분산에 비해 $(\bar x - μ)^2$만큼 작아진다. 데이터의 수가 충분히 커서 $\bar x$와 $μ$가 비슷하다면 문제가 없지만 그렇지 않다면 주의해야 한다. 위의 식을 기대값으로 표현하면 아래가 된다.
$$E((x_i-\bar x)^2)=E((x_i-μ)^2)-E((\bar x-μ)^2)$$여기서 우변의 첫번째 항은 그대로 분산 $V(x)=σ^2$이며 두번째 항 $E((\bar x-μ)^2)$은 $\bar x$의 분산이다. 그리고 표본 평균의 표준오차는 $\frac {σ^2}{n}$이다. 
$$E((x_i-\bar x)^2) = σ^2 - \cfrac{σ^2}{n} = \frac{(n-1)σ^2}{n} <=> σ^2 = \frac{n}{n-1}E((x_i-\bar x)^2)$$정리하자면 $μ$ 대신에 $\bar x$을 사용하여 계산할 경우 $(\bar x - μ)^2$을 무시할 수 없다면 $n$으로 나누는 것이 아니라 $n-1$로 나누는 편이 더 정확하다. 이를 바탕으로 데이터의 평균에서 벗어난 값의 제곱합을 n이 아닌 n-1로 나눈 값을 불편성을 가진 분산이라 한다. 
<hr/>

표본의 평균값이 표본을 바탕으로 계산되는 이상 값과 그 평균값은 독립되어 존재할수 없다. 그리고 표본에서 구한 평균값을 사용하면 진정한 평균값을 사용한것 보다 더 한정적 표본내에서는 분산이 더 작아진다. 

피셔는 표본을 통해 얻어진 분산과 표본 크기 사이에 어떤 관계가 있는지 수학적으로 정리하였다. 피셔는 카이제곱 분포를 사용하여 계산에 사용된 표본 크기에 따라 표본 분산과 진정한 분산이 어떻게 달라지는지 계산할수 있다는 사실도 밝혔다. 

**카이제곱분포는 평균값이 0, 분산이 1(즉 표준편차도 1)의 정규분포를 따르는 x라는 변수를 생각했을 때, 자유도 만큼 x를 추출한 각 표본들의 제곱의 총합으로 만들어진 분포다.** 

본래부터 사용되고 있었던 $x$라는 변수의 제곱을 생하기 때문에, $χ^2$ 카이제곱분포라고 이름이 붙여진것 같다. 카이 제곱분포는 모두 더한 x의 제곱수(전문용어로 자유도)에 의해 분포의 형상이 달라지지만, 자유도가 무한대인경우는 정규분포와 완전히 일치하고, 수백에서 수천만큼 큰 자유도에서는 정규분포라해도 문제없는 상태가 된다. 

T분포는 카이제곱분포의 성질에 근거해서 표본크기에 의해 혹은 카이제곱분포의 자유도별로 평균값의 차이가 평균값 차이의 표준오차 몇배 이내로 수용될지 계산하는데 사용한다.

정규분포를 사용한 Z검정에서는 평균값의 차이의 표준오차 1.96배이내로 수용될 확률이 95%라는 성질을 이용했다. 그러나 T분포는 동일한 95%신뢰 구간에서도 그 구간이 약간 넓게 나타난다. 1.96배 표준오차가 아니라 2.31 표준오차다. 한정된 데이터로 부터 산출한 표준오차는 진정한 표준오차보다 조금 오차가 적어지기 때문에 생각해야할 구간은 다소나마 길어진다. 

예를 들어, T분포에서는 두 그룹이 10명씩 총 20명이 존재하는 경우 2.10 표준오차, 총 30명씩 두 그룹이면 2.00 표준오차, 100명씩 총 200명이면, 1.97 표준오차, 250명씩 총 500명이면 정규분포와 마찬가지로 1.96 표준오차가 된다. 즉 표본 크기가 커질수록 Z검정에서 사용하는 표준정규분포를  이것이 수백에서 수천명의 데이터를 다룰줄 알면 Z-검정도 실용적으로 사용하는데 아무 문제가 없다고 말하는 이유다.

[보충 09] $χ^2$카이제곱 분포와 T분포의 관계

Z검정을 위해선 ($Z = \frac {x-μ}{σ}$) 변환을 하지만 현실적으로 분모에 있는 표준편차($σ$)가 가 무한히 있으면 알 수 있는 참값이 아니라 한정된 데이터에서 추측한, 불규칙성을 가진 값이라는 점에서 Z검정보다 T검정을 사용하는것이 당위성이 있다. 

카이제곱($χ^2$)분포란 평균이 0, 분산이 1인 표준 정규분포를 따르는 서로 독립적인 변수를 생각했을때, 이 변수의 제곱을 몇 개인가 더한것이 따르는 분포다. 변수 $x$가 정규분포를 따르는 것을 $x\sim N(μ, σ^2)$이라 표현하는데 

$$χ_n^2 = ∑_{i=1}^{n}x_i^2 \ \ \ (x \sim N(μ, σ^2))$$

위의 식이 $n$개의 표본이  따르는 카이제곱($χ_n^2$) 분포이다. 표준정규분포를 따르는 $x$를 제곱한 $x^2$변수에 대해서 몇 개($n$)를 더했는가에 따라 다른 분포가 되고 여기서 몇 개($n$)를 가리켜 카이제곱($χ^2$) 분포의 자유도($n$)라고 한다. 예를 들어, $x^2$을 3개 더한 카이제곱($χ^2$) 분포라면, 그 자유도는 3이다. 

그러면 적은 수의 표본를 통해 구한 분산이란 무엇일까? 답은  "[보충 4] 분산과 불편성을 가진 분산"이다. $n$건의 표본으로부터 불편성을 가진 분산 $V$는 아래식으로 표된다.
$$V = \frac{1}{n-1}∑_{i=1}^{n}{(x_i-\bar x)^2}$$

앞서 $x$가이 정규분포를 따룬다고 했을 경우, $x$의 평균 $μ$와 분산 $σ^2$를 사용하면 $x$에서 평균을 빼고 표준편차로 나눈 값은 표준 정규분포를 따른다. 그러한 값의 제곱의 합을 자유도 $n$개만큼 더한 $C$는 아래와 같다. 

$$C = ∑_{i=1}^{n}(\frac{x_i-μ}{σ})^2$$$C$는 자유도 $n$의 카이제곱($χ^2$)분포를 따른다. $σ^2$는 진정한 분산을 나타낸다.
$$σ^2C = ∑_{i=1}^{n}({x_i-μ})^2$$만약 $μ=\bar x$이면 우변은 앞선 $V$식으로 표현이 가능하다.
$$V =  \frac{1}{n-1}∑_{i=1}^{n}{(x_i-\bar x)^2} = \frac{1}{n-1}σ^2C$$T검정통계량은 아래식으로 나타낸다. $$T = \frac{\bar x}{\sqrt{V/n}} = \frac{\bar x}{\sqrt{\frac{1}{n(n-1)}∑_{i=1}^{n}{(x_i-\bar x)^2}}}$$$$= \frac{\bar x}{\sqrt{\frac{1}{n(n-1)}σ^2C}} = \frac{\bar x}{σ/\sqrt{n}}\frac{\sqrt{n-1}}{\sqrt{C}}$$$x$의 표본평균($\bar x$)을 표준오차($\sqrt{\frac{V}{n}}$)로 나누는 것은 가장 기본적인 T검정통계량이다. 또한 위의 식은 
$$T= 표준정규분포를 따르는 값(\frac{\bar x}{σ/\sqrt{n}}) * \frac {\sqrt{자유도}(\sqrt{n-1})}{\sqrt{χ^2분포를 따르는 값}(\sqrt C)}$$Z검정의 표준정규분포에서는 고려하지 못했던 표준오차의 불규칙성을 여기서는 고려하고 있다. 단 이것을 이해하기 위해서는 자유도는 무엇인가? 왜 n이 아니라 n-1인가?라는 부분에 대해서 공부를 해야한다. 
 왜 $n$이 아니라 $n-1$인가 문제는 [보충3] 불편성 부분에서 배웠듯 $\bar x$와 $μ$의 차이 때문에 유래한다. $n-1$로 나누 것은 아래 식에서 유래한다.
$$E((x_i-\bar x)^2) = \frac{n-1}{{n}}σ^2$$$$\bar x = \frac{1}{n} ∑_{j=1}^{n}x_j$$ 따라서, $$E((x_i-\bar x)^2) = E((x_i-\frac{1}{n} ∑_{j=1}^{n}x_j)^2)$$
$$E((x_i-\frac{x_i}{n} - \frac{1}{n}∑_{i \neq j}x_i)^2) = E((\frac{n-1}{n}x_i-\frac{1}{n}∑_{i \neq j})^2)$$요컨데 $x_i$ 부분과 그 이외의 부분으로 나누어 놓은 상태다. 또 $n$번째 데이터인 $x_n$에 대해서만 생각해보면, $$\bar x = \frac{1}{n}∑_{i=1}^{n}x_i = \frac{1}{n}(x_n+∑_{i=1}^{n-1}x_i)$$$$x_n = n\bar x-∑_{i=1}^{n-1}x_i$$$$x_n - \bar x = n\bar x-∑_{i=1}^{n-1}x_i - \bar x $$$$= (n-1)\bar x -∑_{i=1}^{n-1}x_i = -∑_{i=1}^{n-1}(x_i-\bar x)$$
요약하면, $x_n-\bar x$는 $x_i - \bar x$에 대해서 $n-1$번째까지 데이터의 총합에 -1를 곱한것이다. 예를 들어 $n=3$인 경우, $$\bar x = \frac{x_1+x_2+x_3}{3}$$$x_1 - \bar{x} = x_1 -\frac{x_1+x_2+x_3}{3}=\frac{3x_1-x_1-x_2-x_3}{3}=\frac{2x_1-x_2-x_3}{3}$
$x_2 - \bar{x} = x_2 -\frac{x_1+x_2+x_3}{3}=\frac{-x_1+2x_2-x_3}{3}=\frac{2x_2-x_1-x_3}{3}$
따라서, $$(x_1 - \bar{x}) +(x_2 - \bar{x}) = \frac{2x_1-x_2-x_3+2x_2-x_1-x_3}{3} = \frac{x_1+x_2-2x_3}{3}$$$$(x_3 - \bar{x}) = x_3 -\frac{x_1+x_2+x_3}{3}=\frac{-x_1-x_2+2x_3}{3}=\frac{2x_3-x_1-x_2}{3}$$이기 때문에 아래식이 성립한다. $$(x_1 - \bar{x}) +(x_2 - \bar{x}) = -(x_3 - \bar x)$$ 같은 관계가 3 이외의 $n$에 대해서도 성립한다. 즉, 
$$∑_{i=1}^{n-1}(x_i - \bar x) = -(x_n-\bar x)$$ 돌아와서 $E((x_i-\bar x)^2)$는 불편성을 가진 분산을 말한다. $x_n$ 부분과 그 외에 부분으로 나누어 표현하면 아래와 같다. $$\frac{1}{n}∑_{i=1}^{n}(x_i-\bar x)^2 = \frac{1}{n}∑_{i=1}^{n-1}(x_i-\bar x)^2+\frac{1}{n}(x_n-\bar x)^2$$ 우변에 두번째 항은 앞서 규칙을 이용해서 변환할 수 있다. $$\frac{1}{n}∑_{i=1}^{n-1}(x_i-\bar x)^2+\frac{1}{n}(-∑_{i=1}^{n-1}(x_i - \bar x))^2$$ 따라서 정리하면 $$E((x_i-\bar x)^2)=\frac{1}{n}∑_{i=1}^{n-1}(x_i-\bar x)^2+\frac{1}{n}(∑_{i=1}^{n-1}(x_i - \bar x))^2$$ 중요한 것은 본래 평균이 0인  n개의 $(x_i - \bar x)^2$의 합에 대해서 평균이 0인 독립적인 n-1개의 $(x_i - \bar x)^2$ 두 항의 합으로 표현이 된다는 것이다. 

그러한 이유는 $\bar x$가 $n$개의 $x_i$로 구성되기 때문이다. 한 $x_i$의 값은 $\bar x$와 $x_i$가 아닌 부분으로 고정이된다. 그리고 이와 같이 다른 값에 의해서 하나의 값이 고정되는 상태를 통계학에서는 "자유도가 하나 줄었다"라고 표현한다. $\bar x$가 $x_n$에 해당하는 값을 독립적으로 표현하는것처럼 어느 하나의 $x_i$의 값은 평균 $\bar x$, $x_i$외의 값으로 고정되기 때문이다. 

평균이 0, 분산이 1인 정규분포를 따르는 n개의 독립적인 데이터가 있을때, 제곱의 합은 당연히 자유도 n의 카이제곱분포를 따른다. 하지만 그 계산과정에서 n개의 데이터에서 구한 평균을 사용하면 자유도가 하나 줄어버리고 자유도 n-1의 카이제곱 분포를 따르게 된다. 

t 분포는 t검정뿐만 아니라 이후의 회귀분석에서도 중요한 의미를 가진며 수십에서 수백건 정도의 적은 데이터를 정확히 분석해야 할때 더 중요하다. 하지만 자유도라는 개념이 통계학에서, 혹은 피셔의 발명 중에서 가장 초심자를 혼란시키는 원인이 되지 않는가 싶다. 

이제 귀무가설로서 세운 '$x$의 평균값($\bar x$)가 0인지 아닌지'를 생각한다. 도대체 왜 평균이 0인지 아닌지를 검정하는거지? 궁금한 사람을 위해 실제 이용방법도 이야기 한다. 
직원들의 올해 - 작년 매출 차이를 계산한 결과로, 플러스인 사람과 마이너스인 사람이 모두 있지만, 전체적으론 증가한 느낌이 드는 경우를 생각해보자. 느낌이 아니라 명백한 증가고 볼 수 있는지 판단하고 싶다면 매출 차이의 평균값이 0인가 아닌가를 T-검정해보면 된다. 

정리하자면, **분산 계산에 쓰인 데이터 수에 의해 자유도가 달라지고 분산의 배후에 있는 카이제곱 분포의 형상도 달라진다.** **분산 계산에 n개의 데이터 평균을 사용하면 자유도는 n-1이다.** 

데이터의 수가 한정돼 있을때는 이 카이제곱분포 형상의 차이에 의해 평균값 / 데이터를 토앻 구한 표준오차라는, 통계적 가설검정에서 반드시 수행하는 계산결과는 정규분포에서 다소 벗어난ㄷ. 그 벗어난 값을 정확하게 생각하기 위해서 표준오차가 따르는 카이제곱 분포의 자유도를 고려한 것이 t  분포이다. 또 당연하지만, 이 t분포를 사용하려면 자유도 얼마인 t분포인가를 생각해야 한다. 

예를 들면, n명씩 있는 두글 ㅂ사시에 평균값의 차이를 생각할때는 사용하는 분포의 자유도는 총 2n의 자유도에서 평균값 2개분의 자유도를 빼고 2n-2 자유도의 t분포를 사용한다. 

### 피셔의 정확검정

데이터의 수가 한정된 경우 쓰이는 피셔의 정확검정
앞선 데이터는 평균에 대해서 논했다. 그렇다면 비율의 차이에 대해 데이터 수가 한정된 경우에는 어떻게 생각해야 할까. 사실 비율 형태로 집약한 어느 상태를 취할지 말지의 이항변수는 평균값으로 집약하는 양적변수보다도 취할수 있는 분포의 형상이나 분산 범위가 제한되어 있으므로 어느 정도는 데이터 수가 적더라도 정규분포에 수렴하기 쉽다. 그러므로 Z검정을 사용하는 타당성을 그다지 신경 쓰지 않아도 된다. 

좀 더 상세하게 말하자면, 두 그룹이 어느 상태를 취하는지의 비율에 차이가 없다는 귀무가설의 상황에서 그룹별 * 어느 상태를 취할까 말까 라는 분할표를 만들경우, 어떤 칸에도 가급적 10, 최저 5 이상의 숫자가 들어가는 경우는 Z검정을 해도 문제가 없다는 것이 관례적으로 허용되는 기준이다. 

예를 들어, 앞서 살펴본 체육 동아리와 기타 동아리 출신자의 출세율이라는 상황, 30명씩 분류된 두 그룹에서 그 그룹할 합계한 전체의 출세율이 40%인경우, 그룹 간 출세율의 차이가 없다는 귀무가설 아래서는 모든 칸에 10이상의 값이 들어가기 때문에 문제가 없다. - 귀무가설 아래서 분할표(Z 검정용)

귀무가설 아래서 분할표(Z 검정용)
||  과장이상|직급 없음  | 합계 |
|--|--|--|--|
|체육 동아리| 12명(40%)  | 18명(60%)  | 30명 |
|기타 동아리| 12명(40%) | 18명(60%) | 30명|
|합계| 24명(40%) | 36명(60%)  | 60명|

두 그룹을 한친 전체 출세율이 단 1%밖에 되지 않는 경우 귀무 가설 아래서 모든 칸에 최저 5 이상이라는 조건을 채우려면 각 그룹에 데이터가 500명씩 없으면 Z검정에서의 정규분포로의 수렴은 적절하지 않게 된다. 예를 들면, 각 그룹에 300명이 있더라도 출세자가 전체에서 6명 밖에 안된다면 Z검정에 맞는 데이터가 아니라고 할 수 있다. - 귀무가설 아래서 분할표(비 Z검정용)

귀무가설 아래서 분할표(비 Z검정용)
||  과장이상|직급 없음  | 합계 |
|--|--|--|--|
|체육 동아리| 3명(1%)  | 297명(99%)  | 300명 |
|기타 동아리| 3명(1%) | 297명(99%) | 300명|
|합계| 6명(1%) | 594명(99%)  | 600명|

이런 상황에서는 피셔의 정확검정 또는 피셔의 직접확률검정을 사용하는 방법이 있다. 정확 혹은 직접확률이란 정규분포의 수렴이 아니라 정확한 확률 계산을 사용하여 p-값을 산출한다는 의미이다. 

||  과장이상|직급 없음  | 합계 |
|--|--|--|--|
|체육 동아리| 4명(66.7%)  | 2명(33.3%)  | 6명 |
|기타 동아리| 1명(25%) | 3명(75%) | 4명|
|합계| 5명(50%) | 5명(50%)  | 10명|

체육 동아리 출신자 6명 중 4명이 과장 이상으로 출세하였고 기타 동아리 출신자 4명 중 1명이 출세 했다는 데이터가 얻어진 경우를 생각해보자. 체육 동아리 출세율은 66.7% 기타동아리의 출세율은 25%로 체육 동아리 출세율이 41.7%가 더 높다. 이 차이는 과연 우연한 불규칙성에 의해 생긴것이라고 할 수 있을까?

체육 동아리 출신자 6명, 기타 동아리 출신자 4명이고, 그 집단에서 출세자가 5명이라고 정해졋을때, 귀무가설을 생각해야 한다. 이 상황에서 각 조합의 확률을 계산하고 얻어진 데이터가 편중이 생길확률, 즉 p-값을 직접 계산하는 것이다. 

[보충 10] 

계산해보면, 출세자 5명 중에서 4명이상이 체육 동아리 출신자가 되는 확률은 26.2%이다. (총 252 방법 중 4명이 체육동아리(60가지), 5명이 체육동아리(6))
다만 이것은 체육 동아리 출세율이 높은 경우만 생각하는 단측 검점 p-값이라는 점에 주의 하자.

양측 검정은 어느쪽으로 치우치지 않은 가설을 세우는 것이다. 앞서 단측 검정의 가설 '체육 동아리의 출세율이 높을 경우만 생각해서는 안되고 두 그룹의 출세율 차이가 있다라고 가정해야 한다. 

체육 동아리의 출세자 수는 1~5명까지 가능하지만, 가장 일어나기 쉬운 결과는 체육동아리 6명 중 3명이 출세하고 기타동이라 4명중 2명이 출세하는 상황이다. 이때 체육 동아리의 출세율은 50%, 기타 동아리도 50%로 두 그룹의 출세율 차이가 없다.

||  체육 기타 출세율 차이|
|--|--|--|--|
|체육 5 기타 0| $\mid \frac{5}{6} \mid$| 
|체육 4 기타 1| $\mid \frac{4}{6}-\frac{1}{4} \mid = \frac{5}{12}$| 
|체육 3 기타 2| $\mid \frac{3}{6}-\frac{2}{4} \mid = 0$| 
|체육 2 기타 3| $\mid \frac{2}{6}-\frac{3}{4} \mid =\frac{5}{12}$| 
|체육 1 기타 4| $\mid \frac{1}{6}-\frac{4}{4} \mid=\frac{5}{6}$| 

체육동아리 6명 중 3명이 출세한 경우를 제외하고는 모두 두 그룹의 출세율의 차이가 있다. 따라서 그러한 경우의 확률을 모두 더하면 총 52.4%(2.4%+23.8% + 23.8%+2.4%)가 양측검정 p-값이다.

다시 말해 단 10명의 데이터에서 체육동아리와 기타 동아리 출신자의 출세율 차이가 우연히 얻어질 확률은 52.4%라는 것이다.  이정도 확률이면 어쩌다가 이런 결과라 나았을지도 모른다고 생각하는게 옳다.

### T-검정에 대해 알아두어야할 특징

- t검정에 의하면 수십건 정도의 데이터로도 정확히 Z검정을 할 수 있으며, 수백에서 수천건의 데이터가 있을 경우 T검정과 Z검정의 결과는 일치한다.
- T검정은 Z검정과 같이 평균값 차이가 평균값 차이의 표준오차의 몇배인가를 생각하고 그러한 상황이 얼마나 발생하기 어려운지를 밝히기 위해 p-값을 구한다.
- 피셔의 정화검정은 조합의 수를 사용하여 수십건 정도의 데이터로도 정확하게 비율의 차이에 의미가 있는지 p-값을 구한다. 

## 다중검정

이제 셋 이상 그룹간에 평균과 비율 차이를 검정하려면 어떻게 하는지 알아보자. 체육 동아리 출신자, 조기 축구 출신자, 스포츠 무경험자 세 그룹 사이에서 평균 보내스 수령액이나 출세율을 비교하여 생각해보자. 

통계학에선 세 그룹 이상을 비교하기 위한 별도의 분석 방법이 있다. 세 그룹 이상의 평균값 차이에 대해선 **피셔의 분산분석**을 사용하는 것이 좋다. 

다른 그룹간 평균값의 불규칙성을 나타내는 분산과 그룹 안에서 얻어진 값의 불규칙서을 나타내는 분산의 비교를 통해 Z검정 또는 T검정과 마찬가지로 그룹간 평균값 차이가 어느정도인지  p-값을 계산할수 있다. 

비율의 차이는 카이제곱분포를 그대로 사용하는 카이제곱검정이 있다. 피어슨이 만든 분석방법으로 2*2분할표에서만이 아니라 셋 이상 그룹 분할표의 편중이 우연히 생기는 수준인지 아닌지 알 수 있다. 

두 그룹간 어떤 상태를 취하는가 아닌가 라는 비율을 생각할때는 Z검정과 카이 제곱검정의 p-값이 완전히 일치한다. 

[보충 11]

사실 분산분석과 카이제곱검정 모두 비즈니스에서 별로 사용되지 않는다. 왜냐하면 검정할 수  있는 귀무가설이 모든 그룹간 평균값의 차이가 전혀 없거나 그룹간 평균값은 사실 완전히 동일하다는 것을 밝히기 때문이다. 다시 말해서 분산분석을 한 결과 p-값이 적어졌다는 것은 모든 동일 하다고 말할수 없다는 정보를 나타내는게 모두다. 

### T검정이나 카이제곱검정의 단순한 반복

그렇다면 두 그룹간검정을 여러차례 반복하는 것은 어떨까?
어떤 그룹간에 유의한 차이가 생겼다라는 결과가 모든 그룹간에 유의한 차이가 없다라고 말하는 분산분석보다 유용하다. 

그런데 세 그룹정도라면 괜찮지만, 그룹의 수가 많아지면 비교해야할 경우의 수가 엄청 많아진다. 그리고  p-값이 5%미만이라는 것은 덜렁이가 될 위험성을 5이내로 억제하자는 의미였는데, 동전 던지기 처럼 독립적으로 덜렁이의 실수를 저지르지 않을 확률이 95%을 계속하다보면, 100번의 비교만 해봐도 실수를 저지르지 않을 확률이 0.95% 밖에 되지 않는다. 즉 판단에 사용하는 p-값이 많을수록 덜렁이 리스크가 상승된다. 단순히 다수 검정을 반복하면 덜렁이 리스크가 커지는 상황을 검정의 다중성이라고 한다.


그러면 덜렁이 리스크를 줄이면서 의미가 있는 분석을 찾는 방법은 무엇일까??

#### 본페로니 방법

여러가설 검정을 한 다음 최종적으로 덜렁이 리스크를 5%로 유지하기 위해 통계분석방법을 사용하는 법이다. 가장 간단한 다중비교법은 p-값별로 유의인가 아닌가 판단 기준으로 5% 유의수준을 검정한 횟수로 나는 값을 사용하는 것이다. 

예를들어, 5회의 검정을 하면 p-값을 5%가 아닌 1%로, 10회 검정이라면 p-값을 0.5%로 하는 것이다.  이 방식은 발명자의 이름을 따 본페로니 방법이라고 부른다. 5%이내로 유지되는 증명은 [보충12]를 보자. 

본페로니 방법을 통해서 덜렁이 리스크가 통제되었다고 해도 무제한 검정을 해도 되는것은 아니다. 왜냐하면 이는 덜렁이 리스크를 너무 신경써서 반대로 멍청이 리스크를 상승시킨것이기 때문이다. 하지만 벤저민-호크레크그 방법에 근거하여 p-값이 유의하다고 생각합니다. 라고 보고 하면 너무 어렵다. 본페로니 방법도 사람들은 그게 뭐냐고 어리둥절해 한다. 

#### 기준 카테고리를 정해 비교하기

모든 경우의 수로 비교하면 그룹의 수에 따라 폭발적으로 p-값이 증가하기 때문에 기준을 하나 정해서 비교하는 방법이 있다. 또 여기에 본페로니 방법을 사용해도 검정 횟수가 즐기 때문에 멍청이 리스크가 크게 늘지 않는다. 따라서 기준 카테고리끼리도 비교하고 본페로니 방법도 병용하는것이 좋다.

이 기준카테고리로는 보통 데이터 전체에서 차지하는 비율이 높고 누구에게나 이미지가 쉽게 또오르는 집단을 선택하는 것이 좋다. 

#### 탐색적 p-값과 검정적 p-값을 적절히 사용하기

비지니스적으로 직결되는 아이디어를 찾고자 할때 처음부터 미리 덜렁이 리스크를 신경쓰다보면 아무것도 발견 못할 수도 있다. 그래서 p-값을 기준삼아 이익으로 연결될 만한 새로운 아이디어를 탐색하는 목적과 그 결과로 얻어진 아이디어가 이익이 되는지 두가지에 대해  검정을 해야 한다. 

탐색 단계에서는 덜렁이 실수를 저지를 위험성뿐만 아니라 애당초 임의화된 데이터는 없다는 한계도 고려해야 한다. 체육 동아리 출신자가 기타 동아리 그룹보다 보너스 수령액이 많다는 결과가 나와도 그 이유가 무엇인지는 밝혀내기가 어렵고 생각하기에 따라 왜곡과 편중으로 유의차가 얼마든 생길수 있다. 

 탐색 시점에서는 탐색이라는 마음가짐으로 무조건 p-값이 5%미만인, 단지 우연이라고 하기 어려운 관계성을 찾는다. 그리고 이렇다 할만한 것이 있으면 그것을 검정한다. 가장 좋은 방법은 임의화 비교 지만 그렇지 못하더라도 왜곡 시킬 요인을 배제하는 분석방법을 사용한다. 또 검정 다중성이 일어나지 않도록 p-값의 판단 기준을 세워야 하며 검정을 여러번해야한다면 다중성을 교정해서 덜렁이 리스크를 억제하도록 노력해야 한다. 



<!--stackedit_data:
eyJoaXN0b3J5IjpbMTAxNjE3ODUxNCwtMTI5NTIzNzg2NCwtMT
kwOTY4NDk4NiwtMTE5NzkwMzY1MSwtNzkwMzg2MDI4LDIwMDEz
MTIyMDEsNjUwNzE0NDQ5LC03OTIzMDE0ODAsLTE4MzI4NTA0OD
IsMTE0NTA5NDYzOCwtMTcyMDI3NTY3OCw2MDA3Mjk5NCwxNzM5
MjYxNDc3LDE2MTk1NjEzNywtMTQyNjA2NjUyNywtNDkyMTQ1Nz
U3LDE5NDc0NDAwNzYsLTg1MDkzMzM1MSwxMjAzNDkwNzkwLDEx
OTYwMjE4NzZdfQ==
-->