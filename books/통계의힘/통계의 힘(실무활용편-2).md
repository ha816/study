# 통찰의 왕이 되는 분석방법들 - 다중회귀분석과 로지스틱 회귀 분석

## 통계학의 왕도 회귀분석

앞서 1편에서는 아웃컴이 양적인 이든 질적이든 그룹 간 우연이라고 말하기 어려우 수준의 차이가 있는지 없는지 따져보았다. 

아웃컴과 설명변수 사이에 인관관계를 통찰하는 것이 큰 틀이라고 했는데 이 말은 원인에 의해 아웃컴이 좌우되는 것은 아닌가 하는 것은 질적 설명변수ㅡㄹ 생각한다는 것과 같은 듯이다. 

설명 변수와 아웃컴이 모두 질적인 경우 Z검정이나 카이제곱검정으로 아웃컴의 비율을 비교한다.  그렇다면 설명변수가 양적인 경우 어떤 분석이 좋을까? 

설명변수와 아웃컴에 의한 분석방법 정리

||  질적(범주형)|양적(연속형)| 
|--|--|--|
|질적(범주형)| 비율 차이를 Z검정 또는 카이제곱검정  | 회귀분석?|
|양적(연속형)| 평균값 차이를 Z검정 또는 T검정 | 회귀분석? |

## 산포도와 회귀직선으로 경향을 파악한다. 

가로 세로촉에 양적 항목을 잡고 점을 그려넣은 그래프를 전문용어로 산포도라고 한다. 산포도를 보면 두 양적 항목에 대해서 경향성을 볼 수 있다. 그러면 어떻게 해야 객관적으로 경향성을 표현할 수 있을가? 

앞서 불규칙성이나 오차를 포함하는 데이터에서 벗어난 정도의 제곱의 합을 최소화하는 데이터를 참값으로 보는것이 옳다고 했다. 마찬가지로 경향성을 나타내는 직선과 실제 데이터 값과의 차이를 최소화 하는 직선이야 말로 가장 타당한 경향성이라고 볼 수 있다. 

통계의 힘 1편에서 제시된 적이 있는데, 부모의 키가 크면 자녀도 키가 크겠지만 부모의 평균 키만큼 크지는 않다. 반대로 부모의 키가 작으면 자녀의 키도 작겠지만 부모의 평균키 만큼 작지도 않다.  이러한 경향성을 평범으로 회귀라고 부른다. 
회귀분석이라는 이름은 평균값으로 회귀가 일어나는 현상에 대한 분석방법이라는 뜻이다. 

## 회귀분석으로 잘 보이지 않는 관계성 분석이 가능하다. 

최소제곱법을 이용하여 얻은 2개의 양적 항몬간의 경향성을 나타내는 직선을 회귀직선이라고 부르며 이를 실제 구했던 사람은 피어슨이다. 
사실 최소제곱법 계산 자체는 100년 전인 카우스에 의해 발견되었지만, 그보다 훨씬 단순한 회귀분석을 사람들은 발명이라고 할가?

회귀분석에서 가장 큰 차이점은 잘 보이지 않는 관계성을 분석할 수 있다는 점이다. 피어슨은 최소제곱법을 어떤 변수로도 나타낼 수 있는 산포도라는 추상적인 것으로 확장하여, 그 어떤 정보도 일단 수치화하면 관련성을 명백히 할 수 있는 통계학의 만능성을 가진다.

자 그러면 실제 회귀식은 어떻게 구할까?
단순한 예로 A,B,C 3명의 영업직원에게 이달의 고객 방문회수와 성사 계약건수를 물었다. 이 데이터로 계약 건수를 아웃컴으로 경향성을 해석하고 방문 1건을 늘릴때마다 평균 몇건의 계약 성사가 기대가 되는지 알고 싶다. 

설명변수인 방문회수를 가로축, 아웃컴인 계약건수를 Y축에 두고 산포도를 그리면 경향성을 해석할 수 있다. 

$$Y = aX+ b$$

$a$는 X값이 1 늘어날때마다 Y값이 얼마나 늘어나고 줄어드는지 나타내는 기울기이다. 이 기울기를 회귀계수라고도 부른다. $b$는 X가 0일때 Y값이 뭔지 나타내는 절편이다. 

최소제곱법을 사용하여 회귀직선을 구할때는 산포도에 각 점에 대해서 실제의 아웃컴값과 예측 휘귀식에서 구해지는 예측값 차이의 제곱합을 최소화 한다. 
이때 아웃컴과 예측값의 차이를 전문용어로 잔차제곱합이라고 하며, 이 값이 가장 작을때 최량의 회귀직선으로 생각한다. 

우리는 이 최량의 회귀직선을 찾는 것이 목표이다. 최량을 만드는 a,b의 조합은 무엇인가를 생각하는것이 곧 회귀분석 결과다. 

[보충 13]
대학에서 배운 편미분을 이용하여 a,b가 얼마일때 잔차제곱합이 최소가 되는지 알 수 있다. 

## 회귀분석에서는 기우길의 표준오차를 생각한다. 

데이터가 극단적으로 적을땐, 데이터가 우연히 발생한 상황일수도 있기 때문에 경향성을 못 믿겠다고 생각 할 수 있다. 
Z검정이나 T검정에서는 평균값 차이의 표준오차를 생각했지만, 회귀 분석에서는 회귀계수의 표준오차(SE)를 생각한다. 

평균, 비율과 마찬가지로 회귀계수에서도 원시 데이터가 그 무엇이든 모두 더하면 정규분포에 가까워 진다는 중심극한 정리가 작용한다. 수백에서 수천건 이상의 데이터로 회귀분석을 수행하면 100회 정도의 데이터 수집과 분석을 통해 산출되는 회귀 계수의 95회 정도는 진정한 회귀계수 +2SE범위에 수용된다. 데이터 수가 수백건 이라하면 회귀계수에 대해서도 평균값의 차이와 마찬가지로 정규분포보다 T분포를 사용하는 편이 편하다는 점도 완전히 동일하다. 

그러면 어디에서 차이가 있을까?

Z검정에서는 평균값에서 벗어난 값을 제곱하여 계산했다. 이 벗어난 편차의 제곱합을 전문용어로 편차제곱함이라 하는데 이것을 데이터 수로 나눈것이 붓나이다. 

회귀계수의 표준오차는 예측값과 실제 값의 차이를 제곱합을 데이터의 수로 나눈 것인 잔차제곱합을 사용한다. 잔차 제곱합을 데이터의 수롤 나눈 것을 평균제곱잔차라고 한다. 제곱한 차이의 평균값이라는 의미로 평균제곱오차라고도 한다. 

## 회귀분석 오차의 계산에 추가로 필요로 한것

추가로 하나 고려해야 할 사항은 





# 데이터의 배후를 파악한다 - 인자분석과 군집분석
# 통계 분석방법의 총정리와 사용순서



> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTcwMjExMTk4MCwtMzQ0NTE5NzcyLC02MD
czMjQ2ODgsLTY1OTI1MzQ3NCwxNzQ1NzkxMzM2LC01MTEyNzUx
NTcsLTE3ODE5MzY5OTksMTQ5MDAwMzk1OV19
-->