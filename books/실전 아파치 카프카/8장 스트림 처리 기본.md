# Overview

이번 장에서는 스트림을 처리하는 기본 내용을 다룬다. 기본적으로 스트림 처리는 일정량의 모인 데이터를 한꺼번에 처리하는 배치 처리와는 대조되는 형태이다. 

배치 처리는 일반적으로 작업 Job이라는 단위로 묶여서 실행된다. 한 묶음의 데이터를 입력으로 주고, 처리 후에는 작업이 완료된다. 이에 반해서 스트림 처리는 분명한 시작과 끝이 없다. 

카프카 컨슈머의 기본적인 API 사용법을 보면 계속해서 입력된 데이터를 토픽에서 꺼내 처리하는 것을 무한 반복하는 코드가 있는데, 원래 스트림 처리 모델이 그렇다는 것을 알 수 있다. 

# Kafka Streams

Kafka Streams는 카프카가 빌트인으로 제공하는 스트림 처리를 위한 API다. 최근에는 스트림 처리에 특화된 분산 처리 프레임 워크도 등장하고 있으며 대표적으로 Apache Storm, Apache Flink, Spark Streaming 등이 있다. 

위 각종 분산 처리 프레임워크에서는 카프카를 데이터 소스로 사용하는 방법이 정평이 나 있는데, 카프카 자체에 포함된 Kafka Streams를 이용하여 간편하게 스트림 처리를 할 수 있다. 

이번 장에서는 Kafka Streams를 처리하기 위한 예로 소프트웨어의 통계정보인 metrics를 스트림으로 처리해 보자.

# 컴퓨터 시스템의 매트릭스

컴퓨터 시스템에 있어 CPU 사용량과 메모리 사용량등을 정기적으로 취합하여 관리용 서버에 통합해 값을 확인하는 모니터링 방법이 널리 사용되고 있다. 

CPU 사용량과 메모리 사용량은 하드웨어와 소프트웨어의 상태를 나타내는 통곗값으로 이를 메트릭스라 부른다. 

네트워크나 디스크 I/O와 같은 OS에서 얻을 수 있는 메트릭스 외에도 요청 처리 수와 각종 미들웨어가 제공하는 다양한 메트릭스가 존재한다. 매트릭스 단독으로는 단순한 숫자일 수 있지만 운용하고 있는 소프트웨어의 종류, 서버 노드 수에 따라 전체 시스템에서 발생하는 메트릭스는 나름 많은 양의 데이터가 된다. 즉 메트릭스의 데이터 집계 및 처리는 카프카가 자랑하는 좋은 사례가 될 수 있다. 

# 카프카 브로커의 메트릭스를 시각화 하기 

카프카 자체도 브로커와 프로듀서, 컨슈머의 상태를 모니터링하기 위한 매트릭스를 출력한다. 이후에는 카프카 브로커의 메트릭스를 카프카로 보내고 Kafka Streams를 이용하여 스트림 처리를 해본다. 

책에서 구성은 아래와 같다. 

1. Flentd로 카프카 브로커의 메트릭스를 정기적으로 취득하고 토픽으로 기록한다. 
2. Kafka Streams로 메트릭스 데이터를 가공한다.
3. 처리된 메트릭스를 Fluentd로 꺼내 influxDB에 저장한다.
4. influxDB에 저장된 메트릭스를 Grafana로 시각화 한다. 

## Jolokia 설정

카프카는 JMX를 이용하여 메트릭스를 제공하고 있다. 자바가 아닌 언어에서 구현된 도구로 JMX를 얻기 위해서 사용하는 툴이 여기선 jolokia를 사용한다. 

Jolokia는 자바 에이전트 라이브러리로 자바 프로그램에서 로드되어 HTTP를 통해 JMX 정보를 얻을 수 있는 기능을 제공한다. 

JMX를 설치한 후, confleunt-kafka 서비스의 설정 파일 (lib/systemd/system/confluent-kafka.servce)를 편집한다. 섹션내의 KAFKA_OPTS라는 환경 변수를 추가 정의하자. KAFKA_OPTS의 값은 카프카 실행 스크립트에 의해 프로세스 실행시 추가 JVM 옵션으로 취급된다.

```
KAFKA_OPTS=javaagent:/opt/jolokia-jvm.jar
```

JMX에서 얻을 수 있는 메트릭스는 JMX MBean이라는 객체 단위로 관리되고 있으며, type과 name 속성을 지정하여 취득 대상을 좁힐 수 있다.

## Fluentd 설치

Fluentd는 데이터 수집기로 자리매김한 미들웨어로, 플러그인을 조합하여 다양한 데이터 저장소 사이에서 연계할 수 있는 점이 특징이다. 카프카, JMX, InfluxDB 모두에 대응할 수 있다는 점이 본 사례에도 알맞다. 

설치 후에 Flunetd의 설정 파일(td-agent.conf)에 카프카 브로커 메트릭스를 얻기 위한 추가 설정 항목을 작성한다. 

정기적으로 curl 명령을 통해 매트릭스를 얻는 설정을 한다. JMX MBean을 필터링 하지 않고 한꺼번에 취득한다. 

```
<filter kafka.metrics.raw.*>
	@type record_transformer
	<record>
		topic kafaka.metrics
		hostname "#{Socket.gethostname}"
	</record>
</filter>
```
위 설정의 의미는 기본적으로 메트릭스를 이용해 서비스를 모니터링하는 경우 메트릭스를 서버 단위로 집계하고 싶다. 때문에 filter에 해당하는 @type record_transformer를 이용해 호스트 명 정보를 추가한다.

filter plugin에 부가한 토픽 키의 값이 토픽의 키로 사용된다. 또한 이후 스트림 처리를 할때 메트릭스를 호스트 단위로 집계하기 위한 파티션 키로 hostname을 사용하게 되기 때문에 동일한 노드의 메트릭스가 동일한 파티션으로 전달되도록 자동 설정된다. 

다음으로 아래 설정을 추가한다. 

```
<match kafka.metrics.raw.*>
	@type kafka2
	brokers localhost:9092
	topic_key topic
	partition_key_key hostname
	default_message_key nohostname
	max_send_retries 1
	required_acks -1
	<format>
		@type json
	</format>
	<buffer topic>
		flush_intervals 10s
	</buffer>
</filter>
```

## Influx DB에서 데이터 로드

데이터 시각화를 위한 준비로 Kafka Streams로 처리한 데이터를 InfluxDB에 기록한다. 

InfluxDB는 시계열 데이터 저장에 특화된 데이터 저장소로, 메트릭스의 정보를 시각화 하기 위해 Grafana의 데이터 소스를 사용한다. SQL과 비슷한 쿼리를 이용해서 시계열 데이터에 엑세스할 수 있는 것이 특징이다. 

앞서 세팅했던 Fluentd의 설정 파일(td-agent.conf)에 카프카의 토픽(kafka.metrics.processed)에서 처리 완료된 메트릭스 정보를 읽어 InfluxDB에 기록하기 위한 설정을 추가한다. 

```
<source>
	@type kafka_group
	brokers localhost:9092
	consumer_group kafka-fluentd-influxdb
	topics kafka.metrics.processed
	format json
	offset_commit interval 60
</source>

<match kafka.metrics.processed>
	@type influxdb
	host localhost
	port 8086
	dbname kmetrics
	measurement kafka.broker
	tag_kes ["hostname"]
	time_key "timestamp"
	<buffer>
		@type memory
		flush_interval 10s
	</buffer>
</match>
```

InfluxDB에 데이터가 기록되었는지 여부는 influx 명령어를 사용하면 된다. 우선 kmetrics 데이터베이스에 접속한다. 

```
influx -database kmetrics

SELECT BytesIn, hostname From 'kafka.broker' LIMIT 5
```

시계열 데이터를 보관하는 InfluxDB에서는 관계형 DB와는 다른 개념으로 정보가 보관된다. 

데이터 집합을 나타내는 개념이 measurement이며 이는 데이터베이스의 테이블에 해당한다. 현재 measurement 이름으로 kafka.broker를 지정하고 있다. 

데이터 레코드는 타임스팸프/필드값/태그값으로 구성된다. 필드와 태그는 각각 복수로 존재한다. 필드와 태그는 모두 테이블의 열에 해당한다. 필드가 시계열  숫자 데이터를 보관하는 부분인데 반해 태그는 필드 값을 그룹화 하기 위한 레이블에 해당한다. 

fluent-plugin-influxdb 설정 파라미터에서 tag_keys로 지정된 요소는 태그로 취급하고, time_key로 지정된 요소는 타임스탬프로, 그리고 그 외의 요소는 필드로 취급한다. 따라서 출력 결과를 JSON으로 나타내면 hostname은 태그로, BytesIn은 필드로 InfluxDB에 보관된다. 

```
{"hostname":"host1", "timestamp":123123123, "BytesIn": 90909}
```


> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTkwNTI3NjQwNiwxODU4NDk4NzMyLDkzND
A4NzY4MCw4ODA2NzQ1NCwtMTA1MTg3MTE2LC0yMTAzODk4Nzk5
LC0zMjc3MjE5MTQsLTgzMzYwNjc4LC0yMDE2MjIzMjY4LDczMD
k5ODExNl19
-->