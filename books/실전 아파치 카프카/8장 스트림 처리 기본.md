# Overview

이번 장에서는 스트림을 처리하는 기본 내용을 다룬다. 기본적으로 스트림 처리는 일정량의 모인 데이터를 한꺼번에 처리하는 배치 처리와는 대조되는 형태이다. 

배치 처리는 일반적으로 작업 Job이라는 단위로 묶여서 실행된다. 한 묶음의 데이터를 입력으로 주고, 처리 후에는 작업이 완료된다. 이에 반해서 스트림 처리는 분명한 시작과 끝이 없다. 

카프카 컨슈머의 기본적인 API 사용법을 보면 계속해서 입력된 데이터를 토픽에서 꺼내 처리하는 것을 무한 반복하는 코드가 있는데, 원래 스트림 처리 모델이 그렇다는 것을 알 수 있다. 

# Kafka Streams

Kafka Streams는 카프카가 빌트인으로 제공하는 스트림 처리를 위한 API다. 최근에는 스트림 처리에 특화된 분산 처리 프레임 워크도 등장하고 있으며 대표적으로 Apache Storm, Apache Flink, Spark Streaming 등이 있다. 

위 각종 분산 처리 프레임워크에서는 카프카를 데이터 소스로 사용하는 방법이 정평이 나 있는데, 카프카 자체에 포함된 Kafka Streams를 이용하여 간편하게 스트림 처리를 할 수 있다. 

이번 장에서는 Kafka Streams를 처리하기 위한 예로 소프트웨어의 통계정보인 metrics를 스트림으로 처리해 보자.

# 컴퓨터 시스템의 매트릭스

컴퓨터 시스템에 있어 CPU 사용량과 메모리 사용량등을 정기적으로 취합하여 관리용 서버에 통합해 값을 확인하는 모니터링 방법이 널리 사용되고 있다. 

CPU 사용량과 메모리 사용량은 하드웨어와 소프트웨어의 상태를 나타내는 통곗값으로 이를 메트릭스라 부른다. 

네트워크나 디스크 I/O와 같은 OS에서 얻을 수 있는 메트릭스 외에도 요청 처리 수와 각종 미들웨어가 제공하는 다양한 메트릭스가 존재한다. 매트릭스 단독으로는 단순한 숫자일 수 있지만 운용하고 있는 소프트웨어의 종류, 서버 노드 수에 따라 전체 시스템에서 발생하는 메트릭스는 나름 많은 양의 데이터가 된다. 즉 메트릭스의 데이터 집계 및 처리는 카프카가 자랑하는 좋은 사례가 될 수 있다. 

# 카프카 브로커의 메트릭스를 시각화 하기 

카프카 자체도 브로커와 프로듀서, 컨슈머의 상태를 모니터링하기 위한 매트릭스를 출력한다. 이후에는 카프카 브로커의 메트릭스를 카프카로 보내고 Kafka Streams를 이용하여 스트림 처리를 해본다. 

책에서 구성은 아래와 같다. 

1. Flentd로 카프카 브로커의 메트릭스를 정기적으로 취득하고 토픽으로 기록한다. 
2. Kafka Streams로 메트릭스 데이터를 가공한다.
3. 처리된 메트릭스를 Fluentd로 꺼내 influxDB에 저장한다.
4. influxDB에 저장된 메트릭스를 Grafana로 시각화 한다. 

## Jolokia 설정

카프카는 JMX를 이용하여 메트릭스를 제공하고 있다. 자바가 아닌 언어에서 구현된 도구로 JMX를 얻기 위해서 사용하는 툴이 여기선 jolokia를 사용한다. 

Jolokia는 자바 에이전트 라이브러리로 자바 프로그램에서 로드되어 HTTP를 통해 JMX 정보를 얻을 수 있는 기능을 제공한다. 

JMX를 설치한 후, confleunt-kafka 서비스의 설정 파일 (lib/systemd/system/confluent-kafka.servce)를 편집한다. 
```

```

> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIwNzUzODE3MjIsLTEwNTE4NzExNiwtMj
EwMzg5ODc5OSwtMzI3NzIxOTE0LC04MzM2MDY3OCwtMjAxNjIy
MzI2OCw3MzA5OTgxMTZdfQ==
-->