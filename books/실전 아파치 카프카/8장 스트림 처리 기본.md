# Overview

이번 장에서는 스트림을 처리하는 기본 내용을 다룬다. 기본적으로 스트림 처리는 일정량의 모인 데이터를 한꺼번에 처리하는 배치 처리와는 대조되는 형태이다. 

배치 처리는 일반적으로 작업 Job이라는 단위로 묶여서 실행된다. 한 묶음의 데이터를 입력으로 주고, 처리 후에는 작업이 완료된다. 이에 반해서 스트림 처리는 분명한 시작과 끝이 없다. 

카프카 컨슈머의 기본적인 API 사용법을 보면 계속해서 입력된 데이터를 토픽에서 꺼내 처리하는 것을 무한 반복하는 코드가 있는데, 원래 스트림 처리 모델이 그렇다는 것을 알 수 있다. 

# Kafka Streams

Kafka Streams는 카프카가 빌트인으로 제공하는 스트림 처리를 위한 API다. 최근에는 스트림 처리에 특화된 분산 처리 프레임 워크도 등장하고 있으며 대표적으로 Apache Storm, Apache Flink, Spark Streaming 등이 있다. 

위 각종 분산 처리 프레임워크에서는 카프카를 데이터 소스로 사용하는 방법이 정평이 나 있으


> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE3Njc2MjY0MTUsLTIwMTYyMjMyNjgsNz
MwOTk4MTE2XX0=
-->