# Overview

이 장에서는 예제로 사물인터넷과 관련된 애플리케이션을 구현한다. 카프카는 기본적으로 웹사이트 로그를 취급하는 시스템으로 만들어 졌으나 사물인터넷을 구축하는 도구로도 이용할 수 있다. 사물 인터넷을 구축할때 카프카를 사용하는 범위와 특징, 활용법을 간단한 예제를 통해 설명한다.

# 사물인터넷에 필요한 시스템 특성과 카프카

사물인터넷은 추상적인 개념이지만 기몬 PC나 IA 서버 뿐만아니라 다양한 기기가 인터넷에 연결되어 서로 제어하는 상태를 표현한 추상적 개념이다. IOT에서 디바이스의 특징은 아래와 같다.

* 센서 디바이스는 PC 만큼의 파워, 저장소를 갖고 있지 않다.
* 수천 또는 수만개 이상의 디바이스가 접속한다.
* 데이터 처리 지연이 적어야 한다.

# 센서 데이터용 데이터 허브 설계

## 실현할 기능

사물인터넷용 데이터 허브에서 제공하는 기본 기능으로 센서 데이터 수신 기능이 있다. 여러 디바이스에서 나오는 세부적인 데이터를 카프카 브로커에서 수신하기 위한 구성에 대해 설명한다.

또한 센서 디바이스가 취급하는 데이터에 대해 정의한다. 앞서 설명한 바와 같이 센서 디바이스의 하드웨어 자원이 제한적이라는 특성하의 최소한의 데이터만 보낼 수 있다고 가정하면 몇초에 한번 정도로 다음 정보를 보내는 것으로 정의할 수 있다.

* 디바이스 ID
* 타임스탬프
* 센서 정보

데이터에는 최소한의 정보만 있다. 이러한 정보만으로는 하류 시스템에서 실현 가능한 데이터 활용은 제한적이다. 예를 들어 온도 센서를 호텔 객실에 배치하고 특정 객실의 온도가 일정 이상으로 올랐고 경고 메일 발송을 하는 처리를 구현해보도록 하자.

일반적으로 디바이스 마스터 정보를 별도로 관리하고 디바이스 ID로 연동하는 과정을 그 사이에 둠으로써 데이터를 처리한다. 그리고 이렇게 처리한 여러 속성 정보를 활용하여 다양한 서비스를 할 수 있다. 

스트림 처리에 활용되는 데이터에 마스터 데이터 등을 연관지어 보강하는 것을 데이터 보강(Data enrichment)이라고 하는 경우가 많아 본문이선 이런 표현을 쓰겠다.


## 센서 데이터의 수신 기능 설계

카프카에서 디바이스 데이터를 수신하는 법에 대해 생각해보자. 카프카에서 메시지 수신의 기본은 Producer API로 구현된 애플리케이션이 메시지를 보내고 브로커에서 받는것이다. 

프로듀서는 카프카의 기능 확자응ㄹ 위해 메시지 데이터 통신 외에도 브로커와의 메타 데이터 교환, 송신처 파티션 설정등을 한다. 

디바이스의 성능이 제한적이기 때문에 디바이스가 프로듀서의 역할을 하긴 어려울 것이다. 따라서 프로듀서의 역할은 데이터 허브에서 처리해야 한다.

디바이스에서 처리 비용을 최대한 줄이기 위해 **디바이스와 데이터 허브 사이의 통신 프로토콜은 최대한 가벼운 것**을 활용하자. 

여기선 MQTT라 불리는 IOT 전용 통신 프로토콜을 알아보자.

## MQTT

Message Queuing Telemetry Transport는 경량의 Pub/Sub 메시지 프로토콜이다. TCP/IP를 기반으로 동작하며 미국 IBM에 의해 고안되었다. 현재 표준화 단계를 거쳐 거의 표준화가 되어 있다. 

특징은 아래와 같다.

* 동일 계층 HTTP에 비해서 헤더크기가 작고, 통신 오버헤드가 적다.
* Pub/Sub 메시징 모델에 비해 비동기 통신이 가능하다. 
* MQTT 클라이언트가 서비스 품질을 지정할 수 있다.

### Kafka Connect 이용

카프카 브로커는 MQTT를 직접 지원하지 않기 때문에 앞단에서 MQTT 프로토콜을 받아 카프카 프로듀서로 송신하는 기능이 필요하다. 여기선 Kafka Connect를 사용하면 되는데 Kafka-Connect-MQTT 플러그인이 제공되고 있다. 

### Ktream과 KTable의 조인

Kafka Streams API 중 하나인 KTable은 'changelog stream'이라고 설명하고 있다. 

KTable은 이름처럼 스트림을 테이블 처럼 취급할 경우 편리하며, 처리 내부에 상태를 갖고 있어 Key를 기반으로 최신값을 유지한다.

윈도 처리 후에 집계 결과 상태를 유지하는 것외에도 스트림과 Join 하는 용도로 사용이 가능하다. 

KStream과 KTable을 조인하는 경우, KStream, KTable에 대응하는 토픽의 파티션 수가 같아야 하며, 파티셔닝 정책이 동일해야 한다는 제ㅔ약이 있다. 다소 이해하기 어려운 개념이지만 다른 분산 처리 프레임워크에서도 볼 수 있는 Distributed Hash Join의 동작을 파티션 구조로 만든 것이라고 할 수 있다. 

처리 프로그램은 **서로 다른 토픽 사이에서 결합 대상의 메시지가 동일한 파티션에 포함되어 있다는 것을 전제**로 한다.


이러한 제약을 피하기 위해 KTable의 파생인 GlobalKTable을 사용할 수 있다. 

GlobalKTable은 KTable에선 모든 파티션을 하나의 통합된 테이블로 관리하는데 반해서 파티션 별로 각각의 테이블을 생성한다. 파티션 정보를 중복해서 각 처리 워커가 보유하기 때문에 파티션 수의 제약을 받지 않는다. 

한편 파티션 정보의 중복 수 만큼 워커가 갖고 있는 테이블 정보가 증가하기 때문에 매우 큰 테이블을 유지하는 경우 메모리 문제가 발생하고 성능에도 문제가 발생할 수도 있다. 








> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbMjU2NDEzMzU5LDQ1NTYxMjI2OSwxNjU4Nz
M4NzUyLDE4NzI1MDQ0Miw2MDE3NDEwMiwtOTA4NzE4ODY5LDEy
NTEzNDAyMDgsLTg5NTAyODQyNiwxMzAzODIyNzI3LC0xNDEzNz
g4OTY2LC02MDgyMjc5NzUsNzMwOTk4MTE2XX0=
-->