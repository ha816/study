# Overview 

이 장에서는 외부 스트림 처리의 예로 아파치 스파크의 검포넌트 중 하나인 Structured Streaming을 사용해 카프카와 조합한 스트림 처리 애플리케이션을 조립하는 예를 알아보자. 

간단히 Structured Streaming의 개요에 대해 설명하고, 작성할 예제 애플리케이션의 동작 환경에 대해 설명한다. 

스파크와 Strucutred Streaming은 스칼라, 파이썬 자바 등으로 애플리케이션 개발이 가능한데, 애플리케이션 개발에서는 가장 많이 사용하는 언어중 하나인 스칼라를 사용한다. 

# 아파치 스파크

아파치 스파크는 OSS(오픈소스 소프트웨어)의 병렬 분산 처리 프레임워크다. 하둡의 맵리듀스 프레임워크와 마찬가지로 여려 범용 서버로 구성된 클러스터를 사용해 대규머 데이터의 배치 처리를 병렬로 실행할 수 있다. 

스파크는 맵리듀스 프레임 워크에 비해 더 효율적으로 데이터를 처리할 수 있도록 설계되어 있다. 이외에도 다양한 프로그래밍 언어로 애플리케이션 개발이 가능한 점이나, 머신러닝, 쿼리 처리, 그리고 이 장의 주제인 스트림 처리 등 특정 용도에 있어서 병렬 분산 처리를 쉽게 활용할 수 있는 컴포넌트가 포함되어 있다는 점도 장점이다. 

스파크로 개발한 애플리케이션은 클러스터 관리자에 의해 계산 리소스가 관리되는 클러스터에서 동작한다. 클러스터 관리자에는 하둡의 YARN과 아파치 Mesos, 스파크에 포함된 Standalone이 있으며, 쿠버네티스도 이를 지원하고 있다. 

## 스파크의 데이터 처리 모델

스파크는 처리 대상 데이터를 RDD(Resilient Distributed Dateset; 탄력이 있게 분산된 데이터 셋)라 불리는 내장애성을 지닌 분산 컬렉션으로 추상화 한다. 즉 처리 대상의 레코드 하나하나를 RDD로 취급한다. 

```
// 아래 각 레코드는 모든 하나의 추상화된 컬렉션 구조로 취급된다.
고양이, 개, 여우, 너구리
// 각 레코드는 RDD의 한 요소로 추상화된다.
```

RDD는 데이터 처리을 위한 추상화된 인터페이스로 이해할 수 있다. 레코드를 RDD로 추상화하여 개발자는 분산 처리를 의식하지 않고 컬렉션 처리 코드를 작성하여 애플리케이션 개발이 가능하다. 스파크는 처리 대상의 파일이나 RDBMS의 데이블 등 처리 대상의 데이터에 대한 RDD 인터페이스를 부여하는 수단과 기능을 제공한다. 

```
val rdd = sc.textFile("data.txt");

```

> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTY1MzI4NjMzNSwyMzQxMTgzNTRdfQ==
-->