# 데이터 파이프 라인이란?

카프카는 분산 메시징 시스템으로 다른 시스템이나 도구에서 보낸 메시지를 받아 다른 시스템이나 도구의 요청에 근거해 메시지를 전달하는 기능을 제공하고 있다. 

시스템 전체에 이르기 까지 그 시야를 넓히면 카프카는 데이터의 발생, 수집, 가공, 저장, 출력에 이르는 일련의 과정에서 도구와 시스템을 연결하는 역할을 한다. **데이터가 전달되는 경로나 처리를 위한 기반 전체를 데이터 파이프라인이**라 한다. 

웹 서버 OR 애플리케이션 서버 -> 카프카 클러스터 -> 실시간 집계 OR 장기 보존 & 분석기반

카프카가 하나 이상의 브로커로 된 카프카 클러스터, 프로듀서, 컨슈머, 카프카 클라이언트로 구성되어 있다고 소개했다. 이 중 데이터 파이프라인의 일부가 되는 것은 카프카 클러스터, 프로듀서, 컨슈머다. 이제 카프카를 구성하는 구성요소인 프로듀서와 컨슈머의 분류를 알아보자. 

# 데이터 파이프라인의 프로듀서 구성

프로듀서의 구성 패턴은 크게 두 가지로 나뉜다.

* 프로듀서가 직접 카프카에 메시지를 송신하는 패턴
* 프로듀서가 직접 카프카에 메시지를 송신하지 않고 중간에 메시지 송신 도구를 걸쳐 송신하는 패턴

## 프로듀서가 카프카에 메시지를 송신하는 패턴 

말 그대로 프로듀서가 직접 송신하는 패턴이다. 프로듀서 측에서 표준 기능으로 송신 기능을 제공하거나 그 외에 플러그인등을 이용할 수 있다. 이 경우 비교적 간단히 카프카로 데이터 파이프 라인을 구축할 수 있다. 

사실상 카프카가 이 분야의 산업상 표준이 되기도 했기 때문에 메시지 송신을 지원하는 미들웨어도 늘고 있다. 예를 들어, 병렬 분석 분산 처리의 하둡은 매트릭스 출력 기능중 하나로 카프카에 출력할 수 있다. 비슷하게 아파치 스파크는 처리결과를 카프카에 출력 할 수 있다. 

## 메시지 송신 도구를 걸쳐 송신하는 패턴

이 패턴은 프로듀서가 직접 카프카에 송신하지 않고 중간에 미들웨어에서 별개의 메시지 송신 도구를 이용하여 카프카에 메시지를 전송하는  패턴이다. 실제로 현업에서도 많이 사용되는 패턴으로 일반적인 HTTP 서버는 엑세스 로그를 카프카에 직접 송신하는 기능이 없다. 이 경우 로컬의 로그 파일을 출력한 뒤 별도의 송신도구로 카프카에 메시지를 송신한다. 

그 밖에는 MQTT 프로토콜을 이용하는 경우, MQTT 프로토콜을 따른 데이터를 카프카에 송신하기 위해 프로토콜 변환 처리를 위해 Proxy가 필요하다. 이러한 미들웨어가 출력한 데이터를 카프카로 송신하는 도구에 대표적인 것인 Kafka Connect와 Fluentd이다. 

# 데이터 파이프라인의 컨슈머 구성

프로듀서와 비슷하게 두 가지 패턴이 존재한다. 

* 미들웨어가 직접 카프카에서 메시지를 취득해 처리하는 패턴
* 미들웨어가 다른 도구를 통해 카프카에서 메시지를 취득하고 처리/보관하는 패턴

## 미들웨어가 직접 카프카에서 메시지를 취득해 처리하는 패턴

데이터를 처리하거나 기록하는 미들웨어가 카프카에서 직접 메시지를 수신하는 패턴이다. 배치 처리와 스트림 처리를 모두 대응 할 수 있지만 카프카가 스트림 데이터를 취급하기 때문에 특히 스트림 처리를 많이 볼 수 있다. 

카프카에서 직접 메시지를 취득해 처리하는 미들웨어는 스트림 처리가 가능한 Apache Flink가 대표적이다. 또한 스파크 같은 일부 미들웨어는 카프카에서 직접 데이터를 얻을 수 있으며 스트림 처리와 배치 처리를 모두 지원한다. 

## 미들웨어가 다른 도구를 통해 메시지를 취득하고 처리 및 보관하는 패턴

이 패턴은 데이터를 처리하고 기록하는 시스템 또는 미들웨어가 카프카에서 메시지 수신을 지원하지 않아 다른 도구로 카프카에서 메시지를 수신한 후 원하는 시스템에 데이터를 전달하는 방식이다. 프로듀서 쪽과 마찬가지로 데이터를 처리하거나 기록하는 시스템이 카프카를 지원하는 경우에도 요구 사항에 맞게 이 방식을 채택하는 경우도 있다. 

이 역할을 제공하는 도구는 여럿 있지만 많이 사용하는 것이 Kafka Connect와 Fluentd이다. 

![../../../../_images/pipeline.jpg](https://docs.confluent.io/platform/current/_images/pipeline.jpg) 

카프카를 적용하는 사례가 늘면서 카프카와 연계하여 사용할 수 있는 도구와 미들웨어도 늘어나고 있다. 다양한 형태의 데이터 파이프라인 디자인 패턴이 제안되고 있고 그러한 디자인 패턴 중 하나로 컨플루언트는 위와 같이 KafkaConnect와 Kafka Streams를 이용한 데이터 파이프 라인을 제시하고 있다. 

* Kafka Connect를 이용하여 외부의 DataSource에서 데이터를 카프카로 송신한다.
* Kafka Streams를 통해 데이터를 처리하고 처리 결과를 카프카에 송신한다. 
* Kafka Connect를 이용하여 연계 시스템에 데이터를 출력한다.

# 데이터 파이프 라인에서 취급하는 데이터

## 메시지 데이터 형태

파이프라인에서는 카프카를 경유하여 메시지를 송수신 하는데, 이 메시지 데이터의 형태는 프로듀서와 컨슈머에서 불일치 하지 않아야 한다.

메시지는 Key, Value 데이터 형태가 프류두서 애플리케이션에서 지정되고 데이터를 직렬화해서 송신하다. 그리고 컨슈머는 미리 프로듀에서 보낸 Key, Value 데이터 형태와 포함된 데이터를 감안하여 설계하고 구현해야 한다. 

카프카에서는 사실 이런 데이터 혀태를 관리하고 있지 않기 때문에 카프카 클러스터에서 데이터 형태가 다른것을 확인 못하고 컨슈머가 메시지를 수신하여 역직렬화놔 데이터 처리를 하고 난 뒤에 발견되는 경우가 있다. 따라서 주의해야 한다. 

컨슈머 뿐만 아니라 송신 하는 프로듀서에서도 메시지 데이터 형태는 주의가 필요하다. 컨슈머가 사용하는 시리얼 라이저는 Key, Value 마다 1개씩이며 데이터에 따라 구분해서 사용하기 어렵다. 따라서 프로듀서에서 보낸 메시지의 데이터 형태를 변경하려면 그에 해당하는 컨슈머도 변경해야 한다. 그러나 애플리케이션은 항상 데이터를 처리하고 있기 때문에 쉽게 중단시킬 수 없는 경우가 있다. 

이러한 데이터의 불일치를 방지하기 위해 데이터 형태 관리나 향후 확장을 위한 변경 법에 대해서는 미리 방안을 마련한 필요가 있다. 다음 절에서 제공하는 스키마 구조를 갖는 데이터 형태를 이용하는 것도 방법이다. 

## 스키마 구조를 갖는 데이터 형태

다루는 요구 사항에 따라 하나의 메시지에 여러 값을 포함 시키고 싶을 때가 있다. 이런 경우 JSON이나 Apache Avro와 같은 구조화된 데이터가 자주 사용된다. 여러 컬럼을 가진 스키마를 정의하여 하나의 메시지 안에 여러 값을 포함하게 할 수 있다.

스키마 정의는 메시지 송신의 프로듀서 애플리케이션 설계에서 사용되지만 컨슈머 애플리케이션에 미치는 영향이 크기 때문에 확장성을 고려하여 신중하게 결정해야 한다.

## 스키마 에볼루션

스키마 정의는 신중해야 겠지만 애플리케이션 수정이나 기능 추가에 따라 정의를 변경해야 하는 경우가 발생할 수 있다. **스키마 정의를 운용 중에 변경하는 것은 스키마 에볼루션 또는 스키마 진화라고 한다.** 

스키마 에볼루션에 동반하여 정지할 애플리케이션의 수나 정지 시간을 최소화해야하는 경우가 많다. 이러한 문제에 대한 대응으로 에볼루션을 진행할때 스키마 변경 전후의 호환성을 고려하게 된다.

단순히 기존 컬럼에 새로운 컬럼을 추가하는 작업은 크게 문제가 되지 않는다. 하지만 기존 컬럼의 형태를 변경하거나 필수적인 컬럼을 제거하는 등의 처리를 하게 되면 컨슈머에서 에러가 발생할 수 있다. 

앞서 소개한 Apache Avro는 호환성을 고려하는 데이터 형태로 다양한 대응이 가능하다. 이는 7장에서 마저 소개한다.





> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbMzM0NTA4OTg5LDE3NTk0MTA3NjUsLTk1NT
M4OTE5NywtNzcxNDYyMjAwLDE5MzU1Mzk5OTcsMTUxMTUwODg3
NF19
-->