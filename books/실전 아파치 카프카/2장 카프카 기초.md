# Overview

이 장에서는 카프카의 메시지 송수신 구조와 카프카를 이용하는데 알아야할 기본 용어를 설명한다. 아래는 이번 장에서 다룰 토픽들이다. 

1. 메시지 송수신 기본
2. 시스템 구성
3. 분산 메시징을 위한 구조
4. 데이터 견고함을 담보하는 복제의 구조

각 항목은 카프카를 이용하는데는 기본적인것들이지만, 1~3번은 카프카를 이용한 개발자나 사용자에게 중요하고 4번은 카프카를 이용한 플랫폼 설계, 운용 엔지니어에게 더 중요하다. 

# 메시지 송수신

아래는 메시지 자체와 연관된 개념이다.

메세지
: 카프카에서 다루는 데이터의 최소 단위. 메시지는 Key와 Value를 가지며 메시지 전송할때 파티셔닝에 사용된다.

토픽
: 메시지의 종류를 토픽이라라 부른다. 토픽은 메세지 종류를 관리하는 스토리지를 브루는 호칭이기도 하다. 토픽은 브로커에 배치되어 관리된다. 프로듀서와 컨슈머는 특정 토픽을 지정하여 메시지를 송수신함으로써 카프카 클러스터에서 여러 종류의 메세지를 중계한다. 

# 시스템 구성

이제 카프카를 동작시키는데 필요한 시스템 구성 요소를 하나하나 자세히 알아보자.

## 브로커

브로커는 하나의 서버(또는 인스턴스) 당 하나의 데몬 프로세스로 동작하여 메시지 수신/전달 요청을 받아들인다. 이것을 여러 대의 클러스터로 구성할 수 있으며 수신/전달 처리량의 향상을 위한 스케일 아웃이 가능하다. 

브로커로 받은 데이터는 모두 디스크에 저장하여(영속화)가 이루어지기 때문에 디스크의 용량 만큼 데이터를 장기간 보존할 수 있다. 


## 프로듀서 API/ 컨슈머 API

프로듀서/컨슈머를 구현하는 기능은 라이브러리 형태로 제공된다. 프로듀서를 구현하기 위한 API를 프로듀서 API, 컨슈머를 구현하기 위한 API를 컨슈머 API라 한다. 그러나 프로듀서, 컨슈머는 브로커 처럼 데몬 프로세스로 동작하는 프로그램은 아니며 각각 API는 자바이다. 

### 프로듀서

프로듀서는 프로듀서 API를 사용하여 브로커에 데이터를 송신하기 위해 구현된 **애플리케이션**이다. 실제로 프로듀서 기능을 내장하거나 서드 파티의 플러그인 제휴를 통해 제공하는 OSS(Open Soucre Software), 도구의 종류는 아래와 같다. 

* Apache Log4j(Kafka Appender)
	* 로그 출력시 사용하는 자바 기반 로깅 유틸리티 소프트웨어
* Apache Flume
	* 댜량의 로그 데이터를 효율적으로 수집, 취합, 이동하기 위한 분산형 소프트웨어
* Fluentd
	* 크로스 플랫폼 오픈소스 데이터 수집 소프트웨어
* Logstash
	* 엘라스틱서치에서 제공하는 OSS 데이터 수집 엔진

### 컨슈머

컨슈머 API를 이용해 브로커에서 메시지를 취득하도록 구현된 애플리케이션이다.  브로커는 브로커에 도달한 메시지를 그 즉시 컨슈머에서 취득애햐 한다는 제약이 없기 때문에 디스크에 보관된어 있는 동안은 메시지 취득이 가능하다. 

프로듀서와 마찬가지로 카프카 연계를 위한 컨슈머 기능을 갖춘 기존 제품도 많이 존재한다. 특히 Apache Spark (Streaming), Apache Storm, Apache Flink 등의 분산 스트림 처리 OSS에서 카프카가 갖춘 확장성을 유용하게 사용하는 경우가 많기 때문에 표준 라이브러리로 제공되고 있다. 

* Apache Spark
	* 빅데이터 처리를 위한 오픈소스 클러스터 컴퓨팅 프레임워크
* Apache Samza
	* 스트림 처리용 오픈소스 소프트웨어로 준 리얼타임 비동기 계산 프라엠워크
* Apache Flink
	* 스트림 처리용 오픈소스 프레임워크
* Apache Flume
* Fluentd
* Logstash

>Push, Pull 
프로듀서 - 브로커에서는 프로듀서에서 PUSH형으로 메시지가 전달된다. 브로커 - 컨슈머의 데이터 흐름에서는 메시지 송신 요청이 컨슈머로 부터 PULL형태로 메세지를 송신하게 된다. 

시스템 운영상의 PULL형태의 장점은 컨슈머 시스템 고장이나 유지보수로 정지한 경우에도 브로커에 미치는 영향이 적다. 브로커가 만약 Push 형인 경우, 컨슈머의 서비스 중단 시 대응을 매번 브로커에서 실시해야 한다. 

### 주키퍼 

브로커에게 있어 **분산 처리를 위한 관리도구인 아파치 주키퍼**가 필요하다. 주키퍼는 하둡등 병렬 분석 처리용 OSS에 있어서 설정관리, 이름 관리, 동기화를 위한 잠금 관리를 하는 구조로 자주 사용된다. 카프카에선 분산 메시지의 메타 데이터(토픽과 파티션등)을 관리하기 위한 구성 요소로 주로 사용한다. 주키퍼 클러스터(주키퍼 앙상블이라고도 한다)의 구조상 서버의 갯수는 홀수로 구성하는 것이 일반적이다. 

카프카 클러스터 - 카프카는 여러 대의 브로커서버와 주키퍼 서버(클러스터링의 메시지 중계 기능) 그리고 프로듀서/ 컨슈머 API(메시지 송수신을 위한 라이브러리 그룹)로 구성된다. 

# 분산 메시징을 위한 구조 

## 파티션

토픽에 대한 대량의 메시지 입출력을 지원하기 위해, 브로커상의 데이터를 읽고 쓰는 것은 파티션이라는 단위로 분할되어 있다. 토픽을 구성하는 파티션은 브로커 클러스터 안에 분산 배치되어 프로듀서에서의 메시지 수신, 컨슈머로의 배달을 분산해서 실시함으로써 하나의 토픽에 대한 대규모 데이터 수신과 전달을 지원한다. 

각 파티션을 어디 브로커에 어떻게 배치하는 가에 대한 정보는 브로커 측에서 유지된다. 또한 프류도서/ 컨슈머 API에게 파티션들은 은폐되어 있어 있기 때문에 프로듀서/컨슈머에서는 토픽만을 지정학, 구현시에 파티션을 인식할 필요가 없다. 

## 컨슈머 그룹

카프카는 하류 시스템(컨슈머)에서 분산 스트림 처리도 고려해 설계되어 있다. 단일 애플리케이션 안에서 여러 컨슈머가 단일 토픽이나 여러 파티션에서 메시지를 취득하는 방법으로 컨슈머 그룹이라는 개념이 존재한다. 

카프카 클러스터 전체에서 클로벌 ID를 컨슈머 그룹 전체에서 공유하고 여러 컨슈머는 자신이 소속된 컨슈머 그룹을 식별해, 읽어들일 파티션을 분류하고 제어한다.

## 오프셋 

각 파티션에는 수신한 메시지는 각각 일련번호가 부여되어 있어 파티션 단위로 메시지 위치를 나타내는 오프셋이라는 관리 정보를 이용해 컨슈머가 취득하는 메시지의 범위 및 재시도를 제어한다. 제어에 사용되는 오프셋의 종류에는 아래와 같은 것이 있다. 

Log-End-Offsert(LEO) - 파티션 데이터의 끝을 의미
Cuurent Offset - 컨슈머가 어디까지 메시지를 읽었는가 의미
Commit Offset - 컨슈머가 어디까지 커밋 했는지 의미

LEO는 브로커에 의해 파티션에 관한 정보로 관리 및 업데이트된다. Commit Offset은 컨슈머 그룹마다 보관되어 관리, 업데이트 된다. Current Offset은 컨슈머에서의 데이터 취득을 계기로 업데이트된다. 

Commit Offset은 컨슈머로부터 여기까지의 오프셋은 처리했다는 것을 확인하는 오프셋 커밋(Offset Commit)을 계기로 업데이트 된다.  특정 토픽에 대해 여러 컨슈머 그룹이 메시지를 취득하는 경우에는 파티션에 대한 Commit Offset도 컨슈머 그룹 숫자만큼만 존재한다. 

### 메시지 송수신


 
> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTQ3ODY2MjU0NCwxNzg4MDc1NzY5LC0xMj
M1NTAzOTE2LC0zNTQxOTgzMzAsLTEwNDI4Mzg4MTAsLTc5MTc1
NDU0NSwtODc1ODU3NzM3LDcxMjIzNTY1MSwyMDk5NzM0MTE3LC
0zNTcyNjA1OTEsMjc1NDI3MDg5LC0yMTQ0MDIyODMyLC0xMjY4
NTk0Njg4LC01OTgyMTQzNjYsLTEzOTU0NzYwMSwtOTk3NDQ2NT
E4LC0xMDk3NDUwODg3LDE1MTU2MzcxMjUsLTE3Mzk4NDI0Mjks
MjQwMDU5MzEyXX0=
-->