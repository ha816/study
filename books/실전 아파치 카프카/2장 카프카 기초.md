# Overview

이 장에서는 카프카의 메시지 송수신 구조와 카프카를 이용하는데 알아야할 기본 용어를 설명한다. 아래는 이번 장에서 다룰 토픽들이다. 

1. 메시지 송수신 기본
2. 시스템 구성
3. 분산 메시징을 위한 구조
4. 데이터 견고함을 담보하는 복제의 구조

각 항목은 카프카를 이용하는데는 기본적인것들이지만, 1~3번은 카프카를 이용한 개발자나 사용자에게 중요하고 4번은 카프카를 이용한 플랫폼 설계, 운용 엔지니어에게 더 중요하다. 

# 메시지 송수신

아래는 메시지 자체와 연관된 개념이다.

메세지
: 카프카에서 다루는 데이터의 최소 단위. 메시지는 Key와 Value를 가지며 메시지 전송할때 파티셔닝에 사용된다.

토픽
: 메시지의 종류를 토픽이라라 부른다. 토픽은 메세지 종류를 관리하는 스토리지를 브루는 호칭이기도 하다. 토픽은 브로커에 배치되어 관리된다. 프로듀서와 컨슈머는 특정 토픽을 지정하여 메시지를 송수신함으로써 카프카 클러스터에서 여러 종류의 메세지를 중계한다. 

# 시스템 구성

이제 카프카를 동작시키는데 필요한 시스템 구성 요소를 하나하나 자세히 알아보자.

## 브로커

브로커는 하나의 서버(또는 인스턴스) 당 하나의 데몬 프로세스로 동작하여 메시지 수신/전달 요청을 받아들인다. 이것을 여러 대의 클러스터로 구성할 수 있으며 수신/전달 처리량의 향상을 위한 스케일 아웃이 가능하다. 

브로커로 받은 데이터는 모두 디스크에 저장하여(영속화)가 이루어지기 때문에 디스크의 용량 만큼 데이터를 장기간 보존할 수 있다. 


## 프로듀서 API/ 컨슈머 API

프로듀서/컨슈머를 구현하는 기능은 라이브러리 형태로 제공된다. 프로듀서를 구현하기 위한 API를 프로듀서 API, 컨슈머를 구현하기 위한 API를 컨슈머 API라 한다. 그러나 프로듀서, 컨슈머는 브로커 처럼 데몬 프로세스로 동작하는 프로그램은 아니며 각각 API는 자바이다. 

### 프로듀서

프로듀서는 프로듀서 API를 사용하여 브로커에 데이터를 송신하기 위해 구현된 **애플리케이션**이다. 실제로 프로듀서 기능을 내장하거나 서드 파티의 플러그인 제휴를 통해 제공하는 OSS(Open Soucre Software), 도구의 종류는 아래와 같다. 

* Apache Log4j(Kafka Appender)
	* 로그 출력시 사용하는 자바 기반 로깅 유틸리티 소프트웨어
* Apache Flume
	* 댜량의 로그 데이터를 효율적으로 수집, 취합, 이동하기 위한 분산형 소프트웨어
* Fluentd
	* 크로스 플랫폼 오픈소스 데이터 수집 소프트웨어
* Logstash
	* 엘라스틱서치에서 제공하는 OSS 데이터 수집 엔진

### 컨슈머

컨슈머 API를 이용해 브로커에서 메시지를 취득하도록 구현된 애플리케이션이다.  브로커는 브로커에 도달한 메시지를 그 즉시 컨슈머에서 취득애햐 한다는 제약이 없기 때문에 디스크에 보관된어 있는 동안은 메시지 취득이 가능하다. 

프로듀서와 마찬가지로 카프카 연계를 위한 컨슈머 기능을 갖춘 기존 제품도 많이 존재한다. 특히 Apache Spark (Streaming), Apache Storm, Apache Flink 등의 분산 스트림 처리 OSS에서 카프카가 갖춘 확장성을 유용하게 사용하는 경우가 많기 때문에 표준 라이브러리로 제공되고 있다. 

* Apache Spark
	* 빅데이터 처리를 위한 오픈소스 클러스터 컴퓨팅 프레임워크
* Apache Samza
	* 스트림 처리용 오픈소스 소프트웨어로 준 리얼타임 비동기 계산 프라엠워크
* Apache Flink
	* 스트림 처리용 오픈소스 프레임워크
* Apache Flume
* Fluentd
* Logstash

>Push, Pull 
프로듀서 - 브로커에서는 프로듀서에서 PUSH형으로 메시지가 전달된다. 브로커 - 컨슈머의 데이터 흐름에서는 메시지 송신 요청이 컨슈머로 부터 PULL형태로 메세지를 송신하게 된다. 

시스템 운영상의 PULL형태의 장점은 컨슈머 시스템 고장이나 유지보수로 정지한 경우에도 브로커에 미치는 영향이 적다. 브로커가 만약 Push 형인 경우, 컨슈머의 서비스 중단 시 대응을 매번 브로커에서 실시해야 한다. 

### 주키퍼 

브로커에게 있어 **분산 처리를 위한 관리도구인 아파치 주키퍼**가 필요하다. 주키퍼는 하둡등 병렬 분석 처리용 OSS에 있어서 설정관리, 이름 관리, 동기화를 위한 잠금 관리를 하는 구조로 자주 사용된다. 카프카에선 분산 메시지의 메타 데이터(토픽과 파티션등)을 관리하기 위한 구성 요소로 주로 사용한다. 주키퍼 클러스터(주키퍼 앙상블이라고도 한다)의 구조상 서버의 갯수는 홀수로 구성하는 것이 일반적이다. 

카프카 클러스터 - 카프카는 여러 대의 브로커 서버와 주키퍼 서버(클러스터링간 메시지 중계 기능) 그리고 프로듀서/ 컨슈머 API(메시지 송수신을 위한 라이브러리 그룹)로 구성된다. 

# 분산 메시징을 위한 구조 

## 파티션

하나의 브로커 안에는 복수의 토픽 스토리지가 있고 다시 토픽 스토리지안에는 파티션들이 존재한다. 

파티션은 토픽에 대한 대량의 메시지 입출력을 지원하기 위한 구조이다.  파티션은 브로커 클러스터 안에 분산 배치되어 프로듀서에서의 메시지 수신, 컨슈머로의 배달을 분산해서 실시함으로써 하나의 토픽에 대한 대규모 데이터 수신과 전달을 지원한다. 

각 파티션을 어디 브로커에 어떻게 배치하는 가에 대한 정보는 브로커 측에서 유지된다. 또한 프류도서/ 컨슈머 API에게 파티션들은 은폐되어 있어 있기 때문에 프로듀서/컨슈머에서는 토픽만을 히고, 구현시에 파티션을 인식할 필요가 없다. 

## 컨슈머 그룹

카프카는 컨슈머에서 분산 스트림 처리도 고려해 설계되어 있다. 컨슈머 애플리케이션은 단일 토픽(싱글 구조)이나 여러 파티션에서 메시지를 취득하는 방법으로 컨슈머 그룹이라는 개념이 존재한다. 

카프카 클러스터 전체에서 클로벌 ID를 컨슈머 그룹 전체에서 공유하고 여러 컨슈머는 자신이 소속된 컨슈머 그룹을 식별해, 읽어들일 파티션을 분류하고 제어한다.

## 오프셋 

각 파티션에서 수신한 메시지는 각각 일련번호가 부여되어 있어 파티션 단위로 메시지 위치를 나타내는 오프셋이라는 정보를 이용해 컨슈머가 취득하는 메시지의 범위 및 재시도를 제어한다. 제어에 사용되는 오프셋의 종류에는 아래와 같은 것이 있다. 

Log-End-Offsert(LEO) - 파티션 데이터의 끝을 의미
Cuurent Offset - 컨슈머가 어디까지 메시지를 읽었는가 의미
Commit Offset - 컨슈머가 어디까지 커밋 했는지 의미

LEO는 브로커에 의해 파티션에 관한 정보로 관리 및 업데이트된다. Commit Offset은 컨슈머 그룹마다 보관되어 관리, 업데이트 된다. Current Offset은 컨슈머에서의 데이터 취득을 계기로 업데이트된다. 

Commit Offset은 컨슈머로부터 여기까지의 오프셋은 처리했다는 것을 확인하는 오프셋 커밋(Offset Commit)을 계기로 업데이트 된다.  특정 토픽에 대해 여러 컨슈머 그룹이 메시지를 취득하는 경우에는 파티션에 대한 Commit Offset도 컨슈머 그룹 숫자만큼만 존재한다. 

## 메시지 송수신

카프카에게 있어 메시지 송신은 반드시 하나하나 메시지 단위로 송수신하는 것이 아니다. 송수신 처리량을 높이기 위해서 어느 정도 메시지를 축적하여 배치처리로 송수신하는 기능 또한 제공한다. 

### 프로듀서의 메시지 송신

프로듀서가 토픽의 파티션에 메시지를 송신할때 버퍼처럼 프로듀서의 메모리를 이용하여 일정량을 축적 후 송신할 수 있다. 데이터의 송신에 대해서는 지정한 크기까지 메시지가 축적되거나, 지정한 대기 시간에 도달하는 것 중 하나를 트리거로 전송한다. 

트리거의 설정인 크기와 시간은 각각 프로듀서의 설정값인 batch.size와 linger.ms로 설정한다. 

기본 설정으로 하나의 메시지는 1회 송신되지만, 수 바이트에서 수십 바이트의 작은 메시지를 대량으로 브로커에 송신하는 상황에서는 네트워크의 지연이 처리량에 보틀넥인 경우도 있다.  이를 배치로 모아서 송신함으로써 처리량을 향상 시킬 수 있다. 

### 컨슈머의 메시지 취득

컨슈머는 취득 대상의 토픽과 파티션에 대해 Current Offet 까지 취득한 메시지까지 모아 취득한다. 즉 메시지의 유입 빈도가 동일한 경우, 컨슈머의 브로커로의 요청 간격일 길 수록 메시지가 많이 모인다. 

요청으로 제일 작은 단위인 메시지를 딱 하나만 요청하는 경우 하나의 메시지마다 Current Offset을 업데이트한다. 하나의 요청으로 5개의 메시지를 취득하는 경우, 마찬가지로 5개 메시지 만큼 Current Offset을 업데이트한다.

프로듀서 컨슈머 모두 어느정도 메시지를 모아 배치 처리하면 처리량을 향상시키는 효과를 기대할 수 있지만 프로듀서 송신과 컨슈머 수신 처리의 지연시간은 증가한다. 취급하는 시스템에 따라 밀리초에서 초단위의 지연시간도 바람직 하지 않는 경우도 있다. 따라서 배치 처리의 간격에 대해서는 처리량과 대기 시간의 트레이드 오프를 고려한 설계가 필요하다. 

## 컨슈머의 롤백

컨슈머는 위에서 언급한 바와 같이 오프셋을 진행하면서 지속적으로 메시지를 취득하지만, Offset Commit의 구조를 통해 컨슈머 처리 실패, 고장 시 롤백 메시지 재취득을 구현한다. 

즉 브로커와 컨슈머가 Commit Offset까지 메시지를 취득 및 처리가 완료된 상태이라고 하자. 컨슈머는 다음 메세지를 요청하고 브로커는 Current Offset을 요청 갯수 만큼 옮기고 컨슈머로 메세지를 보낸다. 만약 이후 부터 컨슈머에서 예기치 못한 장애가 발생하면, 브로커에서는 가장 최근의 Commit Offset까지 Offset 위치를 롤백하게 된다. 추후에 컨슈머가 장애에서 복구가 되면 롤백된 위치에서 부터 다시 컨슈머의 메시지 재취득 과정이 시작된다.

주의할 점은 Commit Offset까지 롤백된 메시지에 대한 대처는 컨슈머의 애플리케이션에 맡긴다는 것이다. 컨슈머의 롤백은 중복될 수 있는 메시지를 다시 요청하게 되기 때문에 At Least Once 트랜잭션일때 사용 가능한 구조다.  또한 고장의 감지, 복구에 대해서도 카프카에서 제공되는 것은 아니기 때문에 Consumer API를 이용한 애플리케이션 쪽에서의 처리가 필요하다.

다행히도 Spark Streaming등 카프카 연계 기능을 제공하는 대부분의 분산 처리 프레임워크는 컨슈머의 고장이나 쟁애를 감지하여 재실행하는 매커니즘이 있으므로 일반 사용자가 감지하여 메시지 재취득을 행하는 경우는 드물다. 

 ## 메시지 전송시 파티셔닝

프로듀서에서 송신하는 메세지를 어떤 파티션으로 보낼지 결정하는 파티셔닝(분할) 기능이 있다. 메시지에는 Key,Value 값이 있으며 값에 따라 다음 두 가지 패턴 로직에 따라 분류가 된다. 

* Key 해시 값을 사용한 송싱
	* 메세지의 Key값을 명시적으로 지정하여, Key값에 따라 송신처 파티션을 결정하는 로직이된다. 즉 동일한 Key를 가진 메시지는 동일한 ID를 가진 파티션으로 송신된다.
* Round-Robin에 의한 송신
	* 메시지 Key를 지정하지 않고 NULL로 한 경우, 여러 파티션으로의 메시지 송신을 라운드 로빈 방식으로 실행한다. 

예를 들어, 웹의 엑세스 로그를 송신할때 발신지 IP 주소에 따라 파티션별로 나누어 던지는 경우는 로그 안에서 '발신지 IP 주소'를 Key로 설정하여 전송하여 가능하다. 이렇게 파티셔닝을 이용하여 동일한 Key를 가진 메시지는 동일한 컨슈머에서 취득하여 처리하는 식으로 제어할 수 있다. 그러나 파티셔닝을 이용하는 경우 데이터의 편차에 따른 파티션의 평향에 대해 주의를 기울여야 한다. 

## 브로커의 데이터 보관기간

카프카는 수시한 메시지를 디스크에 영속화하고, 컨슈머는 브로커에 보관되어 있으면 과거의 데이터를 읽을 수 있다. 그렇다면 브로커가 수신한 토픽 데이터는 언제까지 보관되고 언제 삭제되는 것일까? 

현실적으로는 스토리지 용량 제한이 있기 때문에 무제한 기간을 둘 수 는 없다. 크게는 두 가지 정책으로 데이터 삭제를 정할 수 있다. 

* 오래된 메시지 삭제
* 압축

오래된 메시지 삭제의 경우 축적된 메시지 중에 오래된것 부터 삭제한다. 삭제 트리거는 메시지 취득 후 경과 시간, 데이터 크기 두 가지로 설정할 수 있다.

* 데이터 취득후 경과 시간을 트리거로 할 경우 
	* 시간, 분, 밀리초로 지정 가능하며, 지정한 시간보다 오래된 데이터는 삭제된다.(기본 1주)
* 데이터 크기를 트리거로 한 경우
	* 축적 데이터가 지정한 데이터 크기보다 커진 경우 데이터가 삭제된다.(기본 -1(크기 제한없음))

압축의 경우는 최신 Key 데이터를 남겨두고 중복되는 Key의 오래된 메시지가 삭제된다. 동일한 Key에 대해서 항상 최신의 Value만 얻을 수 있으면 되는 상황에서 사용할 수 있다. 

예를 들면, RDMS의 INSERT나 UPDATE된 레코드를 카프카에서 수신하는 경우, 변경된 가장 최신의 값만 취득하면 되기 때문에 데이터 삭제가 아닌 압축을 설정하여 디스크 용량과 I/O를 효율적으로 이용하면서 레코드를 유지할 수 있다. 

## 데이터의 견고성을 높이는 복제 구조

카프카는 메시지를 중계함과 동시에 서버가 장애 났을때에 수신한 메시지를 잃지 않기 위해 복제 구조를 갖추고 있다.

파티션은 단일 또는 여러개의 레플리카로 구성되어 토픽단위로 레플리카 수를 지정할 수 있다. 또한 레플리카 중 하나는 Leader에 해당하며 나머지는 Follwer라 불린다. Follwer는 그 이름대로 Leader의 메세지를 지속적으로 취득하여 복제를 유지하도록 동작한다. 다만 프로듀서/컨슈머와 데이터 교환은 Leader가 맡고있다. 

### 레플리카의 동기 상태

Leader Replica의 복제 상태를 유지하고 있는 레플리카는 In-Sync Replica로 분류된다. In-Sync Replica는 ISR로 줄여 나타내기도 한다. 모든 레플리카가 ISR이 아닌 파티션으로 설정된 경우 Under Replicated Partitions라고 부른다. 또한 복제 수와는 독립적으로 최소 ISR 수(min.insync.replica) 설정이 가능하고 고장등으로 일시적인 동기 지연을 허용하여 전체 읽고 쓰기를 계속하는 것이 가능하다. 


### 복제 완료 최신 오프셋(High Watermark)

복제 사용시 오프셋 관리에는 LEO(Log End Offset) 이외에 High Watermark라는 개념이 있다. High Watermark는 복제가 완료된 오프셋이며, 반드시 LEO와 동일하거나 더 오래된 오프셋을  나타낸다. 컨슈머는 High Watermark까지 기록된 메시지를 취득할 수 있다. 








> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEyMjMzMjI3MjIsLTIxMzQxODg4MDgsMj
EzNzA4NzM4MiwtNjU5MDMwNjExLDE5NDk3MjI3MzAsMTYyMTcw
Mzc4MSwyMDcxMjA5MTU5LC0xMDMwMTQ1NzAyLC05MTUyMzM0ND
UsLTkxOTAyNzQ0NSwtMTMxNTIyMzc2MywxNzYyNzI5MDY5LC02
MTIyMzY3OTksMTgyMjU1OTEwOSwtMjc4MTg3OTIsMTc4ODA3NT
c2OSwtMTIzNTUwMzkxNiwtMzU0MTk4MzMwLC0xMDQyODM4ODEw
LC03OTE3NTQ1NDVdfQ==
-->