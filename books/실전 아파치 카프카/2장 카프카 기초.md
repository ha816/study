# Overview

이 장에서는 카프카의 메시지 송수신 구조와 카프카를 이용하는데 알아야할 기본 용어를 설명한다. 카프카는 여러 구성 요소로 이루어져 있어 개별 구성 요소를 파악하는 것만으로는 전체적인 그림을 이해하기 어렵다. 개요부터 시작하여 내부동작까지 단계적 설명을 하겠다. 주요 내용은 아래와 같다. 

1. 메시지 송수신 기본
2. 시스템 구성
3. 분산 메시징을 위한 구조
4. 데이터 견고함을 담보하는 복제의 구조

각 항목은 카프카를 이용하는데는 기본적인것들이지만, 1~3번은 카프카를 이용한 개발자나 사용자에게 중요하고 4번은 카프카를 이용한 플랫폼 설계, 운용 엔지니어에게 더 중요하다. 

# 메시지 송수신 기본

우선 카프카의 기본이 되는 데이터 중계를 위한 시스템 논리 구성을 알아보자.  시스템 구성 및 내부 동작 등 물리적 구성은 다음 절 이후에서 설명하므로 우선 논리적 구성과 기본 용어를 파악해보자. 

카피카의 주요 구성요소 

브로커(Broker) 
- 데이터를 송신,수신하는 서비스

메세지
- 카프카에서 다루는 데이터의 최소 단위, 카프카가 중계하는 로그의 한줄 한 줄과 센서 데이터 등이 이헤 해당한다. 메시지는 Key와 Value를 갖게 되며 나중에 언급할 메시지 전송할때 파티셔닝에 이용

프로듀서
- 데이터의 생산자이며 브로커에 메시지를 보내는 애플리케이션

컨슈머
- 브로커에서 메시지를 취득하는 애플리케이션

토픽
- 메시지의 종류를 토빅이라고 부른다. 
- 토픽은 메세지 종류를 관리하는 스토리지로도 여겨지며, 브로커에 배치되어 관리된다. 프로듀서와 컨슈머는 특정 토픽을 지정하여 메시지를 송수신함으로써 단일 카프카 클러스터에서 여러 종류의 메세지를 중계한다. 

# 시스템 구성

지금까지 메시지 전달에 필요한 각 구성요소의 논리 구성에 대해 살펴봤다. 이러한 구성요소를 동작시키는데 필요한 시스템 구성은 아래와 같다. 

이제 각 요소를 하나하나 자세히 알아보자.

## 브로커

브로커는 하나의 서버(또는 인스턴스) 당 하나의 데몬 프로세스로 동작하여 메시지 수신/전달 요청을 받아들인다. 이것을 여러 대의 클러스터로 구성할 수 있으며 브로커(리로스)를 추가할 수 있어 수신/전달 처리량의 향상을 스케일 아웃할 수 있다. 

브로커로 받은 데이터는 모두 디스크에 저장하여(영속화)가 이루어지기 때문에 디스크의 용량 만큼 데이터를 장기간 보존할 수 있다. 


## 프로듀서 API/ 컨슈머 API

프로듀서/컨슈머를 구현하는 기능은 브로커로 데이터를 보내고 브로커에서 데이터를 받기 위한 라이브러리로 제공된다. 프로듀서를 구현하기 위한 API를 프로듀서 API, 컨슈머를 구현하기 위한 API를 컨슈머 API라 한다. 

그러나 프로듀서, 컨슈머는 브로커 처럼 데몬 프로세스로 동작하는 프로그램은 아니며 각각 API는 자바이다. 

### 프로듀서

프로듀서는 프로듀서 API를 사용하여 브로커에 데이터를 송신하기 위해 구현된 애플리케이션이다. 즉 프로듀서 API를 사용한 어떤 애플리케이션도 되기 때문에 굉장히 종류가 다양하다. 

실제로 프로듀서 기능을 내장하거나 서드 파티의 플러그인 제휴를 통해 제공하는 OSS(Open Soucre Software), 도구의 종류는 아래와 같다. 

* Apache Log4j(Kafka Appender)
	* 로그 출력시 사용하는 자바 기반 로깅 유틸리티 소프트웨어
* Apache Flume
	* 댜량의 로그 데이터를 효율적으로 수집, 취합, 이동하기 위한 분산형 소프트웨어
* Fluentd
	* 크로스 플랫폼 오픈소스 데이터 수집 소프트웨어
* Logstash
	* 엘라스틱서치에서 제공하는 OSS 데이터 수집 엔진

### 컨슈머

컨슈머 API를 이용해 브로커에서 메시지를 취득하도록 구현된 애플리케이션이다. 브로커는 메시지를 디스크에 영속화하기 위해 브로커에 도달하는 즉시 컨슈머에서 취득애햐 한다는 제약이 없기 때문에 디스크에 보관된어 있는 동안은 메시지 취득이 가능하다. 일정 기간 데이터를 축적한 스토리지에서의 데이터 추츨 및 실시간 처리를 위한 애플리케이션의 데이터 입력등으로 이용된다. 

프로듀서와 마찬가지로 카프카 연계를 위한 컨슈머 기능을 갖춘 기존 제품도 많이 존재한다. 특히 Apache Spark (Streaming), Apache Storm, Apache Flink 등의 분산 스트림 처리 OSS에서 카프카가 갖춘 확장성을 유용하기 사용하는 경우가 많기 때문에 표준 라이브러리로 제공되고 있다. 

* Apache Spark
	* 빅데이터 처리를 위한 오픈소스 클러스터 컴퓨팅 프레임워크
* Apache Samza
	* 스트림 처리용 오픈소스 소프트웨어로 준 리얼타임 비동기 계산 프라엠워크
* Apache Flink
	* 스트림 처리용 오픈소스 프레임워크
* Apache Flume
* Fluentd
* Logstash

>Push 형, Pull 형

카프카 시스템에슨 프로듀서 - 브로커 - 컨슈머 흐름으로 이동하는데, 두 노드 간 메시지 전달을 어느쪽에서 발생시킬지에 대해 이해하면 좋다. 

프로듀서 - 브로커에서는 프로듀서에서 PUSH형으로 메시지가 전달된다. 브로커 - 컨슈머의 데이터 흐름에서는 메시지 송신 요청이 컨슈머로 부터 PULL형태로 메세지를 송신하게 된다. 

시스템 운영상의 PULL형태의 장점은 컨슈머 시스템 고장이나 유지보수로 정지한 경우에도 브로커에 미치는 영향이 적은 것을 들을 수 있다. 브로커가 PUSH 형인 경우 컨슈머의 서비스 중단 시 대응을 매번 브로커에서 실시해야 한다. 

카프카를 경유하는 메시지와 후속 시스템이 많을수록 시스템 운용 부하 및 성능 부하가 증가할 것이다. 또한 브로커의 컨슈머 요청을 기다리기, 요청에 대응해서 메시지 보내기 라는 구조와 오프셋에 따른 진행관리 덕분에 중계 역할을 하는 브로커는 후속 시스템이 동적으로 증감해도 컨슈머별 개별 대응이 적아. 컨슈머 자신이 주체적으로 데이터를 수신, 진행 관리를 하기 때문이다. 

### 주키퍼 

카프카 브로커에 있어 분산 처리를 위한 관리도구로 아파치 주키퍼가 필요하다. 주키퍼는 하둡등 병렬 분석 처리용 OSS에 있어서 설정관리, 이름 관리, 동기화를 위한 잠금 관리를 하는 구조로 자주 사용된다. 카프카에 있어서는 분산  메시징의 메타 데이터(토픽과 파티션등)을 관리하기 위한 구성 요소로 가능하다. 주키퍼 클러스터(주키퍼 앙상블이라고도 한다)의 구조상 서버의 갯수는 홀수로 구성하는 것이 일반적이다. 

카프카 클라이언트 - 토픽 작성등 카프카의 동작 및 운영 상에 필요한 조작을 실행하는 서버다. 메시지의 송수신을 처리하는 서버가 아니다. 

카프카 클러스터 - 카프카는 여러대의 브로커서버와, 주키퍼 서버(클러스터링의 메시지 중계 기능) 그리고 프로듀서/ 컨슈머 API(메시지 송수신을 위한 라이브러리 그룹)로 구성된다. 

## 분산 메시징을 위한 구조 

### 파티션

토픽에 대한 대량의 메시지 입출력을 지원하기 위해, 브로커상의 데이터를 읽고 쓰는 것은 파티션이라는 단위로 분할되어 있다. 토픽을 구성하는 파티션은 브로커 클러스터 안에 분산 배치되어 프로듀서에서의 메시지 수신, 컨슈머로의 배달을 분산해서 실시함으로써 하나의 토픽에 대한 대규모 데이터 수신과 전달을 지원한다. 

각 파티션을 어디 브로커에 어떻게 배치하는 가에 대한 정보는 브로커 측에서 유지된다. 또한 프류도서/ 컨슈머 API에게 파티션들은 은폐되어 있어 있기 때문에 프로듀서/컨슈머에서는 토픽만을 지정학, 구현시에 파티션을 인식할 필요가 없다. 

### 컨슈머 그룹

카프카는 하류 시스템(컨슈머)에서 분산 스트림 처리도 고려해 설계되어 있다. 단일 애플리케이션 안에서 여러 컨슈머가 단일 토픽이나 여러 파티션에서 메시지를 취득하는 방법으로 컨슈머 그룹이라는 개념이 존재한다. 

카프카 클러스터 전체에서 클로벌 ID를 컨슈머 그룹 전체에서 공유하고 여러 컨슈머는 자신이 소속된 컨슈머 그룹을 식별해, 읽어들일 파티션을 분류하고 제어한다.

### 오프셋 

각 파티션에는 수신한 메시지는 각각 일련번호가 부여되어 있어 파티션 단위로 메시지 위치를 나타내는 오프셋이라는 관리 정보를 이용해 컨슈머가 취득하는 메시지의 범위 및 재시도를 제어한다. 제어에 사용되는 오프셋의 종류에는 아래와 같은 것이 있다. 

Log-End-Offsert(LEO) - 파티션 데이터의 끝을 의미
Cuurent Offset - 컨슈머가 어디까지 메시지를 읽었는가 의미
Commit Offset - 컨슈머가 어디까지 커밋 했는지 의미

LEO는 브로커에 의해 파티션에 관한 정보로 관리 및 업데이트된다. Commit Offset은 컨슈머 그룹마다 보관되어 관리, 업데이트 된다. Current Offset은 컨슈머에서의 데이터 취득을 계기로 업데이트된다. 

Commit Offset은 컨슈머로부터 여기까지의 오프셋은 처리했다는 것을 확인하는 오프셋 커밋(Offset Commit)을 계기로 업데이트 된다.  특정 토픽에 대해 여러 컨슈머 그룹이 메시지를 취득하는 경우에는 파티션에 대한 Commit Offset도 컨슈머 그룹 숫자만큼만 존재한다. 

### 메시지 송수신


 
> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbMjc1NDI3MDg5LC0yMTQ0MDIyODMyLC0xMj
Y4NTk0Njg4LC01OTgyMTQzNjYsLTEzOTU0NzYwMSwtOTk3NDQ2
NTE4LC0xMDk3NDUwODg3LDE1MTU2MzcxMjUsLTE3Mzk4NDI0Mj
ksMjQwMDU5MzEyLDY3NDcyMTAxNSwtNjI0NTUzOTcsMTA0ODM4
OTU4OCwtMTkzMTQzODczMyw4NTM1MDA1NSwtMTAyMzU1NDkzMC
wtMTcxMTM4MTIyMywtMjA0ODcwMzA4OCwtMzA4NTQyMTk5LC05
NzU3MDAyMTVdfQ==
-->