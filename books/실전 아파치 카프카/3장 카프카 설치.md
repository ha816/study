# 3장 카프카 설치

이번 장에서는 카프카 배포안인 컨플루언트 플랫폼을 이용한 카프카 클러스터 구축 방법을 소개한다. 

http://www.osckorea.com/solution/confluent

카프카 클러스터는 1대 이상의 브로커로 구성되는 점을 고려하여 서버를 1대만 사용하는 경우와 여러대를 사용하는 경우 각각에 대한 구축법을 알아보자. 여기서 만든 클러스터는 이후 4장 이후의 예제로 사용된다. 

# 카프카 클러스터 환경

## 클러스터 구성

카프카는 1대 이상의 브로커로 이루어진 카프카 클러스터, 프로듀서, 컨슈머와 카프카 클러스터를 실행하는 카프카 클라이언트로 구성된다. 

* 브로커들의 집단이 카프카 클러스터
* 카프카 클러스터를 실행 및 관리하는 카프카 클라이언트
* 프로듀서와 컨슈머

카프카 클라이언트는 클러스터의 상태 관리 및 운영에 필요한 다양한 조각을 제공한다. 이번 장의 구축예로 클러스터 3대 서버, 클러스터 1대 모두 단계를 알아보자. 

## 소프트웨어 구성

카프카 클러스터는 1대 이상의 브로커와 주키퍼로 구성되어 있다. 이장에서 구축할 카프카 클러스터는 브로커와 주키퍼를 동일 서버에 함께 설치하는 구성으로 한다. 또한 프로듀서, 컨슈머, 카프카 클라이언트에는 동작에 필요한 라이브러리와 도구를 설치한다. 

여기선 클러스터를 구성하는 각 서버에 카프카 브로커와 주키퍼를 함께 짝을 지어 설치한다. 주키퍼는 지속적인 서비스를 위해 과반수가 동작하고 있어야 한다. 이러한 환경에서 주키퍼는 홀수의 노드 수가 바람직하다. 

실제 사용시 브로커와 주키퍼를 동일 서버에 함께 설치할지 여부는 시스템 요구에 따라 달라진다. 필요한 서버 수를 줄이기 위해서 동일한 서버에 함께 설치하거나, 하둡과 같은 다른 미들웨어와 공유하기 위해 별도로 구축하는 등 각각의 사정을 고려하여 결정한다.

카프카클라이언트 서버에는 클러스터 조작에 필요한 도구를 설치한다. 프로듀서와 컨슈머는 실행 애플리케이션에 따라 카프카 라이브러리를 필요로 하는 경우도 있어 미리 설치하면 좋다.

**주키퍼**

주키퍼는(Zookeeper)는 분산 코디네이션 서비스를 제공하는 오픈소스 프로젝트입니다. 주키퍼의 아키텍처는 znode를 제공하기 위한 안정적인 분산 시스템을 구현하기 위해 설계되었습니다. 

![](https://t1.daumcdn.net/cfile/tistory/9993623A5BF7B2CD28)

클라이언트들은 주키퍼 서버들로 이루어진 앙상블(Ensemble)에 접근하여 znode의 데이터를 읽거나 데이터를 업데이트 합니다. 앙상블안의 주키퍼 서버들은 조율된 상태이며 항상 동일한 데이터를 가지고 있습니다. 따라서 어느 서버에서 데이터를 읽어도 똑같죠.

만일 주키퍼 서버에 쓰기 동작을 할 경우에, 클라이언트는 특정 서버에 접속하여 그 서버의 데이터를 업데이트 합니다. 그리고 업데이트 된 서버는 leader의 역할을 맡은 주키퍼 서버에 그 데이터를 알리고 업데이트하죠. 이 업데이트를 감지한 leader 서버는 그 정보를 다른 곳에 브로드캐스트(Broadcast) 형식으로 알리게 됩니다. 그 업데이트 정보를 받은 나머지 Follower 주키퍼 서버들은 그 내용을 갱신하여 전체 서버들의 데이터들이 일관된 상태로 유지된 상태로 있게 됩니다.

## 카프카 패키지와 배포판

카프카 개발사인 아파치소프트웨어 재단이 배포하는 커뮤니티 버전의 패키지외에도 미국 컨플루언트, 클라우데라, 호튼웍스가 배포하는 배포판에 패키지로도 사용할 수 있다. 

|패키지/배포판|  개발사|
|--|--|
|커뮤니티버전  | 아파트재단|
|Confluent Platform  | 컨플루언트|
|클아두데러 아파치카프카 | 클라우데라|
|Hortonworks data platform| 호튼웍스

각 배포판은 자체적으로 개발한 도구를 추가하거나 배포판에 포함된 다른 도구와 연계를 위한 커스터마이징을 하고 있다. 따라서 카프카를 스파크와 같은 다른 미들웨어와 함께 사용하는 경우 조건을 따져봐야 한다. 

# 카프카 구축

## OS 설치 - 공통

카프카와 컨플루언트 플랫폼은 리눅스와 맥 OS에서 동작한다. 이 책에서는 CentOS7의 64비트를 사용한다. 

## JDK 설치

카프카 실행에는 JDK(Java Developement Kit)이 필요함으로 각 서버에 설치한다. JDK에는 오라클이 제공하는 JDK와 오픈소스인 OpenJDK가 있다. 

자바와 JDK는 여러버전이 존재하는데 책을 쓰는 시점에서 카프카가 지원하고 있는것은 버전 8뿐이다. 

```
sudo rpm -ivh /tmp/jdk-8u221-linux-x64.rpm
```

JDK 설치 후에 관련된 환경 변수를 설정한다. /etc/profile.d/java.sh라는 파일을 만들고 다음과 같이 작성한다. 

```
export JAVA_HOME=/user/java/default
export PATH=$PATH:$JAVA_HOME/bin
```

파일 작성 후 명령으로 환경에 반영한다. 

```
source /etc/profile.d/java.sh
```

환경 변수가 제대로 반영되어 자바 명령을 사용할 수 있는지 확인한다. 
```
echo $JAVA_HOME
/usr/java/default - 환경 변수가 제대로 표시되는지 확인

java - version
java version "1.8.0" - JDK이 버전이 제대로 표시되는지 확인
```

## 브로커의 데이터 디렉터리 설정

카프카 패키지를 설치한 다음 브로커 데이터 디렉터리를 설정한다. 
/etc/kafka/server.properties을 열고 다음과 같이 수정하자. 

```
log.dirs=/var/lib/kafka/data - 이미 작성되어 있는 것을 수정
```

여기에서 설정한 log.dirs는 브로커에서 사용하는 데이터 디렉터리를 설정하는 항목이다. 

## 여러 대에서 동직하기 위한 설정 

우선 주키퍼 설정을 한다. 주키퍼 설정 파일인 /etc/kafka/zookeeper.properties에 다음 내용을 추가한다.

```
initLimit = 10
syncLimit = 5

server.1 = kafka-broker01:2888:3888
server.2 = kafka-broker02:2888:3888
server.3 = kafka-broker03:2888:3888
```

initLimit과 syncLimit는 주키퍼 클러스터의 초기 접속 및 동기 타임아웃 값을 설정하고 있다. 이 타임아웃은 tickTime이라는 파라미터를 단위로 계산된다. tickTime은 기본값으로 3000ms이다. 

server.1=kafka-broker01:288:3888  부분은 클러스터를 구성하는 서버군의 정보를 담고 있다. 다음의 형식으로 클러스터를 구성하는 모든 서버만큼 작성한다.

```
server.<myid>=<서버 호스트명>:<서버 통신용 포트1>:<서버 통신용 포트2>
```

myid란 주키퍼 클러스터 내에서 각 서버 고유하게 부여되는 서버 번호다. 여기에서는 1,2,3이 된다. 

각 서버에 할당된 myid는 각 서버의 /var/lib/zookeeper/myid에 작성해야 한다. myid는 서버마다 다르기 때문에 실행하는 명령도 서버마다 다르다. 

```
echo 1 | sudo -u cp-kafka tee -a /var/lib/zookeeper/myid
echo 2 | sudo -u cp-kafka tee -a /var/lib/zookeeper/myid
echo 3 | sudo -u cp-kafka tee -a /var/lib/zookeeper/myid
```

다음으로 브로커를 추가한다. /etc/kafka/server.properties를 다음과 같이 수정한다. 

```
broker.id=<서버별로 정한 Broker ID> - 이미 작성되어 있는 것을 수정
broker.id.generation.enable = false - 새롭게 작성
zookeeper.connect = kafka-broker01:2181,kafka-broker02:2181,kafka-broker03:2181 - 이미 작성되어 있는 것을 수정
```

log.dirs 설정을 변경한 상태인데, 여기에서는 그 파일에 여러대의 서버에서 실행하기 위한 설정이다. 

broker.id는 브로커 ID를 설정하기 위한 항목이다. 브로커도 주키퍼의 myid와 마찬가지로 브로커마다 고유 ID를 부여해야 한다. 이 브


> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTU4ODI4MDU3MCw2NjMwODAwMzAsLTEzNj
QwMTkyODgsMTUxNTc5MTUyOCwtMTUzMDQ0NTE3MiwtMTE5MzY5
Njk3NiwtOTYzOTk4NzMxLC0xNzA1MzY0ODgwLDMwNjUzMzUzNC
wtOTg4MzgzMDk3LDg5MzYxNDQ1NSwtMTA3NjExNDc5MywtMzYz
NTkyMDgzXX0=
-->