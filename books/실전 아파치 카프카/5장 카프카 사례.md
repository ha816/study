# 카프카의 대표적인 기능

카프카의 대표적인 기능으로 떠올릴 수 있는 것은 메시지 큐 제품/ 로그 수집 /ETL 도구 등 예전부터 존재했던 몇몇 제품의 대체라고 할 수 있다. 

대부분 이전 제품에서 더 이상 취급하지 못할 정도로 대량의 데이터를 처리해야 할때 카프카를 검토했다고 생각하면 되겠다. 

아래는 카프카의 대표적인 기능이다. 

* 데이터 허브
	* 여러 시스템 사이에서 데이터를 상호교환한다.
* 로그 수집
	* BI 도구를 이용한 리포팅과 인공지능 분석을 위해 여러 서버에서 생성된 로그를 수집하고 축적할 곳엔 연결한다.
* 웹 활동 분석
	* 실시간 대시보드와 이상 탐지/부정 검출등 웹에서 사용자 활동을 실시간 파악한다.
* 사물인터넷
	* 센서등 다양한 디바이스에서 보낸 데이터를 수신해서 처리한 후 디바이스에 송신한다.
* 이벤트 소싱
	* 데이터에 대한 일련의 이벤트를 순차적으로 기록하고 CQRS 방식으로 대량의 이벤트를 유연하게 처리한다.

물론 위에서 열거한 모든 기능과 특징을 전부 사용하는 것은 드물다. 카프카는 유연한 구조이기 때문에 사례마다 다른 요구 사항을 토대로 기능을 취사 선택하거나 요구사항에 맞게 설정하는 경우가 많다. 

# 카프카 특징 복습

카프카는 대량의 데이터를 높은 처리량으로 실시간 처리 하기 위한 제품이다. 카프카의 아키텍처는 변함 없이 데이터 상호 교환을 위한 기반으로 발전해 왔다. 현재 카프카가 데이터를 전달하는 파이프라인 그 자체를 구성하기 위한 기반이라고 말한다. 

다시 한번 카프카로 실현할 수 있는 4가지 특성을 알아보자.

* 확장성
	* 여러 서버로 확장이 가능하기 때문에 데이터 양에 따라 시스텀 확장이 가능하다.
* 영속성
	* 수신한 데이터를 디스크에 유지할 수 있기 때문에 언제라도 데이터를 읽을 수 있다.
* 유연성
	* 연계할 수 있는 제품이 많아 제품이나 시스템을 연결하는 허브 역할을 한다.
* 신뢰성
	* 메시지 전달 보증을 하므로 데이터 분실을 걱정하지 않아도 된다.

카프카는 위 4가지 실현을 위한 아키텍처로 Pub/Sub 메시지 모델에 기반한다. 메세지 큐 모델과는 달리 동일한 메시지를 여러 곳에 전달하는 이른바 동보 전송도 가능하다. 특히 메세지를 토픽에 포함된 파티션 단위로 한정하면 메시지의 순서 보증 실현도 가능하다. 

이러한 특성을 바탕으로 대량의 데이터를 처리해야 할때, 카프카의 각 기능과 특징이 중시되는 상황을 정리하면 아래와 같다.

* 실시간
	* 긴급성이 요구되거나 데이터를 즉시 사용하는 경우
* 동보 전송
	* 하나의 동일한 데이터를 후속의 여러 시스템에서 사용하는 경우, 데이터를 전달하는 관계 시스템이 단계적으로 증가하는 경우
* 영속성 
	* 데이터를 버퍼링 해야하는 경우나 처리 시산 간격이 다른 복수의 처리와 관련된 경우
* 다수의 제휴제품
	* 사용하는 제품이 균일하지 않고 다양한 경우도 가능
* 송수신 보증
	* 데이터 손실이 허용되지 않는 경우
* 순서 보증
	* 데이터 소스에 있어 데이터의 생성 순서를 중시하여 순서에 따른 판단과 제어를 수반하는 경우


# 데이터 허브

데이터 허브란 여러 데이터 소소를 제공하는 시스템에서 데이터를 수집하여 여러 시스템에 전달하는 아키텍처를 말한다. 

## 데이터 허브에서 다룰 문제

독립된 시스템이 많은 회사는 각 시스템 간 데이터 연계를 어떻게 할것인지에 대한 문제가 있다 그러한 문제로 아래와 같이 고려할 사항들이 있다.

* 데이터 형식은 무엇이 좋은지? CSV?
* 데이터 송신 시간은 하루에 한번?
* 상대 시스템이 배포 중일땐 어떻게 할지
* 장애가 발생했을때 데이터를 잃지 않기 위해서...?

예를 들어 처음 한 개의 연계 허브 시스템이 있고 이것이 3개의 송신처와 연결된다고 가정하자. 이 과정에서 3개의 각 시스템 별로 연계를 하려면 상당한 시간과 노력이 든다. 

그렇게 만들었다고 해도 추가 연계 시스템이 늘어난다면 또 수습할 일이 생긴다. 이 처럼 시스템이 분리되어 시스템 간의 연계를 효율적으로 할수 없는 상황을 **사일로(silo)**화 되었다고 한다.

[사일로
](https://m.blog.naver.com/PostView.nhn?blogId=jskimco&logNo=60178713431&proxyReferer=https://www.google.com/)

사일로화된 시스템은 IT 기술 보급과 함께 전세계적으로 발생했다. 그리고 사일로화 문제를 해결하기 위해 여러 솔루션도 개발되었다. 

사일로 현상을 피하기 위해선 아래와 같은 과제를 해결해야 한다.

* 데이터 소스에서 생성된 동일한 데이터를 여러 시스템에서 이용한다. 
* 후속 시스템마다 데이터를 필요로 하는 시기와 빈도가 다르다. 
* 접속원이나 연결 시스템에서 이용되는 연계방식이 제각각이다. 
* 데이터 분실을 허용하지 않는다. 

## 데이터 허브

사일로화를 해결하기 위한 개념의 하나로 데이터 허브 아키텍처가 있다. 데이터 허브 아키텍처란 데이터 소스가 되는 시스템에서 데이터를 수집하여 해당 데이터를 여러 시스템에 전달하는 아키텍처이다. 

상류와 하류 시스템사이에 카프카가 데이터 허브의 역할을 하게 된다. 데이터 허브 아키텍처에서는 시스템을 일대일로 연결하는 대신 모든 시스템이 데이터 허브에 데이터를 보내고 데이터 허브에서만 데이터를 받을 수 있도록 되어 있다. 이렇게 하면 시스템은 데이터를 데이터 허브에 보내는것에만 집중하고, 데이터를 수신하는 측에서는 데이터를 허브에서 받는것만 집중하면 된다 

즉 어떻게는 모든 시스템은 카프카에 연결하기만 하면 된다로 해결된다. 

* 동보전송
	* 데이터 소스에서 생성된 동일 데이터를 여러 시스템에서 이용할 수 있다. 이는 Pub/Sub 메시징 모델로 착안하였기에 실현 가능하다.
* 영속화
	* 데이터를 필요로 하는 시기가 달라도 카프카는 데이터를 영속화 하기 때문에 임의의 시기에 추출이 가능하다. 
* 다수 연계 제품
	* Kafka Connect로 연계할 수 있는 제품이 다수 있기 때문에 접속원이나 연결 시스템에서 사용하는 제품이 다수라고 하더라도 이에 대응할 수 있을 가능성이 높다.
* 송수신 보증
	* 카프카는 데이터 분실을 허용하지 않는 요구에 대한 송수신을 만족한다. At Least Once, Exactly Once등 서로 다른 송수신 보증에도 대응할 수 있다. 

이와 더불어 데이터 허브로서 시스템을 중개하려면 단순한 데이터만 가져오기, 단순히 데이터만 모으기만을 하는 것이 아니라 여러 시스템에 대해 사용법에 맞게 사용하기 쉬운 방식으로 데이터를 보관하는 것도 중요하다. 

## 로그 수집

여러 서버에 존재하는 로그 파일을 모아서 한 곳에서 보관하고 싶은 경우가 있다. 예를 들면, 여러 로그의 결과를 모아서 Bi도구나 대시보드에서 시각화하고 싶은 경우다. 도는 집약한 로그를 이용하여 머신 러닝을 구현하고 싶을 수도 있다. 더 간단하게는 여러 서버의 로그를 확인하기 위해 그 서버에 들어가 확인하는 것이 귀찮을 수도 있을 것이다. 로그 수집을 간단하다고 생각할 수 있지만 애플리케이션이 늘어나면서 외부 연계가 늘어나면 그 노력도 배로 증가한다.

### 로그 수집에서 문제 

로그 수집은 우선 여러 데이터 소스와 연결되어야 한다. 데이터 소스로 사용하는 제품이 동일하다면 그 제품이 특화된것도 괜찮지만 다양한 제품과 연계를 염두해 두어야 한다. 

또한 일괄적으로 일정 간격마다 축적하는 것과 함께 버퍼가 넘쳐 로그를 잃는 일이 벌어지면 곤란하기에 대량의 로그를 받아 일정한 모음으로 집약하고 버퍼링하기 위한 장치가 필요하다. 

마지막으로 로그 전달시 로그를 잃어서는 안된다. 약간의 손실을 허용하는 경우가 있겠지만, 엄격한 트랜잭션 관리까지는 아니더라도 로그가 손실되어서는 안된다는 것이 현실적인 요구다.

### 카프카 로그 구현

이러한 과제를 해결하는데 있어 카프카가 유용한 점은 다음과 같다. 

* 다수의 연계 제품
	* 카프카에는 Producer API가 있어 이를 이용하여 카프카와 접속하는 애플리케이션을 만들 수도 있다. 처음부터 애플리케이션을 작성하는 것이 힘들다면 단순히 서버 로그만을 집계하는 경우 FluentId를 도입하여 FluentId와 카프카 조합을 구성하는 것도 좋다. 또한 Kafka Connect를 사용하는 경우는 컨플루언트 플랫폼이나 커뮤니티에서 제공되고 있는 여러 커넥트를 이용해 카프카와 연계할 수 있다. 
* 영속화
	* 카프카는 데이터를 디스크에 영속화한다. 메모리 공간보다 더 큰 데이터라면 이를 디스크에 보관해 혹여 메모리 안에서 손실되거나 제외되더라도 나중에 읽을 수 있도록 되어 있다. 카프카를 메모리 공간을 넘어서는 큰 용량의 버퍼로 이용할 수 있다는 점이 로그 수집에서 카프카를 사용하는 큰 이유라고 할 수 잇다. 
* 송수신 보증
	* 링크드인의 사례처럼 At Least Once(적어도 한번 보내기) 수준의 송수신을 보증한다. 약간의 손실을 보장하는 경우 Ack를 반환하지 않으므로 데이터 소스 쪽의 처리를 줄여 성능을 향상 시킬수도 있다.

## 웹 활동 분석

웹 활동 분석은 웹 사이트를 방문하는 사용자의 행동을 파악하여 마케팅에 활용하기 위한 작업이다. 사용자가 웹에서 클릭하는 활동은 기본적으로 모두 로그에 남기 때문에 사용자가 웹 사이트 페이지 사이를 어떤 식으로 이동했는지 파악할 수 있다. 

대표적인 웹 활둥 분석으로 알 수 있고 이를 통해 실현하고 싶은 것은 아래와 같다. 

* 페이지 뷰와 전환율(성공 또는 구매율) 파악
* 개인화된 권장 사항
* 로얄 고객 파악
* A/B테스트에 의한 웹사이트 개선

웹 사이트 엑세스 분석에는 일정량의 로그를 받아 데이터 베이스나 웨어하우스에 투입하여 엑세스 해석 전용 도구로 분석을 하는 경우가 대부분이다. 

이때 외부에서 제공하는 서비스를 쓰지 않고 자신이 직접 로그 분석환경을 만드는 경우 위의 데이터 허브나 로그 수집에서 언급한 환경을 구축하게 된다. 이것이 배치 처리적 분석 환경 구축이라고 할 수 있다 

그러나 배치 처리적 접근에는 사용자의 행동을 실시간으로 반영하려는 요구가 반드시 나타난다. 전형적인 예는 아래와 같다. 

* 상태 업데이트가 시시각각 표시되는 실시간 대시보드 구축
* 실시간 이상 탐지/부정 검출
* 실시간 사용자의 행동을 추적하여 서비스 이탈 방지

### 웹 활동 분석의 문제 

실시간을 실현하기 위한 구조

긴급성과 즉시성을 필요로 하기 때문에 이를 실현하기 위한 구조가 필요하다. 실시간으로 데이터를 받으려면 어떻게 하면 좋을지, 데이터 파이프라인 내부 어디에서 실시간 처리할 것인지, 이를 위해 어떤 제품을 사용할지 검토가 필요하다.  또한 레코드 단위로 작업을 해야하는지, 수 밀리초 시간폭으로 여러 레코드 단위로 처리해도 상관 없는지 요구 조건을 파악해야 한다.

여러 데이터 소스와 접속

데이터를 생성하는 쪽 시스템이 여럿 있을 경우, 해당 시스템들과 접속할 수 있어야 한다. 데이터 허브의 문제와 같다. 

데이터 분실 방지

예를 들어, 이상 탐지, 부정 검출을 위해선 데이터 레코드가 손실 되었을 경우, 확인할 방법이 없다. 따라서 레코드를 잃지 않기 위해선 송수신 보증이 필요하다. 단 웹 서비스 경우는 중복 없이 1건 송신을 하는 것을 엄격히 요구하는 경우는 그리 많지 않다고 한다. 왜냐하면 Exactly Once라고 하면 데이터 처리량이 감소하고 구현이 복잡해지기 때문이다. 따라서 대량의 데이터를 처리해야 하는 경우 데이터 분실을 허용하지 않는 선인 At LeastOnce 수준으로 제공하는 경우가 많다. 

순서 보증

순서 보증의 경우, 온라임 게임에서 사용자 이탈 방지를 위한 사례가 있다.  사용자의 동작을 추천한 데이터는 서비스 개선에 활용하거나 사용자가 현재 어떤 상황에 있는지도 분석할 수 있다. 데이터를 잘 활용하면 사용자가 게임에 어떤 부분에 실증이 났는지 알 수 있다는 의미다. 

그래서 실증난 게이머에게 즉시 특별 이벤트를 주거나 재밌는 이벤트를 파악할 수 있다. 사용자가 어떤 상황인지를 파악하는 아이디어로 사용자의 행동 순서를 고려하는 방법이 있다.  그렇기에 사용자의 행동 순서를 순서대로 데이터를 받기 위한 시스템이 필요하다. 

### 카프카로 웹 활동 분석 해결하기

위 문제는 사실 카프카를 사용하면 실시간, 다수의 연계 제품, 송수신 보장, 순서 보증이라는 기능이 있어 카프카를 적용하기 적합하다. 

실시간으로 처리하는 부분은 카프카 스트림을 활용하는 방법도 있고, 카프카 뒤에서 스파크의 스트림 처리를 위한 구성 요소인 Structured Streaming을 이용하는 방법도 있다. 

실시간 방생하는 데이터를 간헐적으로 수신하고, 수신한 데이터를 바로 처리하기 때문에 이른바 스트림 처리가 가능하다. 

스트림 처리 엔진에는 Apache Storm, Apache Flink, Apache Samaze 등이 있다. 

>스트림 처리란?
>스트림 처리는 실시간 생성되는 데이터를 순차적으로 처리하는 방식이다. 실시간 데이터를 스트림 데이터라고도 부른다.
>스트림 데이터는 생성된 데이터가 모여 이루어진 파일 형태로 일정 기간마다 보내는 것이 아니라 킬로 바이트 정도의 매우 작은 단위로 지속적으로 보낸다. 
>기본적으로 스트림 처리는 축적하는 방식의 배치처리보다 고려사항이 많다. 왜냐하면 지속적으로 데이터를 처리해야 하므로 시스템 운용을 제약하지 않는 한 처리의 정지점을 마련하는 것이 어렵기 때문이다.
>정지점이 없다는 것은 시스템 운영에서 많은 어려움이 있다. 만약 특정 시점에 문제가 발생하면 해당 처리를 재실행하고자 해도 적절하게 우연하기도 어렵다. 

## 사물 인터넷

사물 인터넷이란 통신 기능이 있는 다양한 디바이스가 인터넷을 통해 서로 연결되어 있는 상태를 말한다. 센서나 통신 기기의 소형화, 저전력화에 따라 다양한 디바이스가 인터넷에 접속할 수 있게 되었다. 그리고 그런 디바이스에서 발생하는 대량의 데이터를 비교적 저렴하고 안정적으로 보관할 수 있도록 하둡과 클라우드 환경을 이용할 수 있게 된것이 그 배경이기도 하다. 

* 디바이스 모니터링
	* 개별 디바이스에게 정보를 직접 수집하고 디바이스 상태를 파악. 
* 예측 보전, 예측 보전/사전 감지
	* 디바이스의 상태를 시계열로 수집하고 수집한 데이터를 분석하여 디바이스의 고장을 사전에 파악해 고장 전에 교환한다.
* 품질 개선
	* 디바이스 모니터링을 실시해 시간 경과에 대한 성능 저하를 파악한 후에 제품 개발에 피드백하여 품질을 개선한다.
* 원격 제어
	* 디바이스에서 얻은 정보를 바탕으로 디바이스에 동작을 원격으로 제어

### 사물 인터넷 구현

사물인터넷은 매 순간 대량으로 구현되는 데이터를 어떻게 처리할 것인가가 큰 이슈이다. 또한 실시간으로 데이터를 교환하는 것과 여러 디바이스와 접속하는 것도 중요한 과제다. 

사물인터넷에선 여러 디바이스가 접목되어 인터페이스가 알기 쉬어야 한다. 특히 MQTT라고 하는 프로토콜에 대한 대응도 고려해야 한다.

이에 대해선 자세히 10장에서 설명하겠다.

## 이벤트 소싱

**이벤트 소싱**은 상태 변화 하나하나를 이벤트로 취급하여 발생하는 이벤트를 순서대로 기록하는 것이다. 사용자는 기록된 이벤트에서 도메인 객체를 구체화할 수 있으며 경위도 확인할 수 있다. 

쉽게 설명하면 DBMS 트랜잭션 로그(WAL)의 코드 쓰기를 상상하면 좋을 것이다. 카프카는 데이터를 모두 추상적인 로그로 취급하고 받은 메세지는 로그에 순차적으로 기록되기 때문에 카프카의 아키텍처 그 자체가 이벤트 소싱에 적합하다. 

CQRS(Command Query Responsibility Segregation) 커맨드 쿼리 책임 분리란 의미로 데이터의 갱신과 질의 처리를 분리하는 개념의 아키텍처다. 

커맨드란 데이터의 create/update/delete 등의 데이터 갱신 처리에 해당한다. 쿼리란 데이터 문의 또는 질의에 해당한다. 즉 CQRS는 Command(갱신)과 Query(질의)의 책임 분리를 말한다. 

갱신 처리시에는 응답 결과를 반환하지 않고 그 질의가 어떤 방법으로 처리되는지도 관여하지 않는다. 질의는 적절한 결과를 반환하는 것에만 책임이 있다. 

### 이벤트 소싱과 CQRS로 해결할 문제

제공하는 서비스에 따라 애플리케이션에서 기록할때와 읽을때 액세스 패턴이 크게 다르다. 대량의 데이터가 시계열로 기록되어도 읽을때는 시계열이 아닌 특정 ID로 읽고 싶을때도 있다. 또한 기록되는 데이터는 동일하더라도 데이터를 여러 목적으로 사용하고 싶을때도 있다. 

만약 처리의 부하가 높지 않다면 1대의 DB에서 쓰기와 읽기 전용 테이블을 2개 준비하여 테이블 형식을 변환하는 방법도 생각 할수 있다. 그러가 쓰기와 읽기 모두 부하가 높다면 튜닝 난이도가 높아진다. 이를 테면 메모리 사용법에 있어 전용 버퍼 공간을 많이 확보할지 아니면 읽기 전용 캐시로 공간을 많이 확보할지 메모리 사용은 어떻게 할지등이 있다. 

이렇게 1대의 DB서버에서 쓰기와 읽기를 효율적으로 구현할 수 없는 상황이 생기는 데, 이때 등장하는 것이 데이터 쓰기와 읽기를 분리하는 CQRS개념이다. 

### 카프카로 구현하기

CQRS개념을 위해서 카프카를 아키텍처로 사용가능하다. 카프카는 이벤트를 저장하는 저장소이며 이벤트를 전달하는 허브로 간주할 수 있다. 

CQRS는 아래와 같은 형태로 구현한다. 

* 카프카가 데이터 소스에서 시계열 데이터를 받아 기록한다. 즉 커맨드 역할을 한다.
* 카프카가 데이터 싱크에 데이터를 전달한다. 받은 쪽은 자신의 쿼리를 만드는데 있어 참고하기 좋은 데이터로 변환하여 사요




> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbOTQ4NDAxODI5LC05OTM2NzEwMjUsMTAzOT
kyODU2NSwtODgwNzIwNDE1LC0xNDA4Mzg1MTA1LDEyMTU1ODU5
MzMsNDE2MzkzMjQ3LC0yMDAxNjE5ODYxLDI3MzYzNzU4NSwtNj
IyMjY5MDY3LDE3MzI4MDE1NjEsLTcwMjE2NjA5MSwyMDM4MTc4
MzQzLC0xNTExOTc5NDEzLDE1NzU3MzI1MzIsLTI0MTI4MjM0LC
0xNTIwNzI1NzE4LDczMDk5ODExNl19
-->