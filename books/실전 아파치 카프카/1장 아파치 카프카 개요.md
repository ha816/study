# 1장 아파치 카프카 개요

1장에서는 아파치 카프카로 무엇을 할 수 있는지 살펴보자. 더불어 아파치 카프카가 탄생한 배경과 현재 산업계에 어떤 영향을 주고 있는지도 알아보자.

## 아파치 카프카

아파치 카프카는 여러 대의 분산 서버에서 대량의 데이터를 처리하는 분산 메세징 시스템이다. 메세지를 받고, 받은 메세지를 다른 시스템이나 장치에 보내기 위해 사용한다. 카프카는 여러 시스템과 장치를 연결하는 중요한 역할을 한다. 

카프카는 높은 처리량(high-throughput)과 실시간(real-time)성이 특징이며 아래와 같은 4가지 특성을 가진다.

확장성 - 여러 서버로 확장(scale out)할 수 있기 때문에 데이터 양이 많아져도 대처할 수 있다. 

영속성 - 수신한 메시지 데이터를 디스크에 유지 하기 때문에 데이터의 영속성이 유지된다.

유연성 - 지원하는 제품들이 많기 때문에 데이터 허브의 역할을 충실하게 할 수 있다. 

신뢰성 - 메세지 전달을 보증하기 때문에 데이터 분실을 걱정하지 않아도 된다. 

카프카는 원래 높은 처리량으로 데이터를 실시간 처리하는 처리 성능에 초점을 두었지만, 기능과 신뢰성을 향상 시켜 현재는 **종합 스트림 처리**를 위한 플랫폼이 되었다.  

카프카는 오픈소스로 공개되어 있으며 여러 기업의 엔지니어들이 참여하고 있는 커뮤니티에서 개발되고 있다. 오픈소스 제품에 흔히 존재하는 기업용 엔터프라이즈 버전이 없고 핵심인 커뮤니티 버전만 존재한다는 것도 매력적이다. 

## 탄생 배경

카프카는 2011년 미국 링크드인에서 출발했다. 카프카는 링크드인 웹사이트에서 생성되는 로그를 처리하여 웹사이트 활동을 추적하는 것을 목적으로 개발되었다. 웹사이트에서의 활동은 사용자가 페이지 뷰와 검색 시 키워드 광고의 이용상황도 포함된다. 웹에서 생성되는 대량의 로그를 분석하여 사용자가 웹에서 하는 활동을 모니터링하고 서비스 개선에 활용하는 것이다.

빅데이터를 어떻게 활용한 것인지 큰 화제였던 당시 많은 웹 기업에서는 웹사이트에서 생성되는 로그를 활용하기 시작했다. 

링크드인의 카프카가 실현하려는 목표는 위에서 언급했던 특징과 같으며 순서대로 자세히 알아보자. 

### 높은 처리량으로 실시간 처리

데이터가 많아지면 그것에 대응하여 처리량이 우수해야 한다. 또한 사용자의 활동을 신속하게 파악하거나 사용자의 활동에 따라 즉시 피드백하기 위해서는 사용자 활동 단위로 실시간 처리가 가능해야 한다. 여기서 말하는 실시간 처리는 수집부터 시작해 수백 밀리초안에 데이터가 처리되는 방식을 가정한다.

### 임의의 타이밍에 데이터를 읽는다. 

실시간 처리에 대한 요구가 있는 반면, 링크드인은 기존 시스템에서 수집한 엑세스 로그를 일정 시간마다 배치로 처리하고 싶다는 요구도 있었따. 데이터를 사용하는 타이밍이 반드시 실시간이 아니라 이용목적에 따라 다를 수 있기 때문에 방대한 데이터를 전달할때 버퍼 역할도 가능하기를 원했다. 

### 다양한 제품과 쉽게 연동

링크드인에서는 데이터의 발생원과 관련된 시스템이 하나가 아니어서 여러 시스템을 통해 데이터를 받아들어야 했다. 또한 이용 목적에 따라 데이터 베이스, 데이터 웨어하우스, 하둡등 여러 시스템에서 데이터를 읽어와야 했다. 

### 메세지를 잃지 않음

취급하는 메세지가 방대하더라도 메세지를 잃어서는 안됐다. 다만, 링크드인의 초기 목적은 웹에서 사용자 활동을 추적하는 것이였기 때문에 한건 한건의 활동을 엄격하게 관리하기 보다는 약간의 중복이 있더라도 잃지 않는것이 중요했다. 

건마다 엄격하게 관리하면 처리 오버헤드가 커지는 것은 알고 있어, 높은 처리량으로 실시간 처리라는 요건과 균형을 가미하여 현실적으로 버릴 부분을 찾아야 했다. 

## 카프카 이전 제품

당시에 카프카와 비슷한 제품들의 상황은 어땟을까? 요구를 부분적으로 충족하는 제품이 있었을지도 모르겠지만, 모든 것을 제공하는 제품은 없었다. 몇가지 제품을 알아보고 링크드인의 요구를 충족하지 못한 부분은 무엇인지 알아보자. 

### 메세지 큐

한건의 레코드 단위로 실시간 처리를 할때 가장 먼저 떠오르는 것은 메시지 큐다. 메세지 큐 제품으로는 IBM의 WebSphere MQ와 JMS 사양을 따르는 아파치 ActiveMQ, 그외 RabbitMQ가 있다. 

메세지 큐에서 제공하는 기능은 차이가 있긴하지만 대략 아래와 같다. 모두 링크드인의 요구와 맞지 않았다. 

#### 전달 보증(message transaction)

IBM WebSphere MQ는 메세지 단위로 트랜잭션을 지원하는 기능이 있다. 하나의 메세지가 정확히 한번만 전송되는 것을 보장할 수 있다. JMS에서도 사양으로 규정되어 있으며, 애플리케이션에서 commit, rollback을 기술하여 트랜잭션을 사용할 수 있다. 

그러나 링크드인에서 다루는 로그의 성질을 생각하면 엄격한 트랜잭션 관리는 다소 오버 스펙이며, 높은 처리량이 우선순위가 높았다. 

####  스케일 아웃(scale out)

대량의 메세지를 한 서버로 처리하는것은 한계가 있다. 그러므로 처음부터 서버가 늘어날 것을 가정하고 아키텍처를 설계해야 한다. 물론 메세지 큐 제품도 클러스터 구성을 생각 했지만 실제로는 처리 성능을 높이는 목적으로 필요시 노드를 추가할 수 있는 스케일 아웃 기능을 전제로 하는 제품이 없었다 

#### 메세지가 대량으로 쌓이는 것을 예상 못했다. 

카프카 등장 이전의 메세지 큐에서는 메시지를 쌓아 둘 수 잇었는데, 큐에 쌓인 메세지가 즉시 사용되는 것으로 예상했지 장시간에 걸쳐 대량으로 축적되는 것은 예상하지 않았다. 링크드 인에서는 실시간 처리 뿐만 아니라 메세지를 배치로 처리하는 것도 가정했기 때문에 일정량의 데이터를 묵음으로 받아 데이터 웨어하우스에서 처리하기 위해서는 축적 시간이 길어져야 했기 때문에 기존 메세지 큐로는 감당 할 수 없었다. 

### 로그 수집 시스템

이어서 데이터를 수집한다는 관점에서 생각 할 수 있는 다른 제품은 로그 수집을 위한 메들웨어다. 주로 웹 서버 드으이 프론트 엔드 서버의 로그를 수집하기 위한 것이다. 당시 이 카테고리에 해당하는 제품은 페이스북이 개발한 Scribe와 미국 클라우데라가 개발한 Flume이다. 

각 프론트엔드 서버가 로그를 중계용 서버에 전송하고 거기서 로그를 수집하여 데이터 베이스와 분산 파일 시스템에 축적한다. 원래 대량의 로그를 처리하는 것을 가정했기 때문에 분산환경의 다중 서버 구성으로 이루어져 있었다. 그러나 이러한 제품은 아래와 같은 문제가 있었다. 

> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTY5NTk2MzQ2OSwxNzk5MDIyMDY1LC0xNz
QwMzQ0NjE3LC04MDM4Mjk4MzEsLTEwNDI4MTM5MzYsLTIwNjE4
Nzg0MDksLTE2ODI2OTQzMjMsMTg4OTc0ODUyNyw0MzIxODQ0ND
ldfQ==
-->