# Overview

리액티브 방법은 스프링 생태계와 함께 한다면 더욱 좋습니다. 이번에는 스프링 클라우드 생태계가 제공하는 기능을 사용해 애플리케이션을 개선하는 방법과 **스프링 클라우드 스트림(Spring Cloud Stream)**을 사용해 완전한 리액티브 시스템을 구축하는 방법을 배울것 입니다. 또한 **RSocket** 라이브러리가 무엇인지 빠른 스트리밍 시스템을 개발하는데 어떻게 도움이 되는지 알아봅시다. 

#  Message Brocker 

메세지 기반 시스템의 본질은 메세지 중심의 통신에 있다는 것을 알아야 합니다. 또한 이전 장에서 리액티브 프로그래밍 기술을 적용해 프로세스 및 서비스 사이의 통신을 위한 비동기 상호 작용을 작성할 수 있습니다. 리액티브 스트림 스펙을 사용해 비동기 방식으로 배압과 오류를 관리할 수 있습니다. 

## 서버사이드 로드밸런싱

분산 시스템 개발 초기 단계에서 위치 투명성과 탄력성을 얻는 방법 중 하나는 HAProxy/Nginx와 같은 외부 로드 밸런서를 진입점으로 사용하거나 전체 시스템에 대한 중앙 로드 밸런서로 사용하는 것입니다. 

게이트 웨이의 역할은 모든 사용자의 요청을 조율하고 두 서비스 A와 B를 호출합니다. 서비스 A가 엑세스 제어의 역할을 한다고 가정합시다. 서비스 A는 호출에 포함된 엑세스 토큰이 올바른지 확인하고 해당 요청이 게이트웨이 접근할 권한이 있는지 확인합니다.

하나의 서비스 앞단에는 로드 밸런서가 존재하게 됩니다. 로드 밸런서로 오토 스케일링을 사용하려면 로드 밸런서가 해당 서비스의 전체 로드 상태를 제공해야 하고 이를 위해 커넥션 수와 같은 메트릭을 수집할 수 있어야 합니다. 또는 로드 밸런서가 응답 대기 시간을 수집하고 이를 기반으로 서비스 상태에 대한 몇 가지 추측이 가능합니다.

로드 밸런서는 주기적으로 이 정볼르 상태 정보와 결합해 로드가 감소할때는 중복 노드를 할당 해제하거나 로드가 증가하면 추가 리소스를 할당하기 위해 노력합니다. 

로드 밸런서는 마치 하위 인스턴스의 레지스트리 역할을 수행합니다. 각 서비스 그룹에는 모든 인스턴스 간의 로드를 관리하는 로드밸런서가 있습니다. 로드 밸런서는 전체 그룹 로드 및 메트릭을 기반으로 스케이링 프로세스를 시작할 수 있습니다. 

하지만 몇 가지 문제점이 있습니다. 우선 로드가 높을때, 로드 밸런서가 시스템의 핫스팟이 될 수 있습니다. 암달의 법칙에 따라 로드 밸런서가 병목 포인트가 되고 서비스 그룹의 최대 처리량이 로드 밸런서의 처리량을 넘을 수 없습니다. 

전용 로드 밸런서는 별도의 강력한 머신이나 가상 머신을 필요로 하기 때문에 로드 밸런서에 비용이 높습니다. 

### 스프링 클라우드와 Ribbong을 이용한 클라이언트 사이트 로드 밸런싱

다행스럽게도 스프링 클라우드 생태계가 서버 측 로드 밸런서가 시스템의 핫 포인트가 되는 문제를 해결하려고 합니다. 스프링 팀은 외부 로드 밸런서에 대한 해결책 대신, 넷플릭스의 분산 시스템 구축 사례를 따르기로 했습니다. 확장성 및 위치 투명성을 달성하는 방법 중 하나는 클라이언트 측 로드 밸런싱을 사용하는 것 입니다. 

클라이언트 로드 밸런싱은 간단합니다. 즉 각 서비스가 다른 서비스의 가용한 인스턴스를 확인하기 위해서 특정한 클라이언트와 통신을 시도합니다. 이를 통해 서비스간 로드 균형을 쉽게 맞추게 됩니다. 

사용하려는 서비스 A의 복제 인스턴스에 다른 서비스의 클라이언트 (B C, D, E ...)가 호출을 하게 됩니다. 이 기법은 몇 가지 한계가 있습니다. 이런 로드 밸런싱 기술을 클라이언트 측 로드 밸런싱이라고 부릅니다. 결과적으로 다른 서비스를 호출하는 클라이언트는 모든 요청을 로컬에서 로드밸런싱해서 대상 서비스의 인스턴스를 선택해야 합니다. 이 기법을 사용하면 단일 장애 지점이 없으므로 확장성이 향상 됩니다. 반면 서비스의 가용성에 대한 정보는 시스템의 다른 서비스에 어떻게든 접근할 수 있어야 합니다. 

서비스 탐색에 사용하는 현대 기술에는 자바 및 스프링 생태계에서 가장 인기 있는 라이브러리인 Ribbon을 사용하는게 좋습니다. **Ribbon 라이브러리는 넥플릭스에서 만든 클라이언트 측 로드 밸런서 패턴을 구현한 것 입니다.** 

Ribbon은 서비스 가용성을 확인하기 위해 두 가지 일반적인 방법을 제공합니다. 가장 간단한 방법은 사전에 구성된 정적 서비스 목록을 사용하는 것 입니다. 사전에 정의된 서비스 A 인스턴스 목록을 가지고 각 서비스 A에 대한 부하를 독립적으로 측정하고, 부하를 참조해 클라이언트측 로드밸런싱을 처리합니다. 

아쉽게도 클라이언트측 로드 밸런싱 기술에는 동기화되지 않는 정보가 존재합니다. 일반적으로 클라이언트 측 로드 밸러서 사이에는 상호 통신이 없으므로 우연이히 모든 발신자가 동일한 인스턴스를 호출하는 경우에는 과부하가 발생할 수 있습니다. 

이렇게 정적인 서비스 인스턴스 목록을 관리하는 방법은 간단하지만 리액티브의 요구사항과는 거리가 멉니다. 부하를 탄력적으로 관리하는 관점에서는 만족하지 않습니다. 

탄력성(elasticity)
: 리액티브 선언문의 관점에서 수요 증가에 대응해 동적으로 시스템 처리량을 늘리고 수요 감소하면 자원 사용을 감소시키는 능력을 의미합니다. 

탄력성을 해결하기 위해 Ribbon은 **유레카와 같은 서비스 레지스트리**와 통합할 수 있습니다. 레지스트리 서비스는 서비스 복제본에 대한 가용성을 지속적으로 업데이트합니다. 

서비스 레지스트리는 발견된 서비스와 서비스 인스턴스에 대한 상태 목록을 보관하고 업데이트 합니다. 클라이언트측 로드 밸런서는 서비스 레지스트리에서 최신정보를 정기적으로 가져와 목록을 업데이트합니다. 

클라이언트측 로드 배런서와 레지스트리 서비스는 모두 대상ㅇ 서비스 인스턴스의 로드에 대한 정보를 보유할 수 있으며, 클라이언트 측 밸런서는 내부 로드 통계를 통해 레지스트리에서 수집한 로드와 주기적으로 동기화 할 수 있습니다. 

사용 가능한 서비스 목록을 관리하는 방법으로 정적 목록을 관리하는 방법으로 동적으로 필요한 서비스 인스턴스를 추가하고 삭제할 수 있습니다. 

서비스 레지스트리를 이용하는 방법은 작은 서비스 클러스터에서 잘 동작합니다. 그러나 유레카와 같은 고전적인 레지스트리 서비스는 시스템의 상태 정보를 업데이트하고 정확하게 유지하는데 많은 노력이 들어 보틀넥이 됩니다. 

최악의 경우 클러스터의 상태가 급속하게 변경되어 등록된 정보가 오래된 정보일 수도 있습니다. 따라서 상태 체크를 위한 간격은 길게 잡을 수도 있습니다. 

여전히 모든 로드 밸런싱이 클라이언트 측에서 발생합니다. 이로 인해 조정되지 않은 로드 밸런싱에 대한 문제는 여전히 발생합니다. 실제 서비스의 부하를 일으키는 부분이 로드 밸런싱이 될 수 있습니다. 분산 시스템에서 서비스 메트릭을 기반으로 한 클라이언트 측 로드밸런서가 제공하는 정보를 더 정확하게 만드는 것은 다른 과제이며 훨씬 어려울 수 있습니다. 그리하여 리액티브 시스템에서는 보두 효과적인 솔류션을 찾아야 합니다. 

## 탄력적이고 신뢰성 있는 메세지 전달 계층 역할의 메세지 브로커

다행이도 리액티브 선언문은 서버 및 클라이언트 측 로드 밸런싱과 관련된 문제의 솔루션을 제공합니다. 

명시적인 메세지 전달을 사용하면 시스템의 메세지 큐 형태 정의, 모니터링 및 필요시 배압 적용을 이용한 부하관리, 탄력성 확보 및 흐름제어가 가능합니다.

위 문장은 메세지를 전송할 목적으로 독립적인 메세지 브로커를 만든것으로 해석할 수 있습니다. 

서비스 C를 사용하는 입장인 서비스 A와 B가 있다고 가정합시다. 서비스 A와 B는 브로커의 메세지 대기열 위치와 서비스 C의 이름을 알고 있습니다.

A와 B는 메세지 큐에 메세지를 보냅니다. 메세지 큐는 독립적인 서비스 입니다. 사용자는 서비스 C를 위한 메세지 큐에 메세지를 보낼 수 있고 메세지를 처리할 여유가 있는 인스턴스가 메세지를 처리합니다. 

실제 C 서비스의 각 인스턴스는 평균적으로 동일한 부하를 받습니다. 이는 각 인스턴스가 처리가능한 처리량을 공개해서 배압을 제어할 수 있기 때문입니다. 메세지 큐는 전체 처리량을 감안해 유입되는 메세지의 양을 조절할 수 있습니다. 

우선 모든 요청은 메세지 큐를 통해 여유가 있는 워커(서비스C 인스턴스)에 전송됩니다. 메세지 큐는 워커 중 하나가 새 메세지를 요청할때 까지 메세지를 보관합니다. 이러한 방식으로 메세지큐는 시스템에 있는 워커의 수를 알 수 있고 그 정보를 기반으로 부하를 관리할 수 있습니다. 

각 워커는 내부적으로 배압을 관리하고 각 워커의 현재 상테에 따라 메세지를 수신할 수 있습니다. 보류 중인 메세지의 수를 모니터링 해서 작업중인 워커의 수를 늘릴 수 있습니다. 또한 워커의 메세지 요청에도 즉각적으로 메세지를 보내줄 수 없는 상황이라면 작업 워커의 수를 줄 일 수 있습니다. 

메세지 큐는 클라이언트 측 로드 밸런싱을 해결할 수 있지만, 서버측 로드 밸런싱과 비슷한 솔루션으로 회귀하는 것으로 보여 큐 시스템 자체가 병목이 되지 않을까 하는 걱정이 있을 수 있습니다. 





<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE5NTc2ODc2MDksMTM1ODQ2NjM2OCwtMT
gwOTA2ODcyLC00MzQ1OTQwMTMsMTEwNzg2OTI3MCwtMTQxNjU2
NDI2LC02OTQ2NjcyOCwxNDI1MDg3NzE4LC00NjIxMjA4NDUsLT
Y4NzQ1NzA5LDk5MjMzNDUzLC0yMTYyMjU4NzgsNzI3NjE4MDQy
LDcxOTk2MDk1OCwtODM1MTgwNzEzLC0xNzg5MTM5ODA5LDE2OT
UyNjIyNCwtMTUyMTkxNSwxNTUxNDIwMjA0LDEyOTcxMDQyMl19

-->