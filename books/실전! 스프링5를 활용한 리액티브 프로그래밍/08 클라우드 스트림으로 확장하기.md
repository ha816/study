# Overview

리액티브 방법은 스프링 생태계와 함께 한다면 더욱 좋습니다. 이번에는 스프링 클라우드 생태계가 제공하는 기능을 사용해 애플리케이션을 개선하는 방법과 **스프링 클라우드 스트림(Spring Cloud Stream)**을 사용해 완전한 리액티브 시스템을 구축하는 방법을 배울것 입니다. 또한 **RSocket** 라이브러리가 무엇인지 빠른 스트리밍 시스템을 개발하는데 어떻게 도움이 되는지 알아봅시다. 

#  Message Brocker 

메세지 기반 시스템의 본질은 메세지 중심의 통신에 있다는 것을 알아야 합니다. 또한 이전 장에서 리액티브 프로그래밍 기술을 적용해 프로세스 및 서비스 사이의 통신을 위한 비동기 상호 작용을 작성할 수 있습니다. 리액티브 스트림 스펙을 사용해 비동기 방식으로 배압과 오류를 관리할 수 있습니다. 

## 서버사이드 로드밸런싱

분산 시스템 개발 초기 단계에서 위치 투명성과 탄력성을 얻는 방법 중 하나는 HAProxy/Nginx와 같은 외부 로드 밸런서를 진입점으로 사용하거나 전체 시스템에 대한 중앙 로드 밸런서로 사용하는 것입니다. 

게이트 웨이의 역할은 모든 사용자의 요청을 조율하고 두 서비스 A와 B를 호출합니다. 서비스 A가 엑세스 제어의 역할을 한다고 가정합시다. 서비스 A는 호출에 포함된 엑세스 토큰이 올바른지 확인하고 해당 요청이 게이트웨이 접근할 권한이 있는지 확인합니다.

하나의 서비스 앞단에는 로드 밸런서가 존재하게 됩니다. 로드 밸런서로 오토 스케일링을 사용하려면 로드 밸런서가 해당 서비스의 전체 로드 상태를 제공해야 하고 이를 위해 커넥션 수와 같은 메트릭을 수집할 수 있어야 합니다. 또는 로드 밸런서가 응답 대기 시간을 수집하고 이를 기반으로 서비스 상태에 대한 몇 가지 추측이 가능합니다.

로드 밸런서는 주기적으로 이 정볼르 상태 정보와 결합해 로드가 감소할때는 중복 노드를 할당 해제하거나 로드가 증가하면 추가 리소스를 할당하기 위해 노력합니다. 

로드 밸런서는 마치 하위 인스턴스의 레지스트리 역할을 수행합니다. 각 서비스 그룹에는 모든 인스턴스 간의 로드를 관리하는 로드밸런서가 있습니다. 로드 밸런서는 전체 그룹 로드 및 메트릭을 기반으로 스케이링 프로세스를 시작할 수 있습니다. 

하지만 몇 가지 문제점이 있습니다. 우선 로드가 높을때, 로드 밸런서가 시스템의 핫스팟이 될 수 있습니다. 암달의 법칙에 따라 로드 밸런서가 병목 포인트가 되고 서비스 그룹의 최대 처리량이 로드 밸런서의 처리량을 넘을 수 없습니다. 

전용 로드 밸런서는 별도의 강력한 머신이나 가상 머신을 필요로 하기 때문에 로드 밸런서에 비용이 높습니다. 

### 스프링 클라우드와 Ribbong을 이용한 클라이언트 사이트 로드 밸런싱

다행스럽게도 스프링 클라우드 생태계가 서버 측 로드 밸런서가 시스템의 핫 포인트가 되는 문제를 해결하려고 합니다. 스프링 팀은 외부 로드 밸런서에 대한 해결책 대신, 넷플릭스의 분산 시스템 구축 사례를 따르기로 했습니다. 확장성 및 위치 투명성을 달성하는 방법 중 하나는 클라이언트 측 로드 밸런싱을 사용하는 것 입니다. 

클라이언트 로드 밸런싱은 간단합니다. 즉 각 서비스가 다른 서비스의 가용한 인스턴스를 확인하기 위해서 특정한 클라이언트와 통신을 시도합니다. 이를 통해 서비스간 로드 균형을 쉽게 맞추게 됩니다. 

사용하려는 서비스 A의 복제 인스턴스에 다른 서비스의 클라이언트 (B C, D, E ...)가 호출을 하게 됩니다. 이 기법은 몇 가지 한계가 있습니다. 이런 로드 밸런싱 기술을 클라이언트 측 로드 밸런싱이라고 부릅니다. 결과적으로 다른 서비스를 호출하는 클라이언트는 모든 요청을 로컬에서 로드밸런싱해서 대상 서비스의 인스턴스를 선택해야 합니다. 이 기법을 사용하면 단일 장애 지점이 없으므로 확장성이 향상 됩니다. 반면 서비스의 가용성에 대한 정보는 시스템의 다른 서비스에 어떻게든 접근할 수 있어야 합니다. 

서비스 탐색에 사용하는 현대 기술에는 자바 및 스프링 생태계에서 가장 인기 있는 라이브러리인 Ribbon을 사용하는게 좋습니다. **Ribbon 라이브러리는 넥플릭스에서 만든 클라이언트 측 로드 밸런서 패턴을 구현한 것 입니다.** 

Ribbon은 서비스 가용성을 확인하기 위해 두 가지 일반적인 방법을 제공합니다. 가장 간단한 방법은 사전에 구성된 정적 서비스 목록을 사용하는 것 입니다. 사전에 정의된 서비스 A 인스턴스 목록을 가지고 각 서비스 A에 대한 부하를 독립적으로 측정하고, 부하를 참조해 클라이언트측 로드밸런싱을 처리합니다. 

아쉽게도 클라이언트측 로드 밸런싱 기술에는 동기화되지 않는 정보가 존재합니다. 일반적으로 클라이언트 측 로드 밸러서 사이에는 상호 통신이 없으므로 우연이히 모든 발신자가 동일한 인스턴스를 호출하는 경우에는 과부하가 발생할 수 있습니다. 

이렇게 정적인 서비스 인스턴스 목록을 관리하는 방법은 간단하지만 리액티브의 요구사항과는 거리가 멉니다. 부하를 탄력적으로 관리하는 관점에서는 만족하지 않습니다. 

탄력성(elasticity)
: 리액티브 선언문의 관점에서 수요 증가에 대응해 동적으로 시스템 처리량을 늘리고 수요 감소하면 자원 사용을 감소시키는 능력을 의미합니다. 

탄력성을 해결하기 위해 Ribbon은 **유레카와 같은 서비스 레지스트리**와 통합할 수 있습니다. 레지스트리 서비스는 서비스 복제본에 대한 가용성을 지속적으로 업데이트합니다. 

서비스 레지스트리는 발견된 서비스와 서비스 인스턴스에 대한 상태 목록을 보관하고 업데이트 합니다. 클라이언트측 로드 밸런서는 서비스 레지스트리에서 최신정보를 정기적으로 가져와 목록을 업데이트합니다. 

클라이언트측 로드 배런서와 레지스트리 서비스는 모두 대상ㅇ 서비스 인스턴스의 로드에 대한 정보를 보유할 수 있으며, 클라이언트 측 밸런서는 내부 로드 통계를 통해 레지스트리에서 수집한 로드와 주기적으로 동기화 할 수 있습니다. 

사용 가능한 서비스 목록을 관리하는 방법으로 정적 목록을 관리하는 방법으로 동적으로 필요한 서비스 인스턴스를 추가하고 삭제할 수 있습니다. 

서비스 레지스트리를 이용하는 방법은 작은 서비스 클러스터에서 잘 동작합니다. 그러나 유레카와 같은 고전적인 레지스트리 서비스는 시스템의 상태 정보를 업데이트하고 정확하게 유지하는데 많은 노력이 들어 보틀넥이 됩니다. 

최악의 경우 클러스터의 상태가 급속하게 변경되어 등록된 정보가 오래된 정보일 수도 있습니다. 따라서 상태 체크를 위한 간격은 길게 잡을 수도 있습니다. 

여전히 모든 로드 밸런싱이 클라이언트 측에서 발생합니다. 이로 인해 조정되지 않은 로드 밸런싱에 대한 문제는 여전히 발생합니다. 실제 서비스의 부하를 일으키는 부분이 로드 밸런싱이 될 수 있습니다. 분산 시스템에서 서비스 메트릭을 기반으로 한 클라이언트 측 로드밸런서가 제공하는 정보를 더 정확하게 만드는 것은 다른 과제이며 훨씬 어려울 수 있습니다. 그리하여 리액티브 시스템에서는 보두 효과적인 솔류션을 찾아야 합니다. 

## 탄력적이고 신뢰성 있는 메세지 전달 계층 역할의 메세지 브로커

다행이도 리액티브 선언문은 서버 및 클라이언트 측 로드 밸런싱과 관련된 문제의 솔루션을 제공합니다. 

명시적인 메세지 전달을 사용하면 시스템의 메세지 큐 형태 정의, 모니터링 및 필요시 배압 적용을 이용한 부하관리, 탄력성 확보 및 흐름제어가 가능합니다.

위 문장은 메세지를 전송할 목적으로 독립적인 메세지 브로커를 만든것으로 해석할 수 있습니다. 

서비스 C를 사용하는 입장인 서비스 A와 B가 있다고 가정합시다. 서비스 A와 B는 브로커의 메세지 대기열 위치와 서비스 C의 이름을 알고 있습니다.

A와 B는 메세지 큐에 메세지를 보냅니다. 메세지 큐는 독립적인 서비스 입니다. 사용자는 서비스 C를 위한 메세지 큐에 메세지를 보낼 수 있고 메세지를 처리할 여유가 있는 인스턴스가 메세지를 처리합니다. 

실제 C 서비스의 각 인스턴스는 평균적으로 동일한 부하를 받습니다. 이는 각 인스턴스가 처리가능한 처리량을 공개해서 배압을 제어할 수 있기 때문입니다. 메세지 큐는 전체 처리량을 감안해 유입되는 메세지의 양을 조절할 수 있습니다. 

우선 모든 요청은 메세지 큐를 통해 여유가 있는 워커(서비스C 인스턴스)에 전송됩니다. 메세지 큐는 워커 중 하나가 새 메세지를 요청할때 까지 메세지를 보관합니다. 이러한 방식으로 메세지큐는 시스템에 있는 워커의 수를 알 수 있고 그 정보를 기반으로 부하를 관리할 수 있습니다. 

각 워커는 내부적으로 배압을 관리하고 각 워커의 현재 상테에 따라 메세지를 수신할 수 있습니다. 보류 중인 메세지의 수를 모니터링 해서 작업중인 워커의 수를 늘릴 수 있습니다. 또한 워커의 메세지 요청에도 즉각적으로 메세지를 보내줄 수 없는 상황이라면 작업 워커의 수를 줄 일 수 있습니다. 

메세지 큐는 클라이언트 측 로드 밸런싱을 해결할 수 있지만, 서버측 로드 밸런싱과 비슷한 솔루션으로 회귀하는 것으로 보여 큐 시스템 자체가 병목이 되지 않을까 하는 걱정이 있을 수 있습니다. 

우선 메세지 큐를 이용하는 통신 모델은 서버 측 로드 밸런싱과 조금 다릅니다. 사용 가능한 서비스를 검색하고 요청을 보낼 사람을 결정하는 대신 메세지 큐는 들어오는 메세지를 큐에 넣습니다.  그런 다음 워커가 메세지를 요청하면 큐에 있던 메세지가 전송됩니다. 여기선 분리되있을 뿐만 아니라 독립적인 두 단계가 있다고 볼 수 있습니다. 

* 메세지를 수신하고 큐에 넣는 단계(매우 빠름)
* 워커가 메세지를 요청할때 메세지 전송

또한 수신자 그룹별로 메세지 큐를 복제합니다. 이를 통해 시스템의 확장성을 향상시키고 병목 현상을 피할 수 있습니다. 

이제 서비스 C를 위한 다수의 복제된 메세지 큐가 존재하게 됩니다. 물론 다른 서비스에서도 각 그룹별로 서비스 D 메세지 큐군이 존재할 수 있습니다.  이 메세지 그룹군은 계속해서 복제본간 메세지 큐간의 동기화를 하게 됩니다. 

다수의 복제본 큐에 걸리는 부하는 그룹 마다 다룰 수 있으므로 특정 그룹에 과부하가 걸리면 다른 그룹은 작업 없이 휴면 상태에 놓일 수 있습니다. 따라서 메세지 큐를 별도의 서비스로 가지는 대신 가상의 큐를 지원하는 메세지 브로커를 사용할 수 있습니다. 이렇게 하면 여러 그룹이 하나의 메세지 브로커를 공유하게 되고 전체적인 시스템 부하가 감소합니다. 메세지 브로커는 리액티브를 지원합니다. 결과적으로 메세지 브로커는 탄력적이고 복원력이 있으며 비동기 논블로킹 메세지 전달을 사용해 내부 상태를 공유할 수 있습니다. 

이제 가상의 메세지 큐에 해당하는 메세지 브로커안에 파티션이 존재하게 됩니다. 각 파티션에는 지정된 수의 수신자(토픽)이 존재합니다. 각 파티션에는 복제본이 있을 수 있습니다.

경우에 따라 파티션 재조정이 나타낼수도 있습니다. 메세지 브로커는 추가적인 리밸런싱 매커니즘을 사용할 수 있으므로 클러스터에 새로운 수신자 또는 새 노드가 추가되는 경우에도 브로커를 쉽게 확장 할 수 있습니다. 

수신자 서비스는 각기 다른 파티션에서도 정보를 가져올 수 있고 파티션은 서로 동기화가 됩니다. 

메세지 브로커너는 백압 지원 및 반복 재생을 보장하는 비동기 메세지 전송을 위한 안정적인 기능을 제공합니다. 이 말은 메세지 브로커가 손상된 경우에도 단 하나의 메세지도 유실되지 않는다는 뜻 입니다. 이후에 메세지 브로커가 복구되면 그 동안 절달되지 못한 모드 메세지가 정상적으로 전달 됩니다. 

요약하면 메세지 브로커 기법이 시스템의 전반벅인 확장성을 향상 시키다는 결론을 내릴 수 있습니다. 이 경우 메세지 브로커는 리액티브 시스템으로 작동하기 때문에 탄력적인 시스템을 쉽게 구현 할 수 있습니다. 따라서 이제 통신에 병목현상이 발생하지 않을것 입니다. 

메세지 브로커에는 RabbitMq, 아파치 카프카, 아파키 펄사 등 이 있습니다.

# 스프링 생태계와 스프링 클라우드 스트림

스프링 클라우드를 사용해 견고한 메세지 기반 시스템을 구축하는 강력한 방법 중 하나는 스프링 클라우드 스트림(Spring Cloud Streams)을 사용하는 것입니다. 스프링 클라우드 스트림은 비동기식 다중 서비스 메세징을 위한 단순한 프로그래밍 모델을 제공합니다. 

스프링 클라우드 스트림 모듈은 스프링 Integration 모듈과 스프링 메세지 모듈을 기반으로 구축되었습니다. 이로 인해 외부 서비스와 쉽게 연계할 수 있고 비동기 메세지 서비스와도 쉽게 통합할 수 있습니다. 안타깝게도 스프링 프레임워크와 통합할 수 있는 메세지 브로커는 많지 않습니다. RabbitMQ와 카프카가 가능합니다. 

@Output 애노테이션으로 메세지를 전달할 큐 이름을 정의할 수 있습니다. 두번 째 애노테이션은 메세지를 수신하는 큐를 정의하는 @Input 입니다. 이 방식은 인터페이스 호출방식을 대체할 수 있고 메서드를 호출하는 대신 특정 큐로 메세지를 보낼 수 있습니다. 

## 클라우드 환경에서의 리액티브 프로그래밍

스프링 클라우드 스트림은 분산된 리액티브 시스템을 구현하는 단순한 방법을 제공하지만, 스프링 클라우드 스트림 프로그래밍 모델의 특성을 다구리 위해서 여전히 설정해야 할 것이 많습니다. 예를 들면 메세지의 목적지에 대한 설정과 플로를 명확하게 보여주는 것 입니다. 

리액티브 확장을 개발한 주된 이유는 연산자의 기능적인 연결을 이용해 복잡한 비동기 데이터 흐름을 숨기는 것이었습니다. 리액티브 시스템에서는 마이크로 서비스 간의 플로 상호작용을 이해하는 것이 매우 중요하지만 특정한 도구의 도움 없이는 달성하기 어렵습니다. 

다행이 아마존은 AWS 람다를 발표하였습니다. 람다는 리액티브 시스템 개발에 새로운 가능성을 열었습니다. 

```
AWS 람다는 이벤트에 대한 응답으로 코드를 실행하고 자동으로 컴퓨팅 자원을 관리하는 서버리스 컴퓨팅 서비스 입니다. 
```

AWS람다는 작고 독립적이며 확장 가능한 서비스를 만들 수 있게 해줍니다. 또한 로직의 개발 라이프 사이클을 특정 데이터 흐름과 분리할 수 있게 해줍니다. 마지막으로 사용자 친화적인 인터페이스를 통해 전체 비지니스 흐름을 독립적으로 구축하도록 해줍니다. 

## 스프링 클라우드 데이터 플로

2016년 초 스프링 클라우드는 스프링 클라우드 플로(Spring Cloud Data Flow)라는 새로운 모듈을 발표했습니다. 

```
스프링 클라우드 데이터 플로는 데이터 통합 및 실시간 데이터 처리 파이프라인을 구축하기 위한 도구입니다. 
```


# 리액티브 메세지 전달을 위한 낮은 지연 시간의 RSocket

최근에는 밀리 단위의 지연도 허용하지 못하는 분야가 있습니다. 예를 들면 증권 거래소 시장, 온라인 비디오 게임 또는 실시간 생산 라인 제어 시스템이 그렇습니다. 이런 시스템에서는 메세지를 큐에 넣었다가 빼는 시간을 용납하지 않습니다. 결국 신뢰성 있는 메세지 브로커는 메세지를 영속화하여 보놎하지만 그로 인해 메세지를 전달하는 걸리는 시간이 길어집니다. 

분산 시스템에서 서비스 사이 지연시간을 짧은 통신을 구현하는 솔루션 중 하나는 서비스 사이에 지속적이고 직접적인 통신을 연결하는 것 입니다. 

웹소켓과 같이 널리 알려진 프로토콜을 사용하면 이러한 통신을 구축할 수 있지만 서비스 사이의 강한 결합이나 웹소켓의 사용은 리액티브 시스템 요구 사항에 적합하지 않습니다. 프로토콜 배압을 제어할 수 있는 기능이 제공되지 않기 때문입니다. 배압은 리액티브 시스템의 핵심 요소 입니다. 

이러한 필요성으로 벤 크리스텐슨은 RSocket이라는 새로운 프로젝트를 시작했습니다. RSocket의 목표는 비동기와 바이너리 수준을 넘어 리액티브 스트림에 충실한 응용 프로토콜을 제공하는 것 입니다. 

##  RSocket VS Reactor-Netty

이미 RXNetty 또는 리액터 네티(네티의 기본 웹플럭스)와 같은 웹 서버가 있습니다. 리액터-네티를 사용하면 메세지를 받을 준비가 되었을때만 수신 메세지를 받아 처리할 수 있습니다. 컴포넌트가 실제로 요청하는 수자가 네트워크의 한계를 넘지 않는 다는 것 입니다. 

프로듀서와 컨슈머 방식의 통신에서 최악의 시나리오는 컨슈머가 프로듀서의 메시지를 처리하지 못할정도로 느린 경우 입니다. 처리 되지 못한 이벤트 일부는 소켓 버퍼에 버퍼링됩니다. 하지만 버퍼의 크기는 제한적이며 어느 시점이 지나면 네트워크 패킷이 유실될 것입니다. 

RSocket을 사용하면 적합한 배압을 이용해 리액티브한 스트림을 쉽게 구현할 수 있습니다. 프로듀스 서비스는 요청에 응답하고 네트워크를 통해 onNext 시그널로 요청 개수만큼 데이터를 보낼 수 있습니다. 

RSocket은 네트어








<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEyOTk0MjY5NjksMTE4MDg1NjI5LC0xOT
YyNjczMDA0LC0xNTk1NDc3OTk4XX0=
-->