# Overview

이제 리액티브 스트림의 생명 주기, 멀티 스레딩, 리택터 프로젝트의 내부 최적화 동작 방식을 자세히 공부해 봅시다. 

# 스트림 생명 주기

## Assembling(조립 단계)

언뜻보면 리액터가 제공하는 API는 처리 흐름에 사용하는 연산자를 조합한 빌더 API 처럼 보입니다. 빌더 패턴은 가변적인 임시 객체 정보를 가지고 있다가 , 객체 생성을 위해선 build와 같은 최종함수를 호출해야 합니다. 그러나 리액터 API는 가공 결과로 불변 객체를 제공합니다. 즉 불변성을 위해 각 연산자가 새로운 객체를 생성합니다. 

리액티브 스트림 실행 흐름을 계획하고 구성하는 단계를 조립 단계라고 합니다. 이 단계에서는 스트림의 타입을 확인해 연산자를 바꾸어 성능 향상 이루거나 몇 가지 훅을 사용하여 디버깅이나 모니터링, 메트릭 수집등의 기능을 사용할 수 있습니다. 

예를 들면 아래와 같이 FluxConcatArray(FluxA, FluxB, FluxC)로 동작하여 성능향상을 꾀합니다.
```
FluxConcatArray(FluxConcatArray(FluxA, FluxB), FluxC)
FluxConcatArray(FluxA, FluxB, FluxC)
```

## Subscription(구독 단계)

구독은 특정 Publisher를 구독(subscribe())할때 발생합니다. 예를 들어 아래 코드는 앞에서 만든 실행 플로를 구독합니다. 

```
...
filteredFlux.subscribe(Subscriber); // filteredFlux(Publisher)를 파라미터로 받은 Subscriber가 구독
```

실행 플로를 만들기 위해 내부적으로 Publisher를 다른 Publisher에 전달합니다 . 즉 일련의 Publisher들로 구성된 체인이 있습니다.  Publisher들이 일련의 체인으로 묶여있기 때문에,  각 Publisher마다 대응하는 Subscriber를 만들고 다시 Subscriber를 체인으로 묶음으로써 Subscriber의 구독 전파가 가능해집니다.

먼저 최상위 Publisher(filteredFlux)를 구독하면, 해당 모든 Publisher 체인의 구독 프로세스가 시작됩니다. 

```
filteredFlux.subscribe(Subscriber){
	mapflux.subscribe(new FilterSubscriber(Subscriber)){
		arrayFlux.subscribe(new MapSubscriber(FilterSubscriber(Subscriber))) {
			... //실제 데이터 송신 시작
			// array -> map -> filtered
		}
	}
}
```
Publisher 체인을 따라 subscribe()가 전파가 되기 때문에, 다음 체인의 Subscriber 생성자에 자기 자신을 파라미터로 전달하고, 그에 따라 Publisher 체인과는 반대 순서로 체인이 형성됩니다.
```
ArraySubscriber(
    MapSubscriber(
        FilterSubscriber(
            Subscriber
        )
    )
)
```

구독 단계는 앞서 조립단계(Assembling)과 유사하게 성능 향상을 꾀할 수 있습니다. 
멀티스레딩을 지원하는 일부 리액티브 연산자로 구독 작업자(워커; Subscriber)를 변경할 수 있습니다. 이 변경은 구독단계에서 Subscriber 체인 생성 과정에서 이루어집니다. 

## Runtime(런타임 단계)

이 단계에서 Publisher와 Subscriber가 onSubscribe() 시그널과 request() 시그널을 교환하면서 스트림 시작됩니다. 앞서 구독단계에서 보았던 예제에서 최상위 Subscriber는 ArraySubscriber이고 거기서부터 onSubscribe()가 전파됩니다.

```
//Subscriber.onSubscribe(Subscription) // 구독자가 구독할 준비를 한다. (Subscription 생성)
MapSubscriber(FilterSubscriber(Subscriber)).onSubscribe(
    new ArraySubscription
) {
    FilterSubscriber(Subscriber).onSubscribe(
        new MapSubscription(ArraySubscription(...))
    ) {
        Subscriber.onSubscribe(
            FilterSubscription(MapSubscription(ArraySubscription(...)))
        ) {
            // 데이터 요청
        }
    }
}
```

모든 구독자 체인(ArraySubcriber -> MapSubscriber -> FilterSubscriber)을 통과하고, 체인에 각 Subscriber가 지정된 구독을 자신의 표현으로 래핑하면 최종적으로 아래와 같이 Subscription 체인의 피라미드를 얻습니다. 
```
FilterSubscription(
    MapSubscription(
        ArraySubscription()
    )
)
```

위 체인을 따라 request(n) 요청이 전파되고, 가장 안 쪽에 있는 ArraySubscription에서 데이터 송신이 시작됩니다. 

```
FilterSubscription(MapSubscription(ArraySubscription(...)))
	.request(10) {
		MapSubscription(ArraySubscription(...))
		.request(10) {
			ArraySubscription(...)
			.request(10) {
				//데이터 전송 시작
			}
		}
	}
```
런타임 단계에서도 request() 호출 횟수를 줄이는 등의 최적화가 이루어집니다. 이를 마이크로 퓨전이라고 합니다.

![Java 9 Flow API - Reactive Streams » grokonez](https://grokonez.com/wp-content/uploads/2017/04/reactive-stream-flow-interface-behavior.png)

# 리액터 쓰레드 스케줄링 모델

리액터 멀티쓰레딩을 위해 사용하는 연산자들을 공부해 봅시다. 현재 실행 중인 쓰레드가 아닌 쓰레드로 실행을 전환할 수 있는 연산자는 크게 네가지가 있습니다.  

## Scheduler

스케쥴러는 Flux의 Mono의 publishOn, subscribeOn 메서드에 사용할 수 있습니다. 스케쥴러는 재사용 가능한 쓰레드를 가지는 일종의 쓰레드 풀입니다. 

`reactor.core.scheduler.Schedulers`에서 기본으로 제공하는 스케쥴러들은 다음과 같습니다.

-   Schedulers.immediate() : Current thread.
-   Schedulers.single() : A single, reusable thread.
-   Schedulers.newSingle() : A per-call dedicated thread.
-   Schedulers.elastic() : An elastic thread pool. It creates new worker pools as needed, 
- and reuse idle ones. 
	- 스레드 풀의 최대 쓰레드 개수가 제한되지 않기 때문에 I/O 작업에 적합합니다. 
-   Schedulers.parallel() : A fixed pool of workers that is tuned for parallel work.
	- 기본적으로 CPU 코어 수의 개수만큼의  워커가 존재하는 풀입니다. CPU 자원이 주로 필요한 작업에 적합합니다
  
    
## publishOn


![](https://raw.githubusercontent.com/reactor/reactor-core/v3.1.3.RELEASE/src/docs/marble/publishon.png)
publishOn 연산자는 실행의 일부를 지정된 스케쥴러에게 위임할 수 있습니다. 

```
Scheduler scheduler = Schedulers.elastic();
Flux.range(0, 100) 
	.map(String.valueOf)
	.filter(s -> s.length() > 1)
	// 메인 스레드 구간
	.publishOn(scheduler) // 스케쥴러의 한 쓰레드에게 위임		
	.map(this.calculateHash)
	.subscribe()
	// 스케쥴러가 정한 스레드 구간
```
 
publishOn 연산자가 실행되기 전 단계는 메인스레드에서 처리가 됩니다. 그리고 그 이후에는 스케쥴러가 지정한 다른 스레드(워커)에서 작업이 실행됩니다. 


메인 쓰레드에서 완료된 작업은 공통의 Queue에 쌓이게 됩니다. publishOn연산자는 내부적으로 전용 스레드가 있어 작업을 순서대로 처리할 수 있도록 Queue를 가지고 있습니다.

![](https://t1.daumcdn.net/cfile/tistory/276C574E58ABE9A122)

한 가지 중요한 점은 리액티브 스트림의 모든 원소는 하나씩 처리되므로 항상 모든 이벤트의 순서를 엄격하게 정의할 수 있습니다. 그리고 이를 직렬성(serializable)이라고 합니다. 

## SubscribeOn


![사용하면서 알게 된 Reactor, 예제 코드로 살펴보기 – tech.kakao.com](https://raw.githubusercontent.com/reactor/reactor-core/v3.1.3.RELEASE/src/docs/marble/subscribeon.png)

subscribeOn을 사용하면 런타임 단계에서 구독(subscription)을 다른 쓰레드에서 처리하도록 변경할 수 있습니다. 

[BlockingCall](https://itstory.tk/entry/Spring-Webflux-JDBC%ED%98%B9%EC%9D%80-blocking-call-%ED%95%B8%EB%93%A4%EB%A7%81-%EB%B0%A9%EB%B2%95)

```
ObjectMapper mapper = new ...;
String json = "...";
Mono.fromCallable(() -> objectMapper.readValue(json, Car.class));
```

Mono.fromCallable은 Callable을 인자로 받아 Mono를 생성하고 실행 결과를 내부적으로 가지는 새로운 구독자에게 전달합니다. 

subscribeOn을 사용하면 구독을 수행할 다른 쓰케쥴러를 지정할 수 있습니다. 아래 코드가 그 예제입니다.
```
Scheduler sheduler = Schedulers.parallel();
Mono.fromCallbe(...)
	.subscribeOn(scheduler)
	.subscribe();
```

## Parallel

parallel 연산자는 다수의 병렬 처리를 위한 연산자입니다. 하위 스트림에 대한 플로 분할과 분할된 플로우 간 조정 역할을 합니다. parallel 연산자는 Flux에서 사용가능합니다.

주의할 점으로 parallel()만을 사용하면 Flux데이터를 CPU 코어 개수만큼의 ParallelFlux로 나누고 라운드로빈 방식으로 처리하게 됩니다. 즉 의도한 병렬처리가 되지 않습니다. 따라서 반드시 .runOn을 사용해서 특정 스케쥴러를 지정하여 병렬처리가 되도록 해야 합니다. 

```
Flux.range(0, 10000)
	.parallel()
	.runOn(Schedulers.parallel()) // 
	.map()
	.filter()
	.subscribe()
```

## Context 

Context는 스트림을 따라 전달되는 **인터페이스** 입니다. 핵심 아이디어는 나중에 런타임 단계에서 필요한 컨텍스트 정보에 엑세스할 수 있도록 하는 것입니다. 

[ThreadLocal](https://javacan.tistory.com/entry/ThreadLocalUsage)
: 자바 1.2 버전부터 제공되고 있지만 아직 다수의 개발자들이 잘 몰라서 활용을 잘 못하는 기능이 하나 있는데, 그 기능이 바로 쓰레드 단위로 로컬 변수를 할당하는 기능입니다.

```
static final ThreadLocal<String> USER_ID = new ThreadLocal<>();

@Test
public void testThreadLocals() {
    USER_ID.set("bsideup");

    Mono.just("Hello %s")
        .delayElement(Duration.ofSeconds(1))
        .doOnNext(greeting -> {
            // WIll print "Hello null". Bummer!
            System.out.println(String.format(greeting, USER_ID.get()));
        })
        .block();
}
```

1.  We set the variable to some value, and this value “sticks” to the current (main) thread.
2.  Now we introduce a delay, and, since everything is non-blocking, the task will be submitted to the parallel scheduler.
3.  Once delay completes,  `doOnNext`  will be called on the same (parallel) thread.

즉 delayElement 때문에 생성된 Parallel thread에는 LocalThread변수가 없기 때문에 의도치 않은 결과가 나타납니다. ThreadLocal을 사용하면 여러 문제가 발생할 수 있는데 이럴때 대안으로 사용가능한 것이 Context입니다.  

subscriberContext()를 사용하면 현재 구독의 사용가능한 Context를 반환합니다. 즉 현재 구독에 쓰이는 Context 정보를 반환합니다.

Context는 key/value로 데이터를 저장하는 데이터 구조입니다. 5개의 key-value쌍까지는 좋은 퍼포먼스를 보입니다. 

#  리액터 내부 구조

## 연산자 융합

### 매크로 퓨전

매크로 퓨전은 주로 조립단계에서 발생하며, 그 목적은 연산자를 다른 연산자로 교체하는 것입니다. Mono는 하나 또는 0개의 원소를 처리하기 위해 고도화 되어 있습니다. 이런 고도화 처리에는 대부분 간단한 연산자들을 다른 연산자로 교체하는 매크로 퓨전 테크닉이 적용되어 있습니다. 

### 마이크로 퓨전

좀 더 복잡한 최적화이며 런타임 최적화 및 공유 리로스 재사용과 관련이 있습니다. 마이크로 퓨전의 좋은 예로는 조건부 연산자가 있습니다. 

factory -> warehouse ->store

어떤 상품을 아래와 같은 과정으로 상점으로 보낸다고 합시다. warehouse에서 상품의 품질 검사를 진행하며 store에 도착하려면 품질 검사를 반드시 통과해야 합니다. 품질 검사에 실패하면 물건을 다시 공장에 보내고 일부 포장이 제대로 안된 상품도 다시 공장으로 보냈습니다.

그리하여 품질검사를 공장에서 하기로 하였고, 많은 비용을 아낄 수 있었습니다.
위 사례를 코드로 나타내 보겠습니다.

```
Flux.from(factory)
	.filter(warehouse)
	.subscribe(store)
```

filter 연산자에 의해서 일부 원소는 거부가 되는 상황이 발생 합니다. 이 거부된 원소는 필터 연산자가 다시 request(1) 메서드를 호출해 새로운 원소를 보충하게 되는데, 사실 request 메서드 실행은 추가적인 CPU 부하를 일으킵니다. 

필터 연산자와 같은 조건부 연산자는 성능에 지대한 영향을 미칠 수 있으므로 














> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE1NjYwNzg1NjUsLTg3ODYwMjAyNCwtNz
IxODg1MjgwLC01OTI2NDI3MjYsLTEwNzE3MTI4LC02MTc2NDEx
ODUsMTU2NjEwODE5MCwyMDc2OTI1ODk4LC0xODk3NTczOTY2LC
0xNDcyMzMzNTY2LDQwOTE5NDA2MywxNzE5MjgxNjcsLTU0Njcz
OTAsLTc4MzE5NDk5NywxMzE3NDExNTQ4LDE2NTYyNjQxODEsLT
g3MDMyOTY2MF19
-->