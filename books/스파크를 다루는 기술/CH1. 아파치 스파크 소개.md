# 스파크란?

스파크(Apache Spark)는 고속 범용 분산 컴퓨팅 플랫폼이다. 
* 메모리 기반으로 하둡 맵 리듀스보다 10배 ~100배 빠르다.
* 컬렉션 기반의 API로 사용자는 클러스터를 다루는 사실을 인지할 필요없다.
* 파이썬, 자바, R, 스칼라도 사용가능하다.

스파크는 또한 맵리듀스와 유사한 일괄 처리기능, 실시간 데이터 처리, SQL과 유사한 정형 데이터 처리, 그래프 알고리즘, 머신 러닝 알고리즘을 모두 단일 프레임워크로 통합했다.

하지만 일부 애플리케이션은 스파크를 사용하기 부적합하다. 분산 아키텍처이기 때문에 약간의 오버헤드가 필연적으로 발생한다. 대량의 데이터를 다룰때는 괜찮지만 단일 머신에서도 처리할 수 있는 작은 데이터를 다룰때는 작은 데이터셋의 연산에 최적화된 다른 프레임 워크를 사용하는 것이 더 효율적이다. 
또 스파크는 온라인 트랜잭션 처리 애플리케이션을 염두에 두고 설계되지 않았다. 즉 원장성을 보장해야 하는 트랜잭션을 빠르게 처리해야 하는 경우 스파크는 부적합하다. 일괄 처리 작업이나 데이터 마이닝 같은 온라인 분석 처리 작업에는 적합하다. 

## 하둡의 HDFS과 맵리듀스의 한계

HDFS(Hadoop File System)과 맵리듀스 처리 엔진으로 구성된 하둡 프레임 워크는 분산 컴퓨터팅을 최초로 대중화 하는데 성공했다. 하둡은 데이터 분산 처리에서 반드시 고민해야 하는 다음 세 가지 문제를 해결했다.

* 병렬처리(parallelization): 전체 연산을 잘게 나누어 동시에 처리하는법
* 데이터 분산(distribution): 데이터를 여러 노드로 분산하는 방법
* 장애 내성(fault tolerance): 분산 컴포넌트의 장애에 대응하는 방법

하둡은 활발히 사용되고 있지만 여러 한계를 가지고 있고 이는 맵리듀스 컴포넌트와 관련이 있다. 맵 리듀스 잡의 결과를 다른 잡에서 사용하려면 먼저 이 결과를 HDFS에 저장해야 한다. 이전 잡의 결과가 다음 작업의 입력이 되는 반복 알고리즘에는 비효율적이다. 또 많은 유형의 문제가 맵 리듀스 2단계 패러다임에 쉽게 들어맞지 않으며, 모든 문제를 일련의 맵과 리듀스 연산으로 분해할 수 없다. 

## 스파크가 가져다준 선물

스파크의 핵심은 맵리듀스처럼 잡에 필요한 데이터를 디스크에서 매번 가져오는 대신, 데이터를 메모리에 캐시로 저장하는 인메모리 실행 모델에 있다. 이 덕부에 속도가 빠르며 특별히 동일한 반복 알고리즘과 같은 재사용하는 모듀 유형의 작업에 더욱 좋다. 


# 스파크 구성 컴포넌트

# 스파크 프로그램의 실행 과정

# 스파크 생태계

# 가상머신 설정


> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTcwODM4MTgxNCwzNTYxNzM0NjUsMjA5Mj
M2NjUzMCwtMTg3OTI1Nzc1N119
-->