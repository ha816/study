# 확률변수(Random Variable)

사실 확률변수의 정의는 간단하다. 표본공간에서 표본을 실수값으로 바꾸는 형태의 함수($X:Ω→R$, 실함수(real-valued function))가 있다면 **확률변수**(random variable)이다. 확률변수는 흔히 알고 있는 것과 다르게 변수가 아니라 함수이다. 다르게 말하자면, 발생하는 사건들에 대응하는 수치 값을 부여하는 함수를 말한다. 

>확률변수 X는 표본공간 S에 정의된 실함수(real-valued function)이다.

확률 변수의 종류에는 크게 이산확률 변수와 연속확률 변수가 있다.
- 이산확률 변수(Discrete Random Variable)
	- 이산확률변수 X가 어떤 구간의 모든 실수 값을 택하지 않고, 0,1,2 .. 와 같은 고립된 값을 택한다. 
	- 이산확률변수 X가 취하는 값에 대해 확률을 대응시켜주는 함수는 확률분포함수(확률질량함수).

- 연속확률 변수(Continuous Random Variable)
	- 확률변수 X가 어떤 구간의 모든 실수값을 택한다.
	- 연속확률 변수 X에 관한 확률을 결정하는 함수는 확률밀도함수.

쉽게 이산확률 변수와 연속확률 변수를 비교하자면, 이산확률 변수는 딱딱 끊어진 또는 구분된 변수로 구성되어 있고, 연속확률 변수는 연속적으로 이어진 변수로 이루어져 있다.


## 예제

주사위 실험과 관련하여 확률변수  X를 다음과 같이 정의하자.
$$X:Ω=\{{⚀,⚁,⚂,⚃,⚄,⚅}\}→R, X(⚀)=1,X(⚁)=2,X(⚂)=3,X(⚃)=4,X(⚄)=5,X(⚅)=6$$

확률변수  X가 의미하는 바를 알아챘는가? 그렇다. $X(◻)$는 $◻$가 보여주는 주사위 눈의 개수를 나타낸다. 이  X라는 확률변수를 이용하면 주사위 실험에서 일어나는 사건들을 간편하게 기술할 수 있다. 예를 들어  [X=1]는 확률변수 X의 함수값이 1이 되게 하는 표본을 모은 사건이다.

$$[X=1]=\{{a∈Ω:X(a)=1}\}=\{{⚀}\}$$

그러면  {⚁,⚂}는 X를 이용하여 어떻게 표현수 있을까? 그렇다.  {⚁,⚂}=[X=2,3]이 된다는 것을 금방 알아차렸을 것이다. 하지만 뭔가 대단한 것을 해낸 것 같지는 않다. 조금 더 “쓸모있을 지 모르는” 확률변수를 하나 정의해 보자.

$$Y(⚀)=1,Y(⚁)=0,Y(⚂)=1,Y(⚃)=0,Y(⚄)=1,Y(⚅)=0$$

그러면  $[Y=1]=\{{a∈Ω:Y(a)=1}\}=\{{⚀,⚂,⚄}\}$는 확률변수  Y에 대한 함숫값이 1인 표본들로 구성돤 사건이다. 한마디로 “홀수의 눈이 나오는 사건”임을 알 수 있다. 눈치 빠른 당신은

[X=1,3,5]=[Y=1] 임을 바로 알아챘을 지도 모르겠다. 아마도 확률변수 X와  Y 사이에는 어떤 관계가 있는 것 같다.

또 하나의 확률변수를 더 생각해보자.

$$Z(⚀)=−1,Z(⚁)=2,Z(⚂)=1,Z(⚃)=4,Z(⚄)=3,Z(⚅)=6$$
어렵지 않게  $X−2Y=Z$가 됨을 확인 할 수 있을 것이다. 확률변수들 간에 연산을 할 수 있다는 것이다! (사실은 $Z = X−2Y$의 함수값으로 정의했다.)

또 다른 예제로, 확률 변수 X를 동전을 두번 던져서 앞이 나오는 횟수라고 정의해보자.
$$X:Ω=\{{ [H,H], [H,T], [T,H], [T,T]}\}→R, X([H,H])=0,X([H,T])=1,X([T,H])=1,X([T,T])=2$$


## 확률변수의 기댓값과 분산

### 기댓값과 분산의 정의

확률론과 관련하여 “기댓값”과 “분산”이라는 개념이 이미 익숙하게 느껴질텐데, 사실 확률변수라는 개념을 도입하기 전에는 정의조차 할 수 없는 것들이다. 기댓값과 분산은 확률분포가 아니라 확률변수의 특성을 나타내는 값들이기 때문이다. 따라서 기댓값을 나타내는 표현  E[X]에는 확률변수 X가 포함되는 것이 매우 자연스럽다.

확률분포함수  $p:Ω→[0,1]$가 주어지고 이에 기반을 두는 확률변수 $X:Ω→R$가 주어지면  XX에 대한  **기댓값**(expectation)을 다음과 같이 정의한다.

$$E[X]=∑_{a∈Ω}p(a)X(a)$$ 

여기서 “기반을 둔다”는 것은 단순히 함수 p와 X의 정의구역이  Ω로 일치한다는 뜻이다.
주사위 실험의 예로 돌아가서  X에 대한 기댓값을 구해보면 다음과 같다.
$$E[X]=∑_{a∈{⚀,⚁,⚂,⚃,⚄,⚅}}p(a)X(a)$$
$$=p(⚀)X(⚀)+p(⚁)X(⚁)+p(⚂)X(⚂)+p(⚃)X(⚃)+p(⚄)X(⚄)+p(⚅)X(⚅)$$
$$=1/6⋅1+1/6⋅2+1/6⋅3+1/6⋅4+1/6⋅5+1/6⋅6=21/6$$

앞에서 확률변수들 간에 연산을 할 수 있다는 사실을 보았다. 예를 들면  X,Y라는 확률변수에 연산을 적용하여 또다른 확률변수  X+Y와  aX를 얻를 수 있다. (여기서  $a∈R$은 상수이다.) 새로 얻어진 확률변수들에 대한 기댓값을 구해보면 기존  X,Y에 대한 기댓값과 다음의 관계를 가진다.
$$E(X+Y)=E(X)+E(Y), E(aX)=aE(X)$$

이것을 기댓값의 선형성(linearity)이라고 한다. 이 성질을 이용하면  X,Y의 기댓값으로 부터  X+Y의 기댓값을 구할 수 있다.

확률변수에 관련된 또 하나의 값,  **분산**(variance)을 정의해보자.

$$V[X]=E[(X−E(X))^2]$$

기댓값의 선형성을 이용하면 분산을 다음과 같이 계산할 수 있다.

$$V[X]=E[(X−E[X])^2]=E[X^2−2E[X]X+E[X]^2]$$
$$=E[X^2]−2E[X]E[X]+E[X]^2=E[X^2]−E[X]^2$$

보다 일반적으로 함수 $F:R→R$에 대해 F(X)라는 새로운 확률변수를 정의할 수 있다:

$$F(X):Ω→R,  F(X)(a)=F(X(a))$$

즉,  F(X)는 F와  X라는 두 함수의 합성함수이다. 예를 들어,  $F(x)=x^3−x+1$이면  $F(X)=X3−X+1$이고
$$E[F(X)]=E[X^3−X+1]=∑_{a∈Ω}p(a)⋅(X(a)^3−X(a)+1)$$ 
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTM3NDk0MDM0MF19
-->