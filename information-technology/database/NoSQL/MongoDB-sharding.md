# MongoDB 샤딩 아키텍처

컨피그 서버는 샤드 클러스터에서 사용자가 생성한 데이터베이스와 컬렉션들의 목록을 관리한다. 하지만 모든 데이터베이스와 컬렉션 목록을 관리하는 것이 아니라, 샤딩이 활성화된 데이터베이스와 컬렉션 정보만을 관리한다. 

샤딩이 되지 않은 객체들은 컨피그 서버가 아니라 각 샤드 서버가 로컬로 관리한다. 그리고 이런 샤드를 프라이머리 샤드라고 한다.

컨피그 서버는 각 컬렌션이 여러 사드 서버로 분산되기 위한 데이터 조각을 관리하는데 이것을 청크(Chunk) 한다. 

![Mongodb Development setup](https://i.stack.imgur.com/KHCwI.png)

다음은 라우터 서버로 쿼리를 요청했을때 진행되는 과정을 나타낸다. 

1. 사용자 쿼리가 참조하는 컬렉션의 청크 메타 정보를 컨피그 서버로부터 가져와 라우터 메모리에 캐시
2. 사용자의 쿼리 조건에서 샤딩키를 찾음
	3. 쿼리 조건에 샤당 키가 있으면 해당 샤딩키를 가지는 모든 청크 정보를 라 우터 캐시에서 검색하여 청크를 가지는 모든 샤드로 사용자 쿼리를 요청
	4. 쿼리 존에 샤딩 키가 없다면 모든 샤드 서버로 사용자 쿼리 요청
3. 쿼리를 전송한 대상 샤드서버로부터 쿼리 결과가 오면 병합하여 결과를 반환

1번 과정은 라우터가 청크 메타 정보를 가지고 있지 않거나 라우터가 가진 청크 메타 정보가 오래돼서 맞지 않을 경우만 수행됩니다. 따라서 요청 쿼리가 많다고 해서 매번 컨피그 서버에 메타 정보를 조회하는 것은 아닙니다. 

# 컨피그 서버

컨피그 서버는 샤딩된 클러스터를 운영하는데 있어 필요한 모든 정보를 저장합니다. 컨피그 서버는 버전에 따라 차이가 있지만 다음과 같은 컬렉션을 가지고 있습니다. 

* databases
* collections
	* 샤드 클러스터에 존재하는 모든 컬렉션, 샤당되지 않은 컬렉션은 제외
* chunks
	* 샤딩된 컬렉션의 모든 청크 정보, 샤딩되지 않은 컬렉션의 청크 정보는 제외
* shards
* mongos
	* 각 라우터는 30초 단위로 샤드 클러스터의 모든 멤버와 핑 메세지를 주고 받습니다. mongos 컬렉션은 현재 컨피그 서버와 한번이라도 연결했던 모든 mongos 목록을 저장합니다.
* settings
	* 청크의 밸런싱 관련 작업 설정이 저장됩니다.
	* 청크 사이즈, 청크 밸런싱 활성화 여부,  밸런싱 시작 시작, 병렬 청크 이동 여부등
* version
	* 
* lockpings
	* 컨피그 서버와의 연결 확인시, 어떤 멤버가 언제 연결 상태가 어땟는지 기록합니다.
* locks
	* 사드 클러스터에 많은 멤버들이 서로 작업을 동기화하면서 처리하는 과정에 같은 작업을 동시에 시작하면 충돌이 발생할 수 있습니다. 
	* 이런 충돌을 피하려면 Locks컬렉션의 잠금을 획득해야 합니다.
* changelog
	* 컨피그 서버의 메타 정보 변경을 유발한 이벤트에 대한 정보를 저장합니다. 
	* 청크 스플릿이나 마이그레이션 같은 작업은 전체 샤드 성능에 큰 저하를 가져올 수 있습니다. 이런 경우 changelog로 청크의 변화를 시간대 별로 확인 가능합니다. 
 
 이 컬렉션들은 모두 컨피그 서버에만 저장됩니다. 
 이 메타 데이터는 샤드 클러스터를 유지하기 위한 내부 관리 목적의 데이터 이므로 사용자가 직접 변경하거나 삭제해서는 안됩니다.

## 컨피그 서버 복제

컨피그 서버는 샤딩이 활성화된 유저의 데이터베이스와 컬렉션 정보 그리고 각 컬렉션의 청크 정보를 가지고 있습니다. 이 메타정보들은 일관성 유지를 위한 매우 중요한 정보이므로 반드시 단일 구성이 아닌 복제 서버를 갖추어야 합니다.

리플리카 셋으로 구현된 컨피그 서버를 CSRS(Config Server as Replica Sets)라고 부릅니다. 

이렇게 CSRS 서버를 구축하려면 아래 조건을 만족해야 합니다. 

* 컨피그 서버는 WiredTiger 스토리지 엔진을 사용해야 합니다.
* 리플리카 셋은 아비터를 가질 수 없습니다.
* 리플리카 셋은 지연된 멤버를 가질 수 없습니다.

레플리카 셋 방식의 컨피그 서버는 최소 3개 이상의 멤버를 갖도록 권장합니다. 컨피그 서버에서는 모든 정보 조회 및 변경 쿼리의 Read Concern과 Write Concern을 "majority"로 설정하는데, 이는 전체 레플리카 셋의 과반수에 접근할 수 있어야 쿼리를 수행한다는 것을 의미합니다. 그래서 만약 커피그 서버가 2대이면, 둘중 하나만 연결되지 않아도 정보 조회와 삭제가 불가하게 됩니다.

컨피그 서버가 샤드 클러스터의 중요한 정보를 저장하긴 하지만, MongoDB 서버가 사용자 쿼리를 처리하는데 컨피그 서버가 항상 필요한 것은 아닙니다. 

라우터 서버는 초기 기동시 메타정보를 일괄적으로 자신의 캐시에 저장해둡니다. 샤드 클러스터에 새로운 멤버가 추가/삭제, 컬렉션 생성/삭제, 청크의 분리/이동에만 라우터 서버가 컨피그 서버에 데이터 변경 쿼리를 실행합니다. 

새로 라우터를 재시작 하지만 않으면 실질적으로 컨피그 서버에 모두 연결할 수 없더라도 쿼리 처리에 아무런 문제가 없다. 

그래서 하드웨어 교체나 관리 작업을 위해 컨피그 서버를 재시작하는 작업은 크게 시간에  구애받지 않고 처리가능합니다. 

# 라우터

라우터 Mongos는 사용자의 쿼리 요청을 샤드 서버로 전달하고, 쿼리 결과를 모아 사용자에게 반환하는 프록시 역할을 한다. 

라우터는 컨피그 서버의 정보를 캐시해두고 있어 쿼리를 어느 샤드서버로 보내야할지 판단할 수 있습니다. 

라우터 서버는 샤드로 부터 결과를 병합하여 사용자에게 반환하며, 불필요한 데이터를 제거하는 역할도 합니다. 

다중 쿼리를 수행시키다 보면 , 샤드 키에 맞지 않는 문서를보게 됩니다. (Orphaned Document)는 청크 마이크레이션 중이거나, 실패했거나 사용자가 강제로 키에 맞지 않는 데이터로 변경하는 경우 발생할 수 있습니다. 

이럴때 필터링 영할이 중요하며 만약 라우터가 아닌 샤드 서버로 직접 쿼리를 할 경우 샤드 키에 맞지 않는 

또한 라우터는 정렬이나 LIMIT 그리고 SKIP과 같은 쿼리 옵션이 있습니다. 

정렬이 필요하지 않은 쿼리는 샤드로부터 각 결과를 라운드--로빈 방식으로  가져온 다음 결과를 반환합니다. 하지만 정렬해샤 할 경우는 검색해야할 샤드 서버 중에서 프라이머머리 샤드를 정하고, $Orderby$ 옵션을 통해서 쿼리를 전달한다. 그러면 프라이머리 샤드는 나머지 샤드로 부터 쿼리 결과를 받아 수행한 결가를 라우터 서버로 반환한다. 

MongoDB 2.X에선 정렬을 라우터 서버에서 수행했지만, 라우터에서 데이터 정렬 작업을 하면 처리 능력이 떨어질 수 있어 응답속도가 느려지는 경우가 많았습니다. 그래서 

MongoDB 3.X 버전부터는 정렬과 같은 무거운 작업은 처리 성능이 뛰어난 샤드 서버가 직접 처리하도록 프라이머리 샤드를 선택하고,  정렬을 위임합니다.

LIMIT가 붙으면 각 샤드가 LIMIT가 붙은 쿼리를 각 샤드에서  수행하고 최종적으로 다시 LIMIT처리를 하여 원하는 개수만 가져옵니다.

SKIP 옵션이 붙으면, 이런 작업이 불가하고 전체 샤드에서 필요한 결과를 병합한 다음 SKIP으로 필요한 문서를 버리고 


## 쿼리 분산

라우터는 쿼리 조건을 기준으로 어느 샤드에 쿼리를 요청할 것인지 판단해야 합니다. 

컬렉션은 특정 필드의 값을 기준으로 샤딩될 수 있는데, 샤용자 쿼리가 샤딩 기준 값에 대한 조건을 가지고 있느냐에 따라 라우터가 쿼리를 요청할 서버를 결정할 수 있습니다. 

라우터가 사용자의 쿼리로만 요청하는 형태를 타켓쿼리(Targeted Query)라 하며, 모든 서버로 요청하는 쿼리를 브로드캐스트 쿼리라 합니다. 둘의 효율은 상황에 따라 다릅니다. 

### 타겟 쿼리

샤드 키 조건으로 사용자가 쿼리가 원하는 데이터가 있는 샤드 서버를 알 수 있습니다. 그리고 실제로 그 샤드서버로만 쿼리를 보냅니다. 

![Choosing a good Shard Key in MongoDB | Blog of Ken W. Alger](https://i2.wp.com/www.kenwalger.com/blog/wp-content/uploads/2017/06/ShardingExample.png?resize=600%2C366)

* 찾고자하는 청크는 여러 샤드로 분포가 될 수 있기 때문에 타겟 쿼리라고 해서 꼭 단일 샤드에만 쿼리를 보내는 것이 아닙니다.
* 샤드 키로는 단일 필드 뿐만 아니라 복수 필드로도 사용 가능합니다. 

SELECT, UPDATE, DELETE의 경우 조건이 샤드 키를 포함하는 경우 타겟 쿼리로 동작할 수 있습니다. 

INSERT의 경우, INSERT 되는 문서가 항상 샤드 키를 포함하므로 항상 타겟 쿼리로 작동합니다. 

### 브로드캐스트 쿼리(Broadcast Query)

샤드 키를 쿼리 조건으로 가지지 않는 경우에는 라우터가 작업 범위를 특정 샤드로 줄일 수가 없습니다. 이런 경우는 해당 쿼리는 모든 샤드로 요청되고 이를 브로드캐스트 쿼리라고 합니다. 

## 커넥션 풀 관리

MongoDB 라우터는 MongoDB 드라이버(클라이언트 드라이버)와 MongoDB 샤드서버를 중계하는 역할이므로 클라이언트와 서버쪽 커넥션을 모두 가지고 있어야 합니다. 

하지만 클라이언트쪽은 독립적으로 커넥션이 유지 되므로 커넥션 수를 제어하기가 쉽지 않습니다. 



MongoDB 라우터는 MongoDB 클라이언트로부터 요청되는 쿼리들을 처리하기 위해 내부적으로 TaskExecutorPool을 서버의 CPU 코어 개수만큼 준비합니다. 

TaskExecutorPool은 우리가 알고 있는 Thread Pool과 동일한 개념으로 이해하면 됩니다. 그리고 TaskExectuorPool은 MongoDB 샤드 서버와의 연결정보를 가지는 커넥션 풀을 하나씩 가지며 커넥션 풀은 내부적으로 다시 서브-커넥션 풀(Sub-Connection Pool)을 가집니다. **서브 커넥션 풀은 샤드 서버당 하나씩 생성됩니다.** 

이 서브 커넥션 풀을 MongoDB에선 specific-pool이라 부릅니다. 

라우터에서 기본적으로 생성되는 TaskExecutorPool은 서버에 장착된 CPU 코어의 개수만큼 생성되는데 만약 명시적으로 제한하고자 한다면 설정 파일에서 수정할 수 있습니다. 

```
setParameter : 
	taskExecutorPoolSize : 5
```

서브 커넥션 풀(Specific Pool)은 minConnections, maxConnections, hostTimeout이라는 옵션으로 컨넥션 풀의 컨넥션을 얼마나 보유할지 결정하는데합니다.

각 서브 커넥션 풀에 커넥션이 maxConnections보다 많으면 자동으로 많은 커넥션을 끊어버립니다. minConnections보다 적다하더라도 일정시간동안 쿼리 요청이 없으면 서브 커넥션 풀 자체를 종료하는데 그 시간이 hostTimeout입니다. 


## Sharding Algorithms

데이터 분산 처리의 근간은 바로 여러 사드로 데이터를 분산시키는 기준이며, 데이터 분산 기준을 샤딩 알고리즘이라고 합니다. MongoDB에서 지원하는 샤딩 알고리즘은 세 가지가 있으며, 레인지 샤딩과 해시 샤딩은 가장 기본적인 알고리즘입니다. 

태그기반의 샤딩(Tag-Aware Sharding) 또는 지역 기반 샤딩은 해시 샤딩과 레인지 샤딩을 특정 샤드와 연결하는 복합적인 샤딩 알고리즘이다. 

### Chunk(청크)

사용자 데이터를 일정 기준으로 그룹핑해서 관리하는데, 이 그룹이 청크입니다. 레인지 샤딩과 해시 샤딩은 각 데이터를 어떤 청크에 포함시켜야할지 결정합니다. 

해시 샤딩과 레인지 샤딩은 각 청크를 어느 샤드 서버에서 관리할 것인지 사용자가 결정할 수 없지만, 태그 기반 샤딩은 특정 청크를 특정 샤드에만 저장하고 처리할 수 있습니다. 

청크는  샤드 키의 원본값또는 해시값의 일정 범위를 가집니다. 하나의 컬렉션에서 샤드 키가 가장 작은값은 MinKey이고 가장 큰 값은 MaxKey입니다. 

![Diagram of the shard key value space segmented into smaller ranges or chunks.](https://docs.mongodb.com/manual/_images/sharding-range-based.bakedsvg.svg)


위 그림 처럼 실제 서비스에서 샤드 키 값의 단위가 일정하지 않습니다. 

청크는 물리적인 의미를 가지지 않으며, 논리적으로만 존재하는 개념입니다. 즉 청크 단위로 데이터 파일이 생성되거나 데이터가 모여 있지 않습니다. 

청크의 실체는 컨피그 서버에 메타 데이터로만 존재하고 실제 각 MongoDB 샤드 서버는 청크에 개념에 대해 알 필요도 없습니다. 

샤드 간의 청크 개수의 불균혀이 발생하면 청크가 다른 샤드로 넘어가고, 이로 인해서 MongoDB에 샤드서버에서는 INSERT와 DELETE가 실행됩니다. 

MongoDB와 달리 물리적인 데이터 파티션을 사용하는 NoSQL로는 대표적으로 HBASE가 있습니다. HBASE에서는 데이터의 파티션 밸렁신이 전혀 무겁지 않고 순식간의 처리가 이루어집니다. 물론 HBASE의 방식이 절대적으로 좋은 방식이라는 이야기는 아니고 선택한 방식의 장단점이 있고 이는 상호 배타적인 장단점 입니다. 

청크는 다큐먼트 자체를 파티션하는 개념이지 세컨더리 인덱스 까지 파티션 하는 개념은 아니다. 

MongoDB는 기본적으로 64MB까지 커질 수 있으며, 이 이상으로 커지면 밸런서에 의해 자동으로 Split됩니다. 청크가 빈번히 스플릿 되면 샤드 서버간의 청크 갯수가 불균형하게 될 수 있는데, 균형이 맞지 않으면 맞도록 밸런서가 청크를 이동 시키며 계속 균형을 잡도록 한다. 


청크의 크기는 ㅚ대 값으로 변경할 수 있지만 , 청크 이동 자체는 매우 고 비용이다. 

따라서 청크가 커져서 하나의 청크가 많은 문서를 저장하게 되면 청크 이동이 발생했을때 서버에 장기간의 부하를 주게 된다. 또한 청크가 크면 클수록 부하를 조절하기가 여러여무, 청크가 작을 수록 샤드간 부하를 미세하게 분산할 수 있지만 청크 이동이 빈번하게 발생할 수도 있다. 

### Range Sharding(레인지 샤딩)

샤드 키의 값을 기준으로 범위를 나누고, 사용자 데이터가 어느 청크에 포함될지 결정하는 사딩 알고리즘이다. 샤드키의 값을 변형하지 않은 상태에서 샤드 키값의 구간에 따라 청크를 할당한다. 

![Ranged Sharding — MongoDB Manual](https://docs.mongodb.com/manual/_images/sharded-cluster-ranged-distribution-good.bakedsvg.svg)

> mongoDB에서는 청크의 범위를 표시할때 대괄호([,])와 소괄호(())를 구분해서 사용합니다. 대괄호는 경계에 있는 값이 현재 범위에 포함되는 것을 말하고 소괄호는 경계값이 포함되지 않는 것을 의미합니다.

레인지 샤딩의 핵심은 **샤드 키 값이 별도의 변형과정을 거치지 않고** 그 자체로 정렬되어서 각 청크의 범위가 결정됩니다. 레인지 샤딩은 단순히 각 청크가 어떤 범위의 값을 가지는지만 결정합니다.

실제 각 청크가 어느 서버로 저장될지는 레인지 샤딩의 목적이나 역할이 아닙니다.

앞서 말한 레인지 샤딩은 샤드키로 선정된 필드의 값을 변형하지 않고 비교 정렬을 하는데, 이러 인해서 레인지 샤딩의 장점과 단점이 정해집니다. 

장점은 검색 쿼리를 타켓 쿼리로 실행할 수 있다는 점 입니다. 특정 필드의 값을 변형없이 그대로 정해진 청크 범위로 판단하여 해당 청크가 있는 샤드에만 요청처리를 보냅니다. 

단점은 각 샤드에 데이터가 균형있게 분산되지 않을 가능성이 높다는 점입니다. 데이터가 특정 청크 범위에만 집중되어 있다면 점보 청크 문제와 샤드 서버의 자원을 균형있게 쓰지 못하는 문제를 가져올 수 있습니다. 

MongoDB에서는 하나의 샤드 키값은 하나의 청크에만 포함될 수 있습니다. 

>점보청크
>MongoDB에선 동일한 샤드키 값은 반드시 하나의 청크에만 포함될 수 있습니다. 극단적으로 모든 문서의 특정 필드가 동일한 필드 값을 가진다고 가정하면 모든 데이터가 하나의 청크에만 포함되게 됩니다. 따라서 해당 청크는 매우 커질것이고 이를 쪼갤 수도 없습니다. 이러한 청크를 점보 청크라고 부릅니다. 점보 청크에 대해서 MongoDB서버는 모든 관리작업(스플릿, 청크 마이그레이션)을 포기하게 됩니다. 

결론적으로 레인지 샤딩을 언제 시용해야하는지 궁금할 것입니다. 일반적으로는 가능하다면 해시 샤딩을 사용하고 해시 샤딩이 불가하다면 레인지 샤딩을 사용하는 것이 좋습니다.

### 해시 샤딩

해시 샤딩은 레인지 샤딩과 달리 샤드 키값을 그대로 청크할당에 활용하는 것이 아니라, 샤드 키 값의 해시 값으로 청크할당을 하는 샤딩 방식입니다. 일반적으로 DBMS에서 사용하는 해시함수는 결과값이 전반적으로 골고루 분산될 수 있는 암호화 해시함수를 주로 사용하는데, MongoDB는 MD5를 사용합니다. 

해시 샤딩 값은 샤드 키값으로 해시 값을 계산한 후, 앞쪽 64bit를 짤라서 64비트 정수형으로 사용합니다. 

![Diagram of hashed shard key distribution](https://docs.mongodb.com/manual/_images/sharded-cluster-hashed-distribution.bakedsvg.svg)

중요한 점은 사실 근본적으로 해시 샤딩도 레인지 샤딩의 일종입니다. 차이점은 MD5 암호화해시함수로 해시함수를 거친 샤드키 값이 전체 범위에 대해서 골고루 분산되는 것 입니다. 

따라서 해시 샤딩은 레인지 샤딩이 가지던 아래 단점을 피할 수 있습니다. 

* 샤드키 값이 특정 범위에 집중될때 발생하는 데이터 불균형
* 연속되 샤드 키 접근으로 특정 샤드 서버에 편중된 부하

하지만 해시 샤딩이라 하더라도 샤드 키 값의 원본이 같다면 해시 결과도 같기 때문에 샤드키의 다양성(Cardinality)가 떨어지면 해시 샤동도 점보 청크가 발생하는 현상을 피할 수는 없습니다. 

> 기본적인 청크 제한 크기가 64MB이기 때문에, 가능하면 동일한 샤드 키 값을 가지는 문서 데이터 크기가 64MB보다 작도로 샤드키를 선택해야 합니다. 예를 들어, 한 문서의 크기가 512B라면 13만건 이상의 같은 샤드키를 가지지 않은 샤드키를 선택하는 것이 점보 청크를 예방하는 방법입니다. 

해시 샤딩은 레인지 샤딩에 비해서 사용시 제약사항은 더 많습니다. 

* 범위 검색 쿼리는 브로드캐스트 쿼리(Broadcast Query)로 실행	
	* 범위 안의 모든 값들에 대해 해시 값을 구하고 타켓 쿼리를 찾는것보다 단순히 브로드 캐스트로 찾는게 효율적이다. 
* 샤드 키 필드에 대해 해시 인덱스를 생성해야 함

다시 해시 인덱스의 제약사항은 아래와 같습니다.

* 단일 필드만 해시 인덱스 생성 가능(복수 필드로 만드는 복합 인덱스 불가)
* 멀티 키 필드에 대해선 해시 인덱스 생성 불가
* 부동 소수점 필드는 소수점 이하를 버리고 함수 수행

단일 필드만 해시 인덱스 생성 가능한 경우는 아래 예제를 보면 이해가 쉽습니다.
```
db.users.insert({
	name: "matt",
	country: "korea",
	composite_field: {name:"matt", country:"korea"}
});

db.users.createIndex({ name: "hashed" }) // 단일필드 인덱스 생성가능
db.users.createIndex({ country: "hashed" }) // 단일필드 인덱스 생성가능
db.users.createIndex({ composite_field: "hashed"}) // 단일필드 인덱스 생성가능
db.users.createIndex({ name: "hashed" , country: "hashed" }) // 복합필드 인덱스 생성불가
```

멀티 키 필드에 대해선 해시 인덱스 생성 불가인 경우는 해시 인덱스가 인덱스 키 필드의 모든 필드 값(Embed 문서 포함)에 대한 해시 값을 이용하기 때문에 여러 값을 가지는 배열(필드)에 대한 해시 인덱스를 지원하기 어렵습니다. 

해시 샤딩을 쓰다보면 가끔 문제가 되는 부분이 있는데 바로 로그파일에 출력되는 메세지 내용입니다. 

MongoDB에서 하나의 청크가 너무 커지면 아래 로그가 MongoDB 서버 에러로 출력됩니다. 다음 메세지는 특정 샤드 키 값을 가지는 문서가 너무 많아서 청크가 스플릿 되지 못하고 계속 커지고 있다는 메세지 입니다.

```
warning: chunk is larger than 8402030000000 bytes because of key {user_name: -75000000000}
```

사실 75000000000는 해시 결과값이기 때문에 문제가 되는 user_name 샤드키 값이 문제인지 알수가 없다. 따라서 user_name 필드로 집계 쿼리를 실행하여 동일한 user_name 값을 가지는 문서 수를 확인해보아야 합니다. 

### 지역 샤딩(Zone Sharding)

지역 샤딩은 레인지 샤딩이나 해시 샤딩과 달리 독립적으로 사용하는 방식이 아니라 레인지 샤딩이나 해시 샤딩과 반드시 함께 사용해야 합니다. 

지역 샤딩은 레인지 샤딩이나 해시 샤딩을 적용한 상태에서 데이터를 저장할 샤드를 한번더 조정할 수 있는 옵션이라고 이해할 수 있습니다. 

지역 샤딩인 도입된것은 사실 국가나 지역 기반으로 데이터의 저장소를 분리하기 위함이였습니다. 

서버간 통신시에 네트워크 왕복(Ping Latency) 시간이 중요한데, 나라 또는 지역간의 왕복시간은 생각보다 많은 시간이 걸립니다. (200ms 이상) 실제 서비스 단에서 이 정도 반응 속도로는 너무 느립니다. 


![enter image description here](https://docs.mongodb.com/manual/_images/sharding-segmenting-data-by-location-overview.bakedsvg.svg)

각 샤드는 자신이 속할 지역을 설정할 수 있습니다.
```
sh.addShardToZone("shard-01", "NA")
sh.addShardToZone("shard-02", "NA")
sh.addShardToZone("shard-03", "EU")
...
```

특정 샤드키로 지역 범위를 설정할 수 있습니다. 
```
sh.updateZoneKeyRange("db.users", { user_id: MinKey}, {user_id: 300}, "NA")
sh.updateZoneKeyRange("db.users", { user_id: 300}, {user_id: 700}, "EU" )
...
```

예를 들어, user_id 값이 250인 사용자는 NA 태그를 할당 받게되고, NA 그룹의 한 샤드에서 필요한 응답을 받게 됩니다.

지역 범위가 반드시 모든 범위 값을 커버해야하는 것은 아닙니다. (MinKey부터 MaxKey)  이렇게 지역이 매핑되지 않은 범위가 있으면 태그가 매핑되지 않은 샤드가 추가로 필요할 수도 있습니다.

지역범위를 설정할때 샤드키의 범위가 연속되어야 하는 것은 아닙니다. 아래와 같이 임의로 할당할 수도 있습니다. 

```
sh.updateZoneKeyRange("db.users", { user_id: minKey}, {user_id: 100}, "NA")
sh.updateZoneKeyRange("db.users", { user_id: 100}, {user_id: 200}, "EU" )
sh.updateZoneKeyRange("db.users", { user_id: 200}, {user_id: 300}, "NA")
...
```

하나의 샤드는 어떤 지역과 연관이 되지 않을 수도 있고, 1개 이상의 지역과 다중으로 매핑될 수도 있습니다. 

```
sh.addShardToZone("shard-01", "NA")
sh.addShardToZone("shard-02", "NA")
sh.addShardToZone("shard-02", "EU")
sh.addShardToZone("shard-03", "EU")
...
```

>주의
>MongoDB에 지역샤딩이 적용되면 현재 가지고 있던 데이터의 구조 전반을 수정하게 됩니다. 처리 주체는 라우터가 아닌 밸런서입니다. 지역범위 기반으로 지역을 알아내고, 지역을 담당하는 샤드를 찾아 청크를 마이그레이션합니다.
>덕분에 라우터 입장에서는 지역샤딩과 독립적으로 자신의 역할을 수행해도 문제가 없습니다.

>주의
>예제로는 레인지 샤딩을 살펴봤는데, 해시샤딩과 지역샤딩의 조합을 생각해볼 수도 있다. 
>하지만 샤드키의 원본 값이 아니라 해시함수로 변형된 값을 기준으로 지역샤딩을 한다면, 해시 값이 어뒤 범위에 포함될지 예측하기가 어렵다. 지역샤딩은 기준이 되는 키 값을 예측할 수 있어야 하는데, 해시샤딩을 쓰면 그것이 불가능한것입니다. 그래서 사실 해시샤딩을 사용하는 경우는 거의 없습니다.















> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTExODkyNDI0NCwtMzkxODI0NDAyLDExNT
IxNDk5NTIsLTIzNzU0NDYzMCwtNjk0ODM0NzExLDgzNjk0NzI5
OCwtNzAzMjk2NTczLDU0NzU2Njk1OSwtNDQ5NjczNDUwLDIxNT
kxMzIwLC0zMzU2Njg5OTksNDkyNzI4MDkxLDY2MDA0NTQwNywt
ODM3Mjg0Njk3LC0xODcyNTQ4ODU1LC0xMzE4MDYxOTc3LC0xMD
Y2MTc1Njk1LC0xMzcwODU3Nzk2LDgyOTczMTIzNiwtMjEwNjM3
NTkxMF19
-->