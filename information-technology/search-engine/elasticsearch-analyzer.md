
# 엘라스틱 서치 분석기

엘락스틱서치는 루씬을 기반으로 구축된 텍스트 기반 검색엔진이다. 루씬은 내부적으로 다양한 분석기를 제공하는데, 엘라스틱서치는 루씬이 제공하는 분석기를 그대로 활용한다. 테스트 분석을 이해하려면 루씬이 제공하는 분석기가 어떻게 동작하는지를 이해하는게 가장 중요하다. 

## 역색인 구조

루씬의 색인은 역색인이라는 특수한 방식을 사용한다. 역색인 구조를 간단히 정리하자면 아래와 같다. 

* 모든 문서가 가지는 단어의 고유 단어 목록
* 해당 단어가 어떤 문서에 속해 있는지에 대한 정보
* 전체 문서에 각 단어가 몇 개 들어있는지에 대한 정보
* 하나의 문서에 단어가 몇 번씩 출현했는지에 대한 빈도

예를 들어 2개의 문서가 있다고 하자. 
```
문서1
elasticsearch is cool

문서2
Elasticsearch is great
```

문서의 역색인을 만들기 위해선 각 문서를 토큰화 해야 한다. 토큰화된 단어에 대해 문서 상의 위치와 출현 빈도 등의 정보를 체크한다. 따라서 결과물은 대략 다음과 같다. 

|토큰| 문서번호|텀의 위치(Position)| 텀의빈도(Term Frequency)|
|--|--|--|--|
|elasticsearch  | doc1 | 1| 1| 
|Elasticsearch  | doc2 | 1| 1| 
|is  | doc1, doc2 | 2,2| 2| 
|cool  | doc1 | 3| 1| 
|great  | doc2 | 3| 1| 

위 내용을 보면 특정 토큰이 어떤 문서에서 어느 위치에 나왔고, 볓번 나왔는지에 대한 정보를 얻을 수 있다. 검색어가 존재하는 문서를 찾기 위해 검색어와 동일한 토큰을 찾아 해당 토큰이 존재하는 문서를 찾아 간다.

cool의 경우, 문서 1의 내용이 나온다. 하지만 "elasticsaerch"로 검색을 하면 어떻게 될까? 예상으로는 문서1과 문서2에 해당하는 내용이 다 나와야 할 것이다. 하지만 토큰의 정보가 정확하게 일치하는 데이터만 출력하기 때문에 문서1은 출력되지만 문서2는 출력되지 않는다. 

이 문제를 해결하는 가장 간단한 방법은 텍스트 전체를 소문자로 변환한 다음 색인하는 것이다. 

색인 한다는 것은 역색인 파일을 만든다는 것이다. 그렇다고 원문 자체를 바꾸는 의미는 아니다. 따라서 색인 파일에 들어갈 토큰만 변경되고 실제 문서의 내용은 변함없이 저장된다. 

색인할때 특정한 규칙과 흐름에 의해 텍스트를 변경하는 과정을 분석(Analyze)라고 하며 이 처리는 분석기 모듈의 조합으로 처리된다.

## 분석기의 구조 

필드의 값을 저장해 검색 결과에 값을 포함하기 위한 매핑 파라미터다. 기본적으로 _source에 색이된 문서가 저장된다. 




> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbNDk5MTM2MzkyXX0=
-->